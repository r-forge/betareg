<!-- README.md is generated from README.qmd via: quarto render README.qmd --to gfm -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "##",
  fig.path = "man/figures/README-",
  out.width = "75%",
  fig.width = 6,
  dpi = 300,
  asp = 0.625
)
```

<img src="https://topmodels.R-Forge.R-project.org/betareg/betareg.png" align="right" alt="countreg logo" width="100" />

# betareg: Beta Regression in R

## Overview

* Beta regression for modeling beta-distributed dependent variables on the open
  unit interval (0, 1), e.g., rates and proportions, see Cribari-Neto and Zeileis
  (2010, [doi:10.18637/jss.v034.i02](https://doi.org/10.18637/jss.v034.i02)).

* Extended-support beta regression models for variables on the closed unit
  interval [0, 1] with boundary observations at 0 and/or 1 see Kosmidis and
  Zeileis (2024, forthcoming).
  
* Alternative specifications of the classical beta regression model:
  Bias-corrected and bias-reduced estimation, finite mixture models, and
  recursive partitioning for (0, 1) beta regression, see Gr√ºn, Kosmidis, and
  Zeileis (2012, [doi:10.18637/jss.v048.i11](https://doi.org/10.18637/jss.v048.i11)).


## Installation

The stable version of `betareg` is available on CRAN:

``` r
install.packages("betareg")
```

The latest development version can be installed from R-universe:

``` r
install.packages("betareg", repos = "https://zeileis.R-universe.dev")
```


## License

The package is available under the
[General Public License version 3](https://www.gnu.org/licenses/gpl-3.0.html)
or [version 2](https://www.gnu.org/licenses/old-licenses/gpl-2.0.html)


## Illustration

A nice first illustration of beta regression is the analysis of reading accuracy
scores from primary school children from Smithson & Verkuilen (2006). Package
and data can be loaded via:

```{r setup}
library("betareg")
data("ReadingSkills", package = "betareg")
```

The reading `accuracy` was scaled to be within (0, 1). Its mean is explained
by verbal `iq` score with separate lines by `dyslexia` (control vs. dyslexic).
The precision parameter is explained by main effects of the two explanatory
variables. More details are provided in `?ReadingSkills`.

```{r betareg}
br <- betareg(accuracy ~ dyslexia * iq | dyslexia + iq, data = ReadingSkills)
summary(br)
```

The regression summary shows that `accuracy` increases with `iq` for the control
group but not for the dyslexic group (even slightly decreases). This can
be brought out more clearly graphically. This also highlights that the model
employs a logit link so that the fitted curves always remain within (0, 1).

```{r plot}
pal <- palette.colors()[c(4, 8)]
pch <- c(19, 17)
plot(accuracy ~ iq, data = ReadingSkills, col = pal[dyslexia], pch = pch[dyslexia])
iq <- -30:30/10
lines(iq, predict(br, newdata = data.frame(dyslexia = "no", iq = iq)), col = pal[1], lwd = 2)
lines(iq, predict(br, newdata = data.frame(dyslexia = "yes", iq = iq)), col = pal[2], lwd = 2)
legend("topleft", c("Control", "Dyslexic"), pch = pch, col = pal, bty = "n")
```


## Extended models

For going beyond this basic analysis the following extensions can be considered.


### Bias reduction

Bias-reduced estimation (instead of the default maximum likelihood estimation) can
be used by adding the argument `type = "BR"` in `betareg()`. This slightly
shrinks all coefficient estimates but leads to qualitatively identical results.  

```{r, eval = FALSE}
betareg(accuracy ~ dyslexia * iq | dyslexia + iq, data = ReadingSkills, type = "BR")
```


### Extended-support beta regression

To analyze the original accuracy scores in [0, 1] (without scaling the perfect
scores of `1` to `0.99`) use the variable `accuracy1`
in the code above. The `betareg()` model then estimates an additional exceedence
parameter that accounts for the boundary probability of a perfect score.  

```{r, eval = FALSE}
betareg(accuracy1 ~ dyslexia * iq | dyslexia + iq, data = ReadingSkills)
```


### Beta regression trees

To find subgroups in a beta regression by recursively splitting subsamples
(rather than fixing the dyslexia interaction in advance), beta regression trees
can be used:  

```{r, eval = FALSE}
betatree(accuracy ~ iq | iq, ~ dyslexia + ..., data = ReadingSkills, minsize = 10)
```

See the documentation of `betatree()` for more details.


### Finite mixtures of beta regressions

To find clusters in a beta regression (without even having the dyslexia information),
finite mixtures of beta regressions can be used:  

```{r, eval = FALSE}
betamix(accuracy ~ iq, data = ReadingSkills, k = 3, ...)
```

See the documentation of `betamix()` for more details.
