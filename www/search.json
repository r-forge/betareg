[
  {
    "objectID": "man/MockJurors.html",
    "href": "man/MockJurors.html",
    "title": "betareg",
    "section": "",
    "text": "Data with responses of naive mock jurors to the conventional conventional two-option verdict (guilt vs. acquittal) versus a three-option verdict setup (the third option was the Scottish ‘not proven’ alternative), in the presence/absence of conflicting testimonial evidence.\n\n\n\ndata(\"MockJurors\")\n\n\n\nA data frame containing 104 observations on 3 variables.\n\n\nverdict\n\n\nfactor indicating whether a two-option or three-option verdict is requested. (A sum contrast rather than treatment contrast is employed.)\n\n\nconflict\n\n\nfactor. Is there conflicting testimonial evidence? (A sum contrast rather than treatment contrast is employed.)\n\n\nconfidence\n\n\njurors degree of confidence in his/her verdict, scaled to the open unit interval (see below).\n\n\n\n\n\nThe data were collected by Daily (2004) among first-year psychology students at Australian National University. Smithson and Verkuilen (2006) employed the data scaling the original confidence (on a scale 0–100) to the open unit interval: ((original_confidence/100) * 103 - 0.5) / 104.\nThe original coding of conflict in the data provided from Smithson’s homepage is -1/1 which Smithson and Verkuilen (2006) describe to mean no/yes. However, all their results (sample statistics, histograms, etc.) suggest that it actually means yes/no which was employed in MockJurors.\n\n\n\nExample 1 from Smithson and Verkuilen (2006) supplements.\n\n\n\nDeady, S. (2004). The Psychological Third Verdict: ‘Not Proven’ or ‘Not Willing to Make a Decision’? Unpublished honors thesis, The Australian National University, Canberra.\nSmithson, M., and Verkuilen, J. (2006). A Better Lemon Squeezer? Maximum-Likelihood Regression with Beta-Distributed Dependent Variables. Psychological Methods, 11(7), 54–71.\n\n\n\nbetareg, ReadingSkills, StressAnxiety\n\n\n\n\nlibrary(\"betareg\")\n\ndata(\"MockJurors\", package = \"betareg\")\nlibrary(\"lmtest\")\n\n## Smithson & Verkuilen (2006, Table 1)\n## variable dispersion model\n## (NOTE: numerical rather than analytical Hessian is used for replication,\n##  Smithson & Verkuilen erroneously compute one-sided p-values)\nmj_vd &lt;- betareg(confidence ~ verdict * conflict | verdict * conflict,\n  data = MockJurors, hessian = TRUE)\nsummary(mj_vd)\n\n\nCall:\nbetareg(formula = confidence ~ verdict * conflict | verdict * conflict, \n    data = MockJurors, hessian = TRUE)\n\nQuantile residuals:\n    Min      1Q  Median      3Q     Max \n-2.4764 -0.6653 -0.0989  0.6000  2.6436 \n\nCoefficients (mean model with logit link):\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)      0.912404   0.103979   8.775  &lt; 2e-16 ***\nverdict          0.005035   0.103979   0.048  0.96138    \nconflict         0.168573   0.103979   1.621  0.10497    \nverdict:conflict 0.280010   0.103979   2.693  0.00708 ** \n\nPhi coefficients (precision model with log link):\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)        1.1733     0.1278   9.180  &lt; 2e-16 ***\nverdict           -0.3299     0.1278  -2.581  0.00985 ** \nconflict           0.2196     0.1278   1.718  0.08576 .  \nverdict:conflict   0.3163     0.1278   2.475  0.01334 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 40.12 on 8 Df\nPseudo R-squared: 0.03885\nNumber of iterations in BFGS optimization: 19 \n\n## model selection for beta regression: null model, fixed dispersion model (p. 61)\nmj_null &lt;- betareg(confidence ~ 1 | 1, data = MockJurors)\nmj_fd &lt;-   betareg(confidence ~ verdict * conflict | 1, data = MockJurors)\nlrtest(mj_null, mj_fd)\n\nLikelihood ratio test\n\nModel 1: confidence ~ 1 | 1\nModel 2: confidence ~ verdict * conflict | 1\n  #Df LogLik Df  Chisq Pr(&gt;Chisq)\n1   2 28.226                     \n2   5 30.580  3 4.7086     0.1944\n\nlrtest(mj_null, mj_vd)\n\nLikelihood ratio test\n\nModel 1: confidence ~ 1 | 1\nModel 2: confidence ~ verdict * conflict | verdict * conflict\n  #Df LogLik Df  Chisq Pr(&gt;Chisq)    \n1   2 28.226                         \n2   8 40.117  6 23.782  0.0005728 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n## McFadden's pseudo-R-squared\n1 - as.vector(logLik(mj_null)/logLik(mj_vd))\n\n[1] 0.296407\n\n## visualization\nif(require(\"lattice\")) {\n  histogram(~ confidence | conflict + verdict, data = MockJurors,\n    col = \"lightgray\", breaks = 0:10/10, type = \"density\")\n}\n\n\n\n\n\n\n\n## see demo(\"SmithsonVerkuilen2006\", package = \"betareg\") for more details",
    "crumbs": [
      "Documentation",
      "Data sets",
      "MockJurors"
    ]
  },
  {
    "objectID": "man/MockJurors.html#confidence-of-mock-jurors-in-their-verdicts",
    "href": "man/MockJurors.html#confidence-of-mock-jurors-in-their-verdicts",
    "title": "betareg",
    "section": "",
    "text": "Data with responses of naive mock jurors to the conventional conventional two-option verdict (guilt vs. acquittal) versus a three-option verdict setup (the third option was the Scottish ‘not proven’ alternative), in the presence/absence of conflicting testimonial evidence.\n\n\n\ndata(\"MockJurors\")\n\n\n\nA data frame containing 104 observations on 3 variables.\n\n\nverdict\n\n\nfactor indicating whether a two-option or three-option verdict is requested. (A sum contrast rather than treatment contrast is employed.)\n\n\nconflict\n\n\nfactor. Is there conflicting testimonial evidence? (A sum contrast rather than treatment contrast is employed.)\n\n\nconfidence\n\n\njurors degree of confidence in his/her verdict, scaled to the open unit interval (see below).\n\n\n\n\n\nThe data were collected by Daily (2004) among first-year psychology students at Australian National University. Smithson and Verkuilen (2006) employed the data scaling the original confidence (on a scale 0–100) to the open unit interval: ((original_confidence/100) * 103 - 0.5) / 104.\nThe original coding of conflict in the data provided from Smithson’s homepage is -1/1 which Smithson and Verkuilen (2006) describe to mean no/yes. However, all their results (sample statistics, histograms, etc.) suggest that it actually means yes/no which was employed in MockJurors.\n\n\n\nExample 1 from Smithson and Verkuilen (2006) supplements.\n\n\n\nDeady, S. (2004). The Psychological Third Verdict: ‘Not Proven’ or ‘Not Willing to Make a Decision’? Unpublished honors thesis, The Australian National University, Canberra.\nSmithson, M., and Verkuilen, J. (2006). A Better Lemon Squeezer? Maximum-Likelihood Regression with Beta-Distributed Dependent Variables. Psychological Methods, 11(7), 54–71.\n\n\n\nbetareg, ReadingSkills, StressAnxiety\n\n\n\n\nlibrary(\"betareg\")\n\ndata(\"MockJurors\", package = \"betareg\")\nlibrary(\"lmtest\")\n\n## Smithson & Verkuilen (2006, Table 1)\n## variable dispersion model\n## (NOTE: numerical rather than analytical Hessian is used for replication,\n##  Smithson & Verkuilen erroneously compute one-sided p-values)\nmj_vd &lt;- betareg(confidence ~ verdict * conflict | verdict * conflict,\n  data = MockJurors, hessian = TRUE)\nsummary(mj_vd)\n\n\nCall:\nbetareg(formula = confidence ~ verdict * conflict | verdict * conflict, \n    data = MockJurors, hessian = TRUE)\n\nQuantile residuals:\n    Min      1Q  Median      3Q     Max \n-2.4764 -0.6653 -0.0989  0.6000  2.6436 \n\nCoefficients (mean model with logit link):\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)      0.912404   0.103979   8.775  &lt; 2e-16 ***\nverdict          0.005035   0.103979   0.048  0.96138    \nconflict         0.168573   0.103979   1.621  0.10497    \nverdict:conflict 0.280010   0.103979   2.693  0.00708 ** \n\nPhi coefficients (precision model with log link):\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)        1.1733     0.1278   9.180  &lt; 2e-16 ***\nverdict           -0.3299     0.1278  -2.581  0.00985 ** \nconflict           0.2196     0.1278   1.718  0.08576 .  \nverdict:conflict   0.3163     0.1278   2.475  0.01334 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 40.12 on 8 Df\nPseudo R-squared: 0.03885\nNumber of iterations in BFGS optimization: 19 \n\n## model selection for beta regression: null model, fixed dispersion model (p. 61)\nmj_null &lt;- betareg(confidence ~ 1 | 1, data = MockJurors)\nmj_fd &lt;-   betareg(confidence ~ verdict * conflict | 1, data = MockJurors)\nlrtest(mj_null, mj_fd)\n\nLikelihood ratio test\n\nModel 1: confidence ~ 1 | 1\nModel 2: confidence ~ verdict * conflict | 1\n  #Df LogLik Df  Chisq Pr(&gt;Chisq)\n1   2 28.226                     \n2   5 30.580  3 4.7086     0.1944\n\nlrtest(mj_null, mj_vd)\n\nLikelihood ratio test\n\nModel 1: confidence ~ 1 | 1\nModel 2: confidence ~ verdict * conflict | verdict * conflict\n  #Df LogLik Df  Chisq Pr(&gt;Chisq)    \n1   2 28.226                         \n2   8 40.117  6 23.782  0.0005728 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n## McFadden's pseudo-R-squared\n1 - as.vector(logLik(mj_null)/logLik(mj_vd))\n\n[1] 0.296407\n\n## visualization\nif(require(\"lattice\")) {\n  histogram(~ confidence | conflict + verdict, data = MockJurors,\n    col = \"lightgray\", breaks = 0:10/10, type = \"density\")\n}\n\n\n\n\n\n\n\n## see demo(\"SmithsonVerkuilen2006\", package = \"betareg\") for more details",
    "crumbs": [
      "Documentation",
      "Data sets",
      "MockJurors"
    ]
  },
  {
    "objectID": "man/XBeta.html",
    "href": "man/XBeta.html",
    "title": "betareg",
    "section": "",
    "text": "Class and methods for extended-support beta distributions using the workflow from the distributions3 package.\n\n\n\nXBeta(mu, phi, nu = 0)\n\n\n\n\n\n\n\nmu\n\n\nnumeric. The mean of the underlying beta distribution on [-nu, 1 + nu].\n\n\n\n\nphi\n\n\nnumeric. The precision parameter of the underlying beta distribution on [-nu, 1 + nu].\n\n\n\n\nnu\n\n\nnumeric. Exceedence parameter for the support of the underlying beta distribution on [-nu, 1 + nu] that is censored to [0, 1].\n\n\n\n\n\n\nIn order to obtain an extended-support beta distribution on [0, 1] an additional exceedence parameter nu is introduced. If nu &gt; 0, this scales the underlying beta distribution to the interval [-nu, 1 + nu] where the tails are subsequently censored to the unit interval [0, 1] with point masses on the boundaries 0 and 1. Thus, nu controls how likely boundary observations are and for nu = 0 (the default), the distribution reduces to the classic beta distribution (in regression parameterization) without boundary observations.\n\n\n\nA XBeta distribution object.\n\n\n\ndxbeta, BetaR\n\n\n\n\nlibrary(\"betareg\")\n\n\n## package and random seed\nlibrary(\"distributions3\")\nset.seed(6020)\n\n## three beta distributions\nX &lt;- XBeta(\n  mu  = c(0.25, 0.50, 0.75),\n  phi = c(1, 1, 2),\n  nu = c(0, 0.1, 0.2)\n)\nX\n\n[1] \"XBeta(mu = 0.25, phi = 1, nu = 0.0)\" \"XBeta(mu = 0.50, phi = 1, nu = 0.1)\"\n[3] \"XBeta(mu = 0.75, phi = 2, nu = 0.2)\"\n\n## compute moments of the distribution\nmean(X)\n\n[1] 0.2500000 0.5000000 0.7886591\n\nvariance(X)\n\n[1] 0.09375000 0.15331441 0.08617379\n\n## support interval (minimum and maximum)\nsupport(X)\n\n     min max\n[1,]   0   1\n[2,]   0   1\n[3,]   0   1\n\n## it is only continuous when there are no point masses on the boundary\nis_continuous(X)\n\n[1]  TRUE FALSE FALSE\n\ncdf(X, 0)\n\n[1] 0.0000000 0.1864295 0.0239812\n\ncdf(X, 1, lower.tail = FALSE)\n\n[1] 0.0000000 0.1864295 0.4695222\n\n## simulate random variables\nrandom(X, 5)\n\n           r_1       r_2        r_3        r_4       r_5\n[1,] 0.7497152 0.8385523 0.03196796 0.91882879 0.5454367\n[2,] 0.1263742 1.0000000 0.00000000 0.07151503 0.0000000\n[3,] 1.0000000 1.0000000 0.86031184 1.00000000 0.9764434\n\n## histograms of 1,000 simulated observations\nx &lt;- random(X, 1000)\nhist(x[1, ])\n\n\n\n\n\n\n\nhist(x[2, ])\n\n\n\n\n\n\n\nhist(x[3, ])\n\n\n\n\n\n\n\n## probability density function (PDF) and log-density (or log-likelihood)\nx &lt;- c(0.25, 0.5, 0.75)\npdf(X, x)\n\n[1] 0.6840925 0.5305165 0.6607051\n\npdf(X, x, log = TRUE)\n\n[1] -0.3796622 -0.6339043 -0.4144477\n\nlog_pdf(X, x)\n\n[1] -0.3796622 -0.6339043 -0.4144477\n\n## cumulative distribution function (CDF)\ncdf(X, x)\n\n[1] 0.6453748 0.5000000 0.3189318\n\n## quantiles\nquantile(X, 0.5)\n\n[1] 0.09331223 0.50000000 0.97152842\n\n## cdf() and quantile() are inverses (except at censoring points)\ncdf(X, quantile(X, 0.5))\n\n[1] 0.5 0.5 0.5\n\nquantile(X, cdf(X, 1))\n\n[1] 1 1 1\n\n## all methods above can either be applied elementwise or for\n## all combinations of X and x, if length(X) = length(x),\n## also the result can be assured to be a matrix via drop = FALSE\np &lt;- c(0.05, 0.5, 0.95)\nquantile(X, p, elementwise = FALSE)\n\n           q_0.05      q_0.5    q_0.95\n[1,] 9.512588e-06 0.09331223 0.9118445\n[2,] 0.000000e+00 0.50000000 1.0000000\n[3,] 1.199277e-01 0.97152842 1.0000000\n\nquantile(X, p, elementwise = TRUE)\n\n[1] 9.512588e-06 5.000000e-01 1.000000e+00\n\nquantile(X, p, elementwise = TRUE, drop = FALSE)\n\n         quantile\n[1,] 9.512588e-06\n[2,] 5.000000e-01\n[3,] 1.000000e+00\n\n## compare theoretical and empirical mean from 1,000 simulated observations\ncbind(\n  \"theoretical\" = mean(X),\n  \"empirical\" = rowMeans(random(X, 1000))\n)\n\n     theoretical empirical\n[1,]   0.2500000 0.2464581\n[2,]   0.5000000 0.4949177\n[3,]   0.7886591 0.7955785",
    "crumbs": [
      "Documentation",
      "distributions3 objects",
      "XBeta"
    ]
  },
  {
    "objectID": "man/XBeta.html#create-an-extended-support-beta-distribution",
    "href": "man/XBeta.html#create-an-extended-support-beta-distribution",
    "title": "betareg",
    "section": "",
    "text": "Class and methods for extended-support beta distributions using the workflow from the distributions3 package.\n\n\n\nXBeta(mu, phi, nu = 0)\n\n\n\n\n\n\n\nmu\n\n\nnumeric. The mean of the underlying beta distribution on [-nu, 1 + nu].\n\n\n\n\nphi\n\n\nnumeric. The precision parameter of the underlying beta distribution on [-nu, 1 + nu].\n\n\n\n\nnu\n\n\nnumeric. Exceedence parameter for the support of the underlying beta distribution on [-nu, 1 + nu] that is censored to [0, 1].\n\n\n\n\n\n\nIn order to obtain an extended-support beta distribution on [0, 1] an additional exceedence parameter nu is introduced. If nu &gt; 0, this scales the underlying beta distribution to the interval [-nu, 1 + nu] where the tails are subsequently censored to the unit interval [0, 1] with point masses on the boundaries 0 and 1. Thus, nu controls how likely boundary observations are and for nu = 0 (the default), the distribution reduces to the classic beta distribution (in regression parameterization) without boundary observations.\n\n\n\nA XBeta distribution object.\n\n\n\ndxbeta, BetaR\n\n\n\n\nlibrary(\"betareg\")\n\n\n## package and random seed\nlibrary(\"distributions3\")\nset.seed(6020)\n\n## three beta distributions\nX &lt;- XBeta(\n  mu  = c(0.25, 0.50, 0.75),\n  phi = c(1, 1, 2),\n  nu = c(0, 0.1, 0.2)\n)\nX\n\n[1] \"XBeta(mu = 0.25, phi = 1, nu = 0.0)\" \"XBeta(mu = 0.50, phi = 1, nu = 0.1)\"\n[3] \"XBeta(mu = 0.75, phi = 2, nu = 0.2)\"\n\n## compute moments of the distribution\nmean(X)\n\n[1] 0.2500000 0.5000000 0.7886591\n\nvariance(X)\n\n[1] 0.09375000 0.15331441 0.08617379\n\n## support interval (minimum and maximum)\nsupport(X)\n\n     min max\n[1,]   0   1\n[2,]   0   1\n[3,]   0   1\n\n## it is only continuous when there are no point masses on the boundary\nis_continuous(X)\n\n[1]  TRUE FALSE FALSE\n\ncdf(X, 0)\n\n[1] 0.0000000 0.1864295 0.0239812\n\ncdf(X, 1, lower.tail = FALSE)\n\n[1] 0.0000000 0.1864295 0.4695222\n\n## simulate random variables\nrandom(X, 5)\n\n           r_1       r_2        r_3        r_4       r_5\n[1,] 0.7497152 0.8385523 0.03196796 0.91882879 0.5454367\n[2,] 0.1263742 1.0000000 0.00000000 0.07151503 0.0000000\n[3,] 1.0000000 1.0000000 0.86031184 1.00000000 0.9764434\n\n## histograms of 1,000 simulated observations\nx &lt;- random(X, 1000)\nhist(x[1, ])\n\n\n\n\n\n\n\nhist(x[2, ])\n\n\n\n\n\n\n\nhist(x[3, ])\n\n\n\n\n\n\n\n## probability density function (PDF) and log-density (or log-likelihood)\nx &lt;- c(0.25, 0.5, 0.75)\npdf(X, x)\n\n[1] 0.6840925 0.5305165 0.6607051\n\npdf(X, x, log = TRUE)\n\n[1] -0.3796622 -0.6339043 -0.4144477\n\nlog_pdf(X, x)\n\n[1] -0.3796622 -0.6339043 -0.4144477\n\n## cumulative distribution function (CDF)\ncdf(X, x)\n\n[1] 0.6453748 0.5000000 0.3189318\n\n## quantiles\nquantile(X, 0.5)\n\n[1] 0.09331223 0.50000000 0.97152842\n\n## cdf() and quantile() are inverses (except at censoring points)\ncdf(X, quantile(X, 0.5))\n\n[1] 0.5 0.5 0.5\n\nquantile(X, cdf(X, 1))\n\n[1] 1 1 1\n\n## all methods above can either be applied elementwise or for\n## all combinations of X and x, if length(X) = length(x),\n## also the result can be assured to be a matrix via drop = FALSE\np &lt;- c(0.05, 0.5, 0.95)\nquantile(X, p, elementwise = FALSE)\n\n           q_0.05      q_0.5    q_0.95\n[1,] 9.512588e-06 0.09331223 0.9118445\n[2,] 0.000000e+00 0.50000000 1.0000000\n[3,] 1.199277e-01 0.97152842 1.0000000\n\nquantile(X, p, elementwise = TRUE)\n\n[1] 9.512588e-06 5.000000e-01 1.000000e+00\n\nquantile(X, p, elementwise = TRUE, drop = FALSE)\n\n         quantile\n[1,] 9.512588e-06\n[2,] 5.000000e-01\n[3,] 1.000000e+00\n\n## compare theoretical and empirical mean from 1,000 simulated observations\ncbind(\n  \"theoretical\" = mean(X),\n  \"empirical\" = rowMeans(random(X, 1000))\n)\n\n     theoretical empirical\n[1,]   0.2500000 0.2464581\n[2,]   0.5000000 0.4949177\n[3,]   0.7886591 0.7955785",
    "crumbs": [
      "Documentation",
      "distributions3 objects",
      "XBeta"
    ]
  },
  {
    "objectID": "man/dbeta4.html",
    "href": "man/dbeta4.html",
    "title": "betareg",
    "section": "",
    "text": "Density, distribution function, quantile function, and random generation for the 4-parameter beta distribution in regression parameterization.\n\n\n\ndbeta4(x, mu, phi, theta1 = 0, theta2 = 1 - theta1, log = FALSE)\n\npbeta4(q, mu, phi, theta1 = 0, theta2 = 1 - theta1, lower.tail = TRUE, log.p = FALSE)\n\nqbeta4(p, mu, phi, theta1 = 0, theta2 = 1 - theta1, lower.tail = TRUE, log.p = FALSE)\n\nrbeta4(n, mu, phi, theta1 = 0, theta2 = 1 - theta1)\n\n\n\n\n\n\n\nx, q\n\n\nnumeric. Vector of quantiles.\n\n\n\n\np\n\n\nnumeric. Vector of probabilities.\n\n\n\n\nn\n\n\nnumeric. Number of observations. If length(n) &gt; 1, the length is taken to be the number required.\n\n\n\n\nmu\n\n\nnumeric. The mean of the beta distribution that is extended to support [theta1, theta2].\n\n\n\n\nphi\n\n\nnumeric. The precision parameter of the beta distribution that is extended to support [theta1, theta2].\n\n\n\n\ntheta1, theta2\n\n\nnumeric. The minimum and maximum, respectively, of the 4-parameter beta distribution. By default a symmetric support is chosen by theta2 = 1 - theta1 which reduces to the classic beta distribution because of the default theta1 = 0.\n\n\n\n\nlog, log.p\n\n\nlogical. If TRUE, probabilities p are given as log(p).\n\n\n\n\nlower.tail\n\n\nlogical. If TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].\n\n\n\n\n\n\nThe distribution is obtained by a linear transformation of a beta-distributed random variable with intercept theta1 and slope theta2 - theta1.\n\n\n\ndbeta4 gives the density, pbeta4 gives the distribution function, qbeta4 gives the quantile function, and rbeta4 generates random deviates.\n\n\n\ndbetar, Beta4",
    "crumbs": [
      "Documentation",
      "Distributions",
      "dbeta4"
    ]
  },
  {
    "objectID": "man/dbeta4.html#the-4-parameter-beta-distribution-in-regression-parameterization",
    "href": "man/dbeta4.html#the-4-parameter-beta-distribution-in-regression-parameterization",
    "title": "betareg",
    "section": "",
    "text": "Density, distribution function, quantile function, and random generation for the 4-parameter beta distribution in regression parameterization.\n\n\n\ndbeta4(x, mu, phi, theta1 = 0, theta2 = 1 - theta1, log = FALSE)\n\npbeta4(q, mu, phi, theta1 = 0, theta2 = 1 - theta1, lower.tail = TRUE, log.p = FALSE)\n\nqbeta4(p, mu, phi, theta1 = 0, theta2 = 1 - theta1, lower.tail = TRUE, log.p = FALSE)\n\nrbeta4(n, mu, phi, theta1 = 0, theta2 = 1 - theta1)\n\n\n\n\n\n\n\nx, q\n\n\nnumeric. Vector of quantiles.\n\n\n\n\np\n\n\nnumeric. Vector of probabilities.\n\n\n\n\nn\n\n\nnumeric. Number of observations. If length(n) &gt; 1, the length is taken to be the number required.\n\n\n\n\nmu\n\n\nnumeric. The mean of the beta distribution that is extended to support [theta1, theta2].\n\n\n\n\nphi\n\n\nnumeric. The precision parameter of the beta distribution that is extended to support [theta1, theta2].\n\n\n\n\ntheta1, theta2\n\n\nnumeric. The minimum and maximum, respectively, of the 4-parameter beta distribution. By default a symmetric support is chosen by theta2 = 1 - theta1 which reduces to the classic beta distribution because of the default theta1 = 0.\n\n\n\n\nlog, log.p\n\n\nlogical. If TRUE, probabilities p are given as log(p).\n\n\n\n\nlower.tail\n\n\nlogical. If TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].\n\n\n\n\n\n\nThe distribution is obtained by a linear transformation of a beta-distributed random variable with intercept theta1 and slope theta2 - theta1.\n\n\n\ndbeta4 gives the density, pbeta4 gives the distribution function, qbeta4 gives the quantile function, and rbeta4 generates random deviates.\n\n\n\ndbetar, Beta4",
    "crumbs": [
      "Documentation",
      "Distributions",
      "dbeta4"
    ]
  },
  {
    "objectID": "man/ReadingSkills.html",
    "href": "man/ReadingSkills.html",
    "title": "betareg",
    "section": "",
    "text": "Data for assessing the contribution of non-verbal IQ to children’s reading skills in dyslexic and non-dyslexic children.\n\n\n\ndata(\"ReadingSkills\")\n\n\n\nA data frame containing 44 observations on 3 variables.\n\n\naccuracy\n\n\nnumeric. Reading score with maximum restricted to be 0.99 rather than 1 (see below).\n\n\ndyslexia\n\n\nfactor. Is the child dyslexic? (A sum contrast rather than treatment contrast is employed.)\n\n\niq\n\n\nnumeric. Non-verbal intelligence quotient transformed to z-scores.\n\n\naccuracy1\n\n\nnumeric. Unrestricted reading score with a maximum of 1 (see below).\n\n\n\n\n\nThe data were collected by Pammer and Kevan (2004) and employed by Smithson and Verkuilen (2006). The original reading accuracy score was transformed by Smithson and Verkuilen (2006) so that accuracy is in the open unit interval (0, 1) and beta regression can be employed. First, the original accuracy was scaled using the minimal and maximal score (a and b, respectively) that can be obtained in the test: accuracy1 = (original_accuracy - a) / (b - a) (a and b are not provided). Subsequently, accuracy was obtained from accuracy1 by replacing all observations with a value of 1 with 0.99.\n\n\n\nExample 3 from Smithson and Verkuilen (2006) supplements.\n\n\n\nCribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R. Journal of Statistical Software, 34(2), 1–24. doi:10.18637/jss.v034.i02\nGrün, B., Kosmidis, I., and Zeileis, A. (2012). Extended Beta Regression in R: Shaken, Stirred, Mixed, and Partitioned. Journal of Statistical Software, 48(11), 1–25. doi:10.18637/jss.v048.i11\nPammer, K., and Kevan, A. (2004). The Contribution of Visual Sensitivity, Phonological Processing and Non-Verbal IQ to Children’s Reading. Unpublished manuscript, The Australian National University, Canberra.\nSmithson, M., and Verkuilen, J. (2006). A Better Lemon Squeezer? Maximum-Likelihood Regression with Beta-Distributed Dependent Variables. Psychological Methods, 11(7), 54–71.\n\n\n\nbetareg, MockJurors, StressAnxiety\n\n\n\n\nlibrary(\"betareg\")\n\ndata(\"ReadingSkills\", package = \"betareg\")\n\n## Smithson & Verkuilen (2006, Table 5)\n## OLS regression\n## (Note: typo in iq coefficient: 0.3954 instead of 0.3594)\nrs_ols &lt;- lm(qlogis(accuracy) ~ dyslexia * iq, data = ReadingSkills)\nsummary(rs_ols)\n\n\nCall:\nlm(formula = qlogis(accuracy) ~ dyslexia * iq, data = ReadingSkills)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.66405 -0.37966  0.03687  0.40887  2.50345 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   1.6011     0.2259   7.089 1.41e-08 ***\ndyslexia     -1.2056     0.2259  -5.338 4.01e-06 ***\niq            0.3594     0.2255   1.594   0.1188    \ndyslexia:iq  -0.4229     0.2255  -1.875   0.0681 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.2 on 40 degrees of freedom\nMultiple R-squared:  0.6151,    Adjusted R-squared:  0.5862 \nF-statistic: 21.31 on 3 and 40 DF,  p-value: 2.083e-08\n\n## Beta regression (with numerical rather than analytic standard errors)\n## (Note: Smithson & Verkuilen erroneously compute one-sided p-values)\nrs_beta &lt;- betareg(accuracy ~ dyslexia * iq | dyslexia + iq,\n  data = ReadingSkills, hessian = TRUE)\nsummary(rs_beta)\n\n\nCall:\nbetareg(formula = accuracy ~ dyslexia * iq | dyslexia + iq, data = ReadingSkills, \n    hessian = TRUE)\n\nQuantile residuals:\n    Min      1Q  Median      3Q     Max \n-2.3625 -0.5872  0.3026  0.9425  1.5874 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   1.1232     0.1509   7.444 9.76e-14 ***\ndyslexia     -0.7416     0.1515  -4.897 9.74e-07 ***\niq            0.4864     0.1671   2.911 0.003603 ** \ndyslexia:iq  -0.5813     0.1726  -3.368 0.000757 ***\n\nPhi coefficients (precision model with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   3.3044     0.2265  14.589  &lt; 2e-16 ***\ndyslexia      1.7466     0.2940   5.941 2.83e-09 ***\niq            1.2291     0.4596   2.674  0.00749 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood:  65.9 on 7 Df\nPseudo R-squared: 0.5756\nNumber of iterations in BFGS optimization: 25 \n\n## visualization\nplot(accuracy ~ iq, data = ReadingSkills, col = as.numeric(dyslexia), pch = 19)\nnd &lt;- data.frame(dyslexia = \"no\", iq = -30:30/10)\nlines(nd$iq, predict(rs_beta, nd))\nlines(nd$iq, plogis(predict(rs_ols, nd)), lty = 2)\nnd &lt;- data.frame(dyslexia = \"yes\", iq = -30:30/10)\nlines(nd$iq, predict(rs_beta, nd), col = 2)\nlines(nd$iq, plogis(predict(rs_ols, nd)), col = 2, lty = 2)\nlegend(\"topleft\", c(\"Dyslexia: no\", \"Dyslexia: yes\", \"OLS\", \"Beta\"),\n  lty = c(0, 0, 2, 1), pch = c(19, 19, NA, NA), col = c(1, 2, 1, 1), bty = \"n\")\n\n\n\n\n\n\n\n## see demo(\"SmithsonVerkuilen2006\", package = \"betareg\") for more details",
    "crumbs": [
      "Documentation",
      "Data sets",
      "ReadingSkills"
    ]
  },
  {
    "objectID": "man/ReadingSkills.html#dyslexia-and-iq-predicting-reading-accuracy",
    "href": "man/ReadingSkills.html#dyslexia-and-iq-predicting-reading-accuracy",
    "title": "betareg",
    "section": "",
    "text": "Data for assessing the contribution of non-verbal IQ to children’s reading skills in dyslexic and non-dyslexic children.\n\n\n\ndata(\"ReadingSkills\")\n\n\n\nA data frame containing 44 observations on 3 variables.\n\n\naccuracy\n\n\nnumeric. Reading score with maximum restricted to be 0.99 rather than 1 (see below).\n\n\ndyslexia\n\n\nfactor. Is the child dyslexic? (A sum contrast rather than treatment contrast is employed.)\n\n\niq\n\n\nnumeric. Non-verbal intelligence quotient transformed to z-scores.\n\n\naccuracy1\n\n\nnumeric. Unrestricted reading score with a maximum of 1 (see below).\n\n\n\n\n\nThe data were collected by Pammer and Kevan (2004) and employed by Smithson and Verkuilen (2006). The original reading accuracy score was transformed by Smithson and Verkuilen (2006) so that accuracy is in the open unit interval (0, 1) and beta regression can be employed. First, the original accuracy was scaled using the minimal and maximal score (a and b, respectively) that can be obtained in the test: accuracy1 = (original_accuracy - a) / (b - a) (a and b are not provided). Subsequently, accuracy was obtained from accuracy1 by replacing all observations with a value of 1 with 0.99.\n\n\n\nExample 3 from Smithson and Verkuilen (2006) supplements.\n\n\n\nCribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R. Journal of Statistical Software, 34(2), 1–24. doi:10.18637/jss.v034.i02\nGrün, B., Kosmidis, I., and Zeileis, A. (2012). Extended Beta Regression in R: Shaken, Stirred, Mixed, and Partitioned. Journal of Statistical Software, 48(11), 1–25. doi:10.18637/jss.v048.i11\nPammer, K., and Kevan, A. (2004). The Contribution of Visual Sensitivity, Phonological Processing and Non-Verbal IQ to Children’s Reading. Unpublished manuscript, The Australian National University, Canberra.\nSmithson, M., and Verkuilen, J. (2006). A Better Lemon Squeezer? Maximum-Likelihood Regression with Beta-Distributed Dependent Variables. Psychological Methods, 11(7), 54–71.\n\n\n\nbetareg, MockJurors, StressAnxiety\n\n\n\n\nlibrary(\"betareg\")\n\ndata(\"ReadingSkills\", package = \"betareg\")\n\n## Smithson & Verkuilen (2006, Table 5)\n## OLS regression\n## (Note: typo in iq coefficient: 0.3954 instead of 0.3594)\nrs_ols &lt;- lm(qlogis(accuracy) ~ dyslexia * iq, data = ReadingSkills)\nsummary(rs_ols)\n\n\nCall:\nlm(formula = qlogis(accuracy) ~ dyslexia * iq, data = ReadingSkills)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.66405 -0.37966  0.03687  0.40887  2.50345 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   1.6011     0.2259   7.089 1.41e-08 ***\ndyslexia     -1.2056     0.2259  -5.338 4.01e-06 ***\niq            0.3594     0.2255   1.594   0.1188    \ndyslexia:iq  -0.4229     0.2255  -1.875   0.0681 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.2 on 40 degrees of freedom\nMultiple R-squared:  0.6151,    Adjusted R-squared:  0.5862 \nF-statistic: 21.31 on 3 and 40 DF,  p-value: 2.083e-08\n\n## Beta regression (with numerical rather than analytic standard errors)\n## (Note: Smithson & Verkuilen erroneously compute one-sided p-values)\nrs_beta &lt;- betareg(accuracy ~ dyslexia * iq | dyslexia + iq,\n  data = ReadingSkills, hessian = TRUE)\nsummary(rs_beta)\n\n\nCall:\nbetareg(formula = accuracy ~ dyslexia * iq | dyslexia + iq, data = ReadingSkills, \n    hessian = TRUE)\n\nQuantile residuals:\n    Min      1Q  Median      3Q     Max \n-2.3625 -0.5872  0.3026  0.9425  1.5874 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   1.1232     0.1509   7.444 9.76e-14 ***\ndyslexia     -0.7416     0.1515  -4.897 9.74e-07 ***\niq            0.4864     0.1671   2.911 0.003603 ** \ndyslexia:iq  -0.5813     0.1726  -3.368 0.000757 ***\n\nPhi coefficients (precision model with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   3.3044     0.2265  14.589  &lt; 2e-16 ***\ndyslexia      1.7466     0.2940   5.941 2.83e-09 ***\niq            1.2291     0.4596   2.674  0.00749 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood:  65.9 on 7 Df\nPseudo R-squared: 0.5756\nNumber of iterations in BFGS optimization: 25 \n\n## visualization\nplot(accuracy ~ iq, data = ReadingSkills, col = as.numeric(dyslexia), pch = 19)\nnd &lt;- data.frame(dyslexia = \"no\", iq = -30:30/10)\nlines(nd$iq, predict(rs_beta, nd))\nlines(nd$iq, plogis(predict(rs_ols, nd)), lty = 2)\nnd &lt;- data.frame(dyslexia = \"yes\", iq = -30:30/10)\nlines(nd$iq, predict(rs_beta, nd), col = 2)\nlines(nd$iq, plogis(predict(rs_ols, nd)), col = 2, lty = 2)\nlegend(\"topleft\", c(\"Dyslexia: no\", \"Dyslexia: yes\", \"OLS\", \"Beta\"),\n  lty = c(0, 0, 2, 1), pch = c(19, 19, NA, NA), col = c(1, 2, 1, 1), bty = \"n\")\n\n\n\n\n\n\n\n## see demo(\"SmithsonVerkuilen2006\", package = \"betareg\") for more details",
    "crumbs": [
      "Documentation",
      "Data sets",
      "ReadingSkills"
    ]
  },
  {
    "objectID": "man/Beta4.html",
    "href": "man/Beta4.html",
    "title": "betareg",
    "section": "",
    "text": "Class and methods for 4-parameter beta distributions in regression specification using the workflow from the distributions3 package.\n\n\n\nBeta4(mu, phi, theta1 = 0, theta2 = 1 - theta1)\n\n\n\n\n\n\n\nmu\n\n\nnumeric. The mean of the beta distribution that is extended to support [theta1, theta2].\n\n\n\n\nphi\n\n\nnumeric. The precision parameter of the beta distribution that is extended to support [theta1, theta2].\n\n\n\n\ntheta1, theta2\n\n\nnumeric. The minimum and maximum, respectively, of the 4-parameter beta distribution. By default a symmetric support is chosen by theta2 = 1 - theta1 which reduces to the classic beta distribution because of the default theta1 = 0.\n\n\n\n\n\n\nThe distribution is obtained by a linear transformation of a beta-distributed random variable with intercept theta1 and slope theta2 - theta1.\n\n\n\nA Beta4 distribution object.\n\n\n\ndbeta4, BetaR\n\n\n\n\nlibrary(\"betareg\")\n\n\n## package and random seed\nlibrary(\"distributions3\")\nset.seed(6020)\n\n## three beta distributions\nX &lt;- Beta4(\n  mu  = c(0.25, 0.50, 0.75),\n  phi = c(1, 1, 2),\n  theta1 = c(0, -0.1, -0.1),\n  theta2 = c(1, 1.1, 1.5)\n)\nX\n\n[1] \"Beta4(mu = 0.25, phi = 1, theta1 =  0.0, theta2 = 1.0)\"\n[2] \"Beta4(mu = 0.50, phi = 1, theta1 = -0.1, theta2 = 1.1)\"\n[3] \"Beta4(mu = 0.75, phi = 2, theta1 = -0.1, theta2 = 1.5)\"\n\n## compute moments of the distribution\nmean(X)\n\n[1] 0.25 0.50 1.10\n\nvariance(X)\n\n[1] 0.09375 0.18000 0.16000\n\n## support interval (minimum and maximum)\nsupport(X)\n\n      min max\n[1,]  0.0 1.0\n[2,] -0.1 1.1\n[3,] -0.1 1.5\n\n## simulate random variables\nrandom(X, 5)\n\n           r_1       r_2         r_3        r_4         r_5\n[1,] 0.7497152 0.8385523  0.03196796 0.91882879  0.54543668\n[2,] 0.1263742 1.0978772 -0.09430773 0.07151503 -0.00499443\n[3,] 1.4311350 1.4850582  1.11178496 1.36985916  1.24450679\n\n## histograms of 1,000 simulated observations\nx &lt;- random(X, 1000)\nhist(x[1, ])\n\n\n\n\n\n\n\nhist(x[2, ])\n\n\n\n\n\n\n\nhist(x[3, ])\n\n\n\n\n\n\n\n## probability density function (PDF) and log-density (or log-likelihood)\nx &lt;- c(0.25, 0.5, 0.75)\npdf(X, x)\n\n[1] 0.6840925 0.5305165 0.4235834\n\npdf(X, x, log = TRUE)\n\n[1] -0.3796622 -0.6339043 -0.8590048\n\nlog_pdf(X, x)\n\n[1] -0.3796622 -0.6339043 -0.8590048\n\n## cumulative distribution function (CDF)\ncdf(X, x)\n\n[1] 0.6453748 0.5000000 0.2022198\n\n## quantiles\nquantile(X, 0.5)\n\n[1] 0.09331223 0.50000000 1.23888962\n\n## cdf() and quantile() are inverses\ncdf(X, quantile(X, 0.5))\n\n[1] 0.5 0.5 0.5\n\nquantile(X, cdf(X, 1))\n\n[1] 1 1 1\n\n## all methods above can either be applied elementwise or for\n## all combinations of X and x, if length(X) = length(x),\n## also the result can be assured to be a matrix via drop = FALSE\np &lt;- c(0.05, 0.5, 0.95)\nquantile(X, p, elementwise = FALSE)\n\n            q_0.05      q_0.5    q_0.95\n[1,]  9.512588e-06 0.09331223 0.9118445\n[2,] -9.261300e-02 0.50000000 1.0926130\n[3,]  2.656317e-01 1.23888962 1.4975313\n\nquantile(X, p, elementwise = TRUE)\n\n[1] 9.512588e-06 5.000000e-01 1.497531e+00\n\nquantile(X, p, elementwise = TRUE, drop = FALSE)\n\n         quantile\n[1,] 9.512588e-06\n[2,] 5.000000e-01\n[3,] 1.497531e+00\n\n## compare theoretical and empirical mean from 1,000 simulated observations\ncbind(\n  \"theoretical\" = mean(X),\n  \"empirical\" = rowMeans(random(X, 1000))\n)\n\n     theoretical empirical\n[1,]        0.25 0.2464581\n[2,]        0.50 0.4930360\n[3,]        1.10 1.1068752",
    "crumbs": [
      "Documentation",
      "distributions3 objects",
      "Beta4"
    ]
  },
  {
    "objectID": "man/Beta4.html#create-a-4-parameter-beta-distribution",
    "href": "man/Beta4.html#create-a-4-parameter-beta-distribution",
    "title": "betareg",
    "section": "",
    "text": "Class and methods for 4-parameter beta distributions in regression specification using the workflow from the distributions3 package.\n\n\n\nBeta4(mu, phi, theta1 = 0, theta2 = 1 - theta1)\n\n\n\n\n\n\n\nmu\n\n\nnumeric. The mean of the beta distribution that is extended to support [theta1, theta2].\n\n\n\n\nphi\n\n\nnumeric. The precision parameter of the beta distribution that is extended to support [theta1, theta2].\n\n\n\n\ntheta1, theta2\n\n\nnumeric. The minimum and maximum, respectively, of the 4-parameter beta distribution. By default a symmetric support is chosen by theta2 = 1 - theta1 which reduces to the classic beta distribution because of the default theta1 = 0.\n\n\n\n\n\n\nThe distribution is obtained by a linear transformation of a beta-distributed random variable with intercept theta1 and slope theta2 - theta1.\n\n\n\nA Beta4 distribution object.\n\n\n\ndbeta4, BetaR\n\n\n\n\nlibrary(\"betareg\")\n\n\n## package and random seed\nlibrary(\"distributions3\")\nset.seed(6020)\n\n## three beta distributions\nX &lt;- Beta4(\n  mu  = c(0.25, 0.50, 0.75),\n  phi = c(1, 1, 2),\n  theta1 = c(0, -0.1, -0.1),\n  theta2 = c(1, 1.1, 1.5)\n)\nX\n\n[1] \"Beta4(mu = 0.25, phi = 1, theta1 =  0.0, theta2 = 1.0)\"\n[2] \"Beta4(mu = 0.50, phi = 1, theta1 = -0.1, theta2 = 1.1)\"\n[3] \"Beta4(mu = 0.75, phi = 2, theta1 = -0.1, theta2 = 1.5)\"\n\n## compute moments of the distribution\nmean(X)\n\n[1] 0.25 0.50 1.10\n\nvariance(X)\n\n[1] 0.09375 0.18000 0.16000\n\n## support interval (minimum and maximum)\nsupport(X)\n\n      min max\n[1,]  0.0 1.0\n[2,] -0.1 1.1\n[3,] -0.1 1.5\n\n## simulate random variables\nrandom(X, 5)\n\n           r_1       r_2         r_3        r_4         r_5\n[1,] 0.7497152 0.8385523  0.03196796 0.91882879  0.54543668\n[2,] 0.1263742 1.0978772 -0.09430773 0.07151503 -0.00499443\n[3,] 1.4311350 1.4850582  1.11178496 1.36985916  1.24450679\n\n## histograms of 1,000 simulated observations\nx &lt;- random(X, 1000)\nhist(x[1, ])\n\n\n\n\n\n\n\nhist(x[2, ])\n\n\n\n\n\n\n\nhist(x[3, ])\n\n\n\n\n\n\n\n## probability density function (PDF) and log-density (or log-likelihood)\nx &lt;- c(0.25, 0.5, 0.75)\npdf(X, x)\n\n[1] 0.6840925 0.5305165 0.4235834\n\npdf(X, x, log = TRUE)\n\n[1] -0.3796622 -0.6339043 -0.8590048\n\nlog_pdf(X, x)\n\n[1] -0.3796622 -0.6339043 -0.8590048\n\n## cumulative distribution function (CDF)\ncdf(X, x)\n\n[1] 0.6453748 0.5000000 0.2022198\n\n## quantiles\nquantile(X, 0.5)\n\n[1] 0.09331223 0.50000000 1.23888962\n\n## cdf() and quantile() are inverses\ncdf(X, quantile(X, 0.5))\n\n[1] 0.5 0.5 0.5\n\nquantile(X, cdf(X, 1))\n\n[1] 1 1 1\n\n## all methods above can either be applied elementwise or for\n## all combinations of X and x, if length(X) = length(x),\n## also the result can be assured to be a matrix via drop = FALSE\np &lt;- c(0.05, 0.5, 0.95)\nquantile(X, p, elementwise = FALSE)\n\n            q_0.05      q_0.5    q_0.95\n[1,]  9.512588e-06 0.09331223 0.9118445\n[2,] -9.261300e-02 0.50000000 1.0926130\n[3,]  2.656317e-01 1.23888962 1.4975313\n\nquantile(X, p, elementwise = TRUE)\n\n[1] 9.512588e-06 5.000000e-01 1.497531e+00\n\nquantile(X, p, elementwise = TRUE, drop = FALSE)\n\n         quantile\n[1,] 9.512588e-06\n[2,] 5.000000e-01\n[3,] 1.497531e+00\n\n## compare theoretical and empirical mean from 1,000 simulated observations\ncbind(\n  \"theoretical\" = mean(X),\n  \"empirical\" = rowMeans(random(X, 1000))\n)\n\n     theoretical empirical\n[1,]        0.25 0.2464581\n[2,]        0.50 0.4930360\n[3,]        1.10 1.1068752",
    "crumbs": [
      "Documentation",
      "distributions3 objects",
      "Beta4"
    ]
  },
  {
    "objectID": "man/plot.betareg.html",
    "href": "man/plot.betareg.html",
    "title": "betareg",
    "section": "",
    "text": "Various types of standard diagnostic plots can be produced, involving various types of residuals, influence measures etc.\n\n\n\n## S3 method for class 'betareg'\nplot(x, which = 1:4,\n  caption = c(\"Residuals vs indices of obs.\", \"Cook's distance plot\",\n    \"Generalized leverage vs predicted values\", \"Residuals vs linear predictor\", \n    \"Half-normal plot of residuals\", \"Predicted vs observed values\"),\n    sub.caption = paste(deparse(x\\$call), collapse = \"\\n\"), main = \"\", \n    ask = prod(par(\"mfcol\")) &lt; length(which) && dev.interactive(), \n    ..., type = \"quantile\", nsim = 100, level = 0.9)\n\n\n\n\n\n\n\nx\n\n\nfitted model object of class “betareg”.\n\n\n\n\nwhich\n\n\nnumeric. If a subset of the plots is required, specify a subset of the numbers 1:6.\n\n\n\n\ncaption\n\n\ncharacter. Captions to appear above the plots.\n\n\n\n\nsub.caption\n\n\ncharacter. Common title-above figures if there are multiple.\n\n\n\n\nmain\n\n\ncharacter. Title to each plot in addition to the above caption.\n\n\n\n\nask\n\n\nlogical. If TRUE, the user is asked before each plot.\n\n\n\n\n…\n\n\nother parameters to be passed through to plotting functions.\n\n\n\n\ntype\n\n\ncharacter indicating type of residual to be used, see residuals.betareg.\n\n\n\n\nnsim\n\n\nnumeric. Number of simulations in half-normal plots.\n\n\n\n\nlevel\n\n\nnumeric. Confidence level in half-normal plots.\n\n\n\n\n\n\nThe plot method for betareg objects produces various types of diagnostic plots. Most of these are standard for regression models and involve various types of residuals, influence measures etc. See Ferrari and Cribari-Neto (2004) for a discussion of some of these displays.\nThe which argument can be used to select a subset of currently six supported types of displays. The corresponding element of caption contains a brief description. In some more detail, the displays are: Residuals (as selected by type) vs indices of observations (which = 1). Cook’s distances vs indices of observations (which = 2). Generalized leverage vs predicted values (which = 3). Residuals vs linear predictor (which = 4). Half-normal plot of residuals (which = 5), which is obtained using a simulation approach. Predicted vs observed values (which = 6).\n\n\n\nCribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R. Journal of Statistical Software, 34(2), 1–24. doi:10.18637/jss.v034.i02\nFerrari, S.L.P., and Cribari-Neto, F. (2004). Beta Regression for Modeling Rates and Proportions. Journal of Applied Statistics, 31(7), 799–815.\n\n\n\nbetareg\n\n\n\n\nlibrary(\"betareg\")\n\ndata(\"GasolineYield\", package = \"betareg\")\n\ngy &lt;- betareg(yield ~ gravity + pressure + temp10 + temp, data = GasolineYield)\n\npar(mfrow = c(3, 2))\nplot(gy, which = 1:6)\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "Documentation",
      "Beta regression",
      "plot.betareg"
    ]
  },
  {
    "objectID": "man/plot.betareg.html#diagnostic-plots-for-betareg-objects",
    "href": "man/plot.betareg.html#diagnostic-plots-for-betareg-objects",
    "title": "betareg",
    "section": "",
    "text": "Various types of standard diagnostic plots can be produced, involving various types of residuals, influence measures etc.\n\n\n\n## S3 method for class 'betareg'\nplot(x, which = 1:4,\n  caption = c(\"Residuals vs indices of obs.\", \"Cook's distance plot\",\n    \"Generalized leverage vs predicted values\", \"Residuals vs linear predictor\", \n    \"Half-normal plot of residuals\", \"Predicted vs observed values\"),\n    sub.caption = paste(deparse(x\\$call), collapse = \"\\n\"), main = \"\", \n    ask = prod(par(\"mfcol\")) &lt; length(which) && dev.interactive(), \n    ..., type = \"quantile\", nsim = 100, level = 0.9)\n\n\n\n\n\n\n\nx\n\n\nfitted model object of class “betareg”.\n\n\n\n\nwhich\n\n\nnumeric. If a subset of the plots is required, specify a subset of the numbers 1:6.\n\n\n\n\ncaption\n\n\ncharacter. Captions to appear above the plots.\n\n\n\n\nsub.caption\n\n\ncharacter. Common title-above figures if there are multiple.\n\n\n\n\nmain\n\n\ncharacter. Title to each plot in addition to the above caption.\n\n\n\n\nask\n\n\nlogical. If TRUE, the user is asked before each plot.\n\n\n\n\n…\n\n\nother parameters to be passed through to plotting functions.\n\n\n\n\ntype\n\n\ncharacter indicating type of residual to be used, see residuals.betareg.\n\n\n\n\nnsim\n\n\nnumeric. Number of simulations in half-normal plots.\n\n\n\n\nlevel\n\n\nnumeric. Confidence level in half-normal plots.\n\n\n\n\n\n\nThe plot method for betareg objects produces various types of diagnostic plots. Most of these are standard for regression models and involve various types of residuals, influence measures etc. See Ferrari and Cribari-Neto (2004) for a discussion of some of these displays.\nThe which argument can be used to select a subset of currently six supported types of displays. The corresponding element of caption contains a brief description. In some more detail, the displays are: Residuals (as selected by type) vs indices of observations (which = 1). Cook’s distances vs indices of observations (which = 2). Generalized leverage vs predicted values (which = 3). Residuals vs linear predictor (which = 4). Half-normal plot of residuals (which = 5), which is obtained using a simulation approach. Predicted vs observed values (which = 6).\n\n\n\nCribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R. Journal of Statistical Software, 34(2), 1–24. doi:10.18637/jss.v034.i02\nFerrari, S.L.P., and Cribari-Neto, F. (2004). Beta Regression for Modeling Rates and Proportions. Journal of Applied Statistics, 31(7), 799–815.\n\n\n\nbetareg\n\n\n\n\nlibrary(\"betareg\")\n\ndata(\"GasolineYield\", package = \"betareg\")\n\ngy &lt;- betareg(yield ~ gravity + pressure + temp10 + temp, data = GasolineYield)\n\npar(mfrow = c(3, 2))\nplot(gy, which = 1:6)\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "Documentation",
      "Beta regression",
      "plot.betareg"
    ]
  },
  {
    "objectID": "man/dbetar.html",
    "href": "man/dbetar.html",
    "title": "betareg",
    "section": "",
    "text": "Density, distribution function, quantile function, and random generation for the beta distribution in regression parameterization.\n\n\n\ndbetar(x, mu, phi, log = FALSE)\n\npbetar(q, mu, phi, lower.tail = TRUE, log.p = FALSE)\n\nqbetar(p, mu, phi, lower.tail = TRUE, log.p = FALSE)\n\nrbetar(n, mu, phi)\n\n\n\n\n\n\n\nx, q\n\n\nnumeric. Vector of quantiles.\n\n\n\n\np\n\n\nnumeric. Vector of probabilities.\n\n\n\n\nn\n\n\nnumeric. Number of observations. If length(n) &gt; 1, the length is taken to be the number required.\n\n\n\n\nmu\n\n\nnumeric. The mean of the beta distribution.\n\n\n\n\nphi\n\n\nnumeric. The precision parameter of the beta distribution.\n\n\n\n\nlog, log.p\n\n\nlogical. If TRUE, probabilities p are given as log(p).\n\n\n\n\nlower.tail\n\n\nlogical. If TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].\n\n\n\n\n\n\nThis is the reparameterization of the beta distribution with mean mu and precision phi, as employed in beta regression. The classic parameterization of the beta distribution is obtained by setting shape1 = mu * phi and shape2 = (1 - mu) * phi, respectively.\n\n\n\ndbetar gives the density, pbetar gives the distribution function, qbetar gives the quantile function, and rbetar generates random deviates.\n\n\n\ndbeta, BetaR",
    "crumbs": [
      "Documentation",
      "Distributions",
      "dbetar"
    ]
  },
  {
    "objectID": "man/dbetar.html#the-beta-distribution-in-regression-parameterization",
    "href": "man/dbetar.html#the-beta-distribution-in-regression-parameterization",
    "title": "betareg",
    "section": "",
    "text": "Density, distribution function, quantile function, and random generation for the beta distribution in regression parameterization.\n\n\n\ndbetar(x, mu, phi, log = FALSE)\n\npbetar(q, mu, phi, lower.tail = TRUE, log.p = FALSE)\n\nqbetar(p, mu, phi, lower.tail = TRUE, log.p = FALSE)\n\nrbetar(n, mu, phi)\n\n\n\n\n\n\n\nx, q\n\n\nnumeric. Vector of quantiles.\n\n\n\n\np\n\n\nnumeric. Vector of probabilities.\n\n\n\n\nn\n\n\nnumeric. Number of observations. If length(n) &gt; 1, the length is taken to be the number required.\n\n\n\n\nmu\n\n\nnumeric. The mean of the beta distribution.\n\n\n\n\nphi\n\n\nnumeric. The precision parameter of the beta distribution.\n\n\n\n\nlog, log.p\n\n\nlogical. If TRUE, probabilities p are given as log(p).\n\n\n\n\nlower.tail\n\n\nlogical. If TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].\n\n\n\n\n\n\nThis is the reparameterization of the beta distribution with mean mu and precision phi, as employed in beta regression. The classic parameterization of the beta distribution is obtained by setting shape1 = mu * phi and shape2 = (1 - mu) * phi, respectively.\n\n\n\ndbetar gives the density, pbetar gives the distribution function, qbetar gives the quantile function, and rbetar generates random deviates.\n\n\n\ndbeta, BetaR",
    "crumbs": [
      "Documentation",
      "Distributions",
      "dbetar"
    ]
  },
  {
    "objectID": "man/summary.betareg.html",
    "href": "man/summary.betareg.html",
    "title": "betareg",
    "section": "",
    "text": "Methods for extracting information from fitted beta regression model objects of class “betareg”.\n\n\n\n## S3 method for class 'betareg'\nsummary(object, phi = NULL, type = \"quantile\", ...)\n\n## S3 method for class 'betareg'\ncoef(object, model = c(\"full\", \"mean\", \"precision\"), phi = NULL, ...)\n## S3 method for class 'betareg'\nvcov(object, model = c(\"full\", \"mean\", \"precision\"), phi = NULL, ...)\n## S3 method for class 'betareg'\nbread(x, phi = NULL, ...)\n## S3 method for class 'betareg'\nestfun(x, phi = NULL, ...)\n\n\n\n\n\n\n\nobject, x\n\n\nfitted model object of class “betareg”.\n\n\n\n\nphi\n\n\nlogical indicating whether the parameters in the precision model (for phi) should be reported as full model parameters (TRUE) or nuisance parameters (FALSE). The default is taken from object$phi.\n\n\n\n\ntype\n\n\ncharacter specifying type of residuals to be included in the summary output, see residuals.betareg.\n\n\n\n\nmodel\n\n\ncharacter specifying for which component of the model coefficients/covariance should be extracted. (Only used if phi is NULL.)\n\n\n\n\n…\n\n\ncurrently not used.\n\n\n\n\n\n\nA set of standard extractor functions for fitted model objects is available for objects of class “betareg”, including methods to the generic functions print and summary which print the estimated coefficients along with some further information. The summary in particular supplies partial Wald tests based on the coefficients and the covariance matrix. As usual, the summary method returns an object of class “summary.betareg” containing the relevant summary statistics which can subsequently be printed using the associated print method.\nA logLik method is provided, hence AIC can be called to compute information criteria.\n\n\n\nCribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R. Journal of Statistical Software, 34(2), 1–24. doi:10.18637/jss.v034.i02\nFerrari, S.L.P., and Cribari-Neto, F. (2004). Beta Regression for Modeling Rates and Proportions. Journal of Applied Statistics, 31(7), 799–815.\nSimas, A.B., and Barreto-Souza, W., and Rocha, A.V. (2010). Improved Estimators for a General Class of Beta Regression Models. Computational Statistics & Data Analysis, 54(2), 348–366.\n\n\n\nbetareg\n\n\n\n\nlibrary(\"betareg\")\n\noptions(digits = 4)\n\ndata(\"GasolineYield\", package = \"betareg\")\n\ngy2 &lt;- betareg(yield ~ batch + temp | temp, data = GasolineYield)\n\nsummary(gy2)\n\n\nCall:\nbetareg(formula = yield ~ batch + temp | temp, data = GasolineYield)\n\nQuantile residuals:\n   Min     1Q Median     3Q    Max \n-2.104 -0.585 -0.143  0.690  2.520 \n\nCoefficients (mean model with logit link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -5.923236   0.183526  -32.27  &lt; 2e-16 ***\nbatch1       1.601988   0.063856   25.09  &lt; 2e-16 ***\nbatch2       1.297266   0.099100   13.09  &lt; 2e-16 ***\nbatch3       1.565338   0.099739   15.69  &lt; 2e-16 ***\nbatch4       1.030072   0.063288   16.28  &lt; 2e-16 ***\nbatch5       1.154163   0.065643   17.58  &lt; 2e-16 ***\nbatch6       1.019445   0.066351   15.36  &lt; 2e-16 ***\nbatch7       0.622259   0.065632    9.48  &lt; 2e-16 ***\nbatch8       0.564583   0.060185    9.38  &lt; 2e-16 ***\nbatch9       0.359439   0.067141    5.35  8.6e-08 ***\ntemp         0.010359   0.000436   23.75  &lt; 2e-16 ***\n\nPhi coefficients (precision model with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.36409    1.22578    1.11     0.27    \ntemp         0.01457    0.00362    4.03  5.7e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood:   87 on 13 Df\nPseudo R-squared: 0.952\nNumber of iterations: 33 (BFGS) + 28 (Fisher scoring) \n\ncoef(gy2)\n\n      (Intercept)            batch1            batch2            batch3 \n         -5.92324           1.60199           1.29727           1.56534 \n           batch4            batch5            batch6            batch7 \n          1.03007           1.15416           1.01944           0.62226 \n           batch8            batch9              temp (phi)_(Intercept) \n          0.56458           0.35944           0.01036           1.36409 \n       (phi)_temp \n          0.01457 \n\nvcov(gy2)\n\n                  (Intercept)     batch1     batch2     batch3     batch4\n(Intercept)         3.368e-02 -4.124e-03 -8.216e-03 -8.839e-03 -3.672e-03\nbatch1             -4.124e-03  4.078e-03  2.483e-03  2.524e-03  2.189e-03\nbatch2             -8.216e-03  2.483e-03  9.821e-03  3.401e-03  2.395e-03\nbatch3             -8.839e-03  2.524e-03  3.401e-03  9.948e-03  2.427e-03\nbatch4             -3.672e-03  2.189e-03  2.395e-03  2.427e-03  4.005e-03\nbatch5             -4.461e-03  2.240e-03  2.548e-03  2.594e-03  2.206e-03\nbatch6             -3.902e-03  2.204e-03  2.439e-03  2.475e-03  2.178e-03\nbatch7             -3.007e-03  2.146e-03  2.267e-03  2.285e-03  2.133e-03\nbatch8             -6.259e-04  1.993e-03  1.804e-03  1.775e-03  2.013e-03\nbatch9             -1.801e-03  2.068e-03  2.031e-03  2.026e-03  2.072e-03\ntemp               -7.753e-05  4.999e-06  1.504e-05  1.657e-05  3.891e-06\n(phi)_(Intercept)  -1.860e-02  1.682e-04  9.769e-04  1.420e-03  1.409e-04\n(phi)_temp          4.618e-05  2.069e-07 -1.937e-06 -2.948e-06  6.530e-08\n                      batch5     batch6     batch7     batch8     batch9\n(Intercept)       -4.461e-03 -3.902e-03 -3.007e-03 -6.259e-04 -1.801e-03\nbatch1             2.240e-03  2.204e-03  2.146e-03  1.993e-03  2.068e-03\nbatch2             2.548e-03  2.439e-03  2.267e-03  1.804e-03  2.031e-03\nbatch3             2.594e-03  2.475e-03  2.285e-03  1.775e-03  2.026e-03\nbatch4             2.206e-03  2.178e-03  2.133e-03  2.013e-03  2.072e-03\nbatch5             4.309e-03  2.223e-03  2.156e-03  1.977e-03  2.065e-03\nbatch6             2.223e-03  4.402e-03  2.140e-03  2.003e-03  2.070e-03\nbatch7             2.156e-03  2.140e-03  4.308e-03  2.044e-03  2.078e-03\nbatch8             1.977e-03  2.003e-03  2.044e-03  3.622e-03  2.100e-03\nbatch9             2.065e-03  2.070e-03  2.078e-03  2.100e-03  4.508e-03\ntemp               5.827e-06  4.454e-06  2.259e-06 -3.585e-06 -7.000e-07\n(phi)_(Intercept)  1.011e-03  5.045e-04 -4.523e-04 -1.307e-03 -3.533e-04\n(phi)_temp        -2.185e-06 -8.969e-07  1.470e-06  3.675e-06  1.119e-06\n                        temp (phi)_(Intercept) (phi)_temp\n(Intercept)       -7.753e-05        -1.860e-02  4.618e-05\nbatch1             4.999e-06         1.682e-04  2.069e-07\nbatch2             1.504e-05         9.769e-04 -1.937e-06\nbatch3             1.657e-05         1.420e-03 -2.948e-06\nbatch4             3.891e-06         1.409e-04  6.530e-08\nbatch5             5.827e-06         1.011e-03 -2.185e-06\nbatch6             4.454e-06         5.045e-04 -8.969e-07\nbatch7             2.259e-06        -4.523e-04  1.470e-06\nbatch8            -3.585e-06        -1.307e-03  3.675e-06\nbatch9            -7.000e-07        -3.533e-04  1.119e-06\ntemp               1.902e-07         4.666e-05 -1.175e-07\n(phi)_(Intercept)  4.666e-05         1.503e+00 -4.342e-03\n(phi)_temp        -1.175e-07        -4.342e-03  1.309e-05\n\nlogLik(gy2)\n\n'log Lik.' 86.98 (df=13)\n\nAIC(gy2)\n\n[1] -148\n\ncoef(gy2, model = \"mean\")\n\n(Intercept)      batch1      batch2      batch3      batch4      batch5 \n   -5.92324     1.60199     1.29727     1.56534     1.03007     1.15416 \n     batch6      batch7      batch8      batch9        temp \n    1.01944     0.62226     0.56458     0.35944     0.01036 \n\ncoef(gy2, model = \"precision\")\n\n(Intercept)        temp \n    1.36409     0.01457 \n\nsummary(gy2, phi = FALSE)\n\n\nCall:\nbetareg(formula = yield ~ batch + temp | temp, data = GasolineYield)\n\nQuantile residuals:\n   Min     1Q Median     3Q    Max \n-2.104 -0.585 -0.143  0.690  2.520 \n\nCoefficients (mean model with logit link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -5.923236   0.183526  -32.27  &lt; 2e-16 ***\nbatch1       1.601988   0.063856   25.09  &lt; 2e-16 ***\nbatch2       1.297266   0.099100   13.09  &lt; 2e-16 ***\nbatch3       1.565338   0.099739   15.69  &lt; 2e-16 ***\nbatch4       1.030072   0.063288   16.28  &lt; 2e-16 ***\nbatch5       1.154163   0.065643   17.58  &lt; 2e-16 ***\nbatch6       1.019445   0.066351   15.36  &lt; 2e-16 ***\nbatch7       0.622259   0.065632    9.48  &lt; 2e-16 ***\nbatch8       0.564583   0.060185    9.38  &lt; 2e-16 ***\nbatch9       0.359439   0.067141    5.35  8.6e-08 ***\ntemp         0.010359   0.000436   23.75  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood:   87 on 13 Df\nPseudo R-squared: 0.952\nNumber of iterations: 33 (BFGS) + 28 (Fisher scoring)",
    "crumbs": [
      "Documentation",
      "Beta regression",
      "summary.betareg"
    ]
  },
  {
    "objectID": "man/summary.betareg.html#methods-for-betareg-objects",
    "href": "man/summary.betareg.html#methods-for-betareg-objects",
    "title": "betareg",
    "section": "",
    "text": "Methods for extracting information from fitted beta regression model objects of class “betareg”.\n\n\n\n## S3 method for class 'betareg'\nsummary(object, phi = NULL, type = \"quantile\", ...)\n\n## S3 method for class 'betareg'\ncoef(object, model = c(\"full\", \"mean\", \"precision\"), phi = NULL, ...)\n## S3 method for class 'betareg'\nvcov(object, model = c(\"full\", \"mean\", \"precision\"), phi = NULL, ...)\n## S3 method for class 'betareg'\nbread(x, phi = NULL, ...)\n## S3 method for class 'betareg'\nestfun(x, phi = NULL, ...)\n\n\n\n\n\n\n\nobject, x\n\n\nfitted model object of class “betareg”.\n\n\n\n\nphi\n\n\nlogical indicating whether the parameters in the precision model (for phi) should be reported as full model parameters (TRUE) or nuisance parameters (FALSE). The default is taken from object$phi.\n\n\n\n\ntype\n\n\ncharacter specifying type of residuals to be included in the summary output, see residuals.betareg.\n\n\n\n\nmodel\n\n\ncharacter specifying for which component of the model coefficients/covariance should be extracted. (Only used if phi is NULL.)\n\n\n\n\n…\n\n\ncurrently not used.\n\n\n\n\n\n\nA set of standard extractor functions for fitted model objects is available for objects of class “betareg”, including methods to the generic functions print and summary which print the estimated coefficients along with some further information. The summary in particular supplies partial Wald tests based on the coefficients and the covariance matrix. As usual, the summary method returns an object of class “summary.betareg” containing the relevant summary statistics which can subsequently be printed using the associated print method.\nA logLik method is provided, hence AIC can be called to compute information criteria.\n\n\n\nCribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R. Journal of Statistical Software, 34(2), 1–24. doi:10.18637/jss.v034.i02\nFerrari, S.L.P., and Cribari-Neto, F. (2004). Beta Regression for Modeling Rates and Proportions. Journal of Applied Statistics, 31(7), 799–815.\nSimas, A.B., and Barreto-Souza, W., and Rocha, A.V. (2010). Improved Estimators for a General Class of Beta Regression Models. Computational Statistics & Data Analysis, 54(2), 348–366.\n\n\n\nbetareg\n\n\n\n\nlibrary(\"betareg\")\n\noptions(digits = 4)\n\ndata(\"GasolineYield\", package = \"betareg\")\n\ngy2 &lt;- betareg(yield ~ batch + temp | temp, data = GasolineYield)\n\nsummary(gy2)\n\n\nCall:\nbetareg(formula = yield ~ batch + temp | temp, data = GasolineYield)\n\nQuantile residuals:\n   Min     1Q Median     3Q    Max \n-2.104 -0.585 -0.143  0.690  2.520 \n\nCoefficients (mean model with logit link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -5.923236   0.183526  -32.27  &lt; 2e-16 ***\nbatch1       1.601988   0.063856   25.09  &lt; 2e-16 ***\nbatch2       1.297266   0.099100   13.09  &lt; 2e-16 ***\nbatch3       1.565338   0.099739   15.69  &lt; 2e-16 ***\nbatch4       1.030072   0.063288   16.28  &lt; 2e-16 ***\nbatch5       1.154163   0.065643   17.58  &lt; 2e-16 ***\nbatch6       1.019445   0.066351   15.36  &lt; 2e-16 ***\nbatch7       0.622259   0.065632    9.48  &lt; 2e-16 ***\nbatch8       0.564583   0.060185    9.38  &lt; 2e-16 ***\nbatch9       0.359439   0.067141    5.35  8.6e-08 ***\ntemp         0.010359   0.000436   23.75  &lt; 2e-16 ***\n\nPhi coefficients (precision model with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.36409    1.22578    1.11     0.27    \ntemp         0.01457    0.00362    4.03  5.7e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood:   87 on 13 Df\nPseudo R-squared: 0.952\nNumber of iterations: 33 (BFGS) + 28 (Fisher scoring) \n\ncoef(gy2)\n\n      (Intercept)            batch1            batch2            batch3 \n         -5.92324           1.60199           1.29727           1.56534 \n           batch4            batch5            batch6            batch7 \n          1.03007           1.15416           1.01944           0.62226 \n           batch8            batch9              temp (phi)_(Intercept) \n          0.56458           0.35944           0.01036           1.36409 \n       (phi)_temp \n          0.01457 \n\nvcov(gy2)\n\n                  (Intercept)     batch1     batch2     batch3     batch4\n(Intercept)         3.368e-02 -4.124e-03 -8.216e-03 -8.839e-03 -3.672e-03\nbatch1             -4.124e-03  4.078e-03  2.483e-03  2.524e-03  2.189e-03\nbatch2             -8.216e-03  2.483e-03  9.821e-03  3.401e-03  2.395e-03\nbatch3             -8.839e-03  2.524e-03  3.401e-03  9.948e-03  2.427e-03\nbatch4             -3.672e-03  2.189e-03  2.395e-03  2.427e-03  4.005e-03\nbatch5             -4.461e-03  2.240e-03  2.548e-03  2.594e-03  2.206e-03\nbatch6             -3.902e-03  2.204e-03  2.439e-03  2.475e-03  2.178e-03\nbatch7             -3.007e-03  2.146e-03  2.267e-03  2.285e-03  2.133e-03\nbatch8             -6.259e-04  1.993e-03  1.804e-03  1.775e-03  2.013e-03\nbatch9             -1.801e-03  2.068e-03  2.031e-03  2.026e-03  2.072e-03\ntemp               -7.753e-05  4.999e-06  1.504e-05  1.657e-05  3.891e-06\n(phi)_(Intercept)  -1.860e-02  1.682e-04  9.769e-04  1.420e-03  1.409e-04\n(phi)_temp          4.618e-05  2.069e-07 -1.937e-06 -2.948e-06  6.530e-08\n                      batch5     batch6     batch7     batch8     batch9\n(Intercept)       -4.461e-03 -3.902e-03 -3.007e-03 -6.259e-04 -1.801e-03\nbatch1             2.240e-03  2.204e-03  2.146e-03  1.993e-03  2.068e-03\nbatch2             2.548e-03  2.439e-03  2.267e-03  1.804e-03  2.031e-03\nbatch3             2.594e-03  2.475e-03  2.285e-03  1.775e-03  2.026e-03\nbatch4             2.206e-03  2.178e-03  2.133e-03  2.013e-03  2.072e-03\nbatch5             4.309e-03  2.223e-03  2.156e-03  1.977e-03  2.065e-03\nbatch6             2.223e-03  4.402e-03  2.140e-03  2.003e-03  2.070e-03\nbatch7             2.156e-03  2.140e-03  4.308e-03  2.044e-03  2.078e-03\nbatch8             1.977e-03  2.003e-03  2.044e-03  3.622e-03  2.100e-03\nbatch9             2.065e-03  2.070e-03  2.078e-03  2.100e-03  4.508e-03\ntemp               5.827e-06  4.454e-06  2.259e-06 -3.585e-06 -7.000e-07\n(phi)_(Intercept)  1.011e-03  5.045e-04 -4.523e-04 -1.307e-03 -3.533e-04\n(phi)_temp        -2.185e-06 -8.969e-07  1.470e-06  3.675e-06  1.119e-06\n                        temp (phi)_(Intercept) (phi)_temp\n(Intercept)       -7.753e-05        -1.860e-02  4.618e-05\nbatch1             4.999e-06         1.682e-04  2.069e-07\nbatch2             1.504e-05         9.769e-04 -1.937e-06\nbatch3             1.657e-05         1.420e-03 -2.948e-06\nbatch4             3.891e-06         1.409e-04  6.530e-08\nbatch5             5.827e-06         1.011e-03 -2.185e-06\nbatch6             4.454e-06         5.045e-04 -8.969e-07\nbatch7             2.259e-06        -4.523e-04  1.470e-06\nbatch8            -3.585e-06        -1.307e-03  3.675e-06\nbatch9            -7.000e-07        -3.533e-04  1.119e-06\ntemp               1.902e-07         4.666e-05 -1.175e-07\n(phi)_(Intercept)  4.666e-05         1.503e+00 -4.342e-03\n(phi)_temp        -1.175e-07        -4.342e-03  1.309e-05\n\nlogLik(gy2)\n\n'log Lik.' 86.98 (df=13)\n\nAIC(gy2)\n\n[1] -148\n\ncoef(gy2, model = \"mean\")\n\n(Intercept)      batch1      batch2      batch3      batch4      batch5 \n   -5.92324     1.60199     1.29727     1.56534     1.03007     1.15416 \n     batch6      batch7      batch8      batch9        temp \n    1.01944     0.62226     0.56458     0.35944     0.01036 \n\ncoef(gy2, model = \"precision\")\n\n(Intercept)        temp \n    1.36409     0.01457 \n\nsummary(gy2, phi = FALSE)\n\n\nCall:\nbetareg(formula = yield ~ batch + temp | temp, data = GasolineYield)\n\nQuantile residuals:\n   Min     1Q Median     3Q    Max \n-2.104 -0.585 -0.143  0.690  2.520 \n\nCoefficients (mean model with logit link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -5.923236   0.183526  -32.27  &lt; 2e-16 ***\nbatch1       1.601988   0.063856   25.09  &lt; 2e-16 ***\nbatch2       1.297266   0.099100   13.09  &lt; 2e-16 ***\nbatch3       1.565338   0.099739   15.69  &lt; 2e-16 ***\nbatch4       1.030072   0.063288   16.28  &lt; 2e-16 ***\nbatch5       1.154163   0.065643   17.58  &lt; 2e-16 ***\nbatch6       1.019445   0.066351   15.36  &lt; 2e-16 ***\nbatch7       0.622259   0.065632    9.48  &lt; 2e-16 ***\nbatch8       0.564583   0.060185    9.38  &lt; 2e-16 ***\nbatch9       0.359439   0.067141    5.35  8.6e-08 ***\ntemp         0.010359   0.000436   23.75  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood:   87 on 13 Df\nPseudo R-squared: 0.952\nNumber of iterations: 33 (BFGS) + 28 (Fisher scoring)",
    "crumbs": [
      "Documentation",
      "Beta regression",
      "summary.betareg"
    ]
  },
  {
    "objectID": "man/betareg.control.html",
    "href": "man/betareg.control.html",
    "title": "betareg",
    "section": "",
    "text": "Various parameters that control fitting of beta regression models using betareg.\n\n\n\nbetareg.control(phi = TRUE, method = \"BFGS\", maxit = 5000,\n  gradient = NULL, hessian = FALSE, trace = FALSE, start = NULL,\n  fsmaxit = 200, fstol = 1e-8, quad = 20, ...)\n\n\n\n\n\n\n\nphi\n\n\nlogical indicating whether the precision parameter phi should be treated as a full model parameter (TRUE, default) or as a nuisance parameter.\n\n\n\n\nmethod\n\n\ncharacters string specifying the method argument passed to optim. Additionally, method = “nlminb” can be used to employ nlminb, instead.\n\n\n\n\nmaxit\n\n\ninteger specifying the maxit argument (maximal number of iterations) passed to optim.\n\n\n\n\ntrace\n\n\nlogical or integer controlling whether tracing information on\nthe progress of the optimization should be produced (passed to optim).\n\n\n\n\ngradient\n\n\nlogical. Should the analytical gradient be used for optimizing the log-likelihood? If set to FALSE a finite-difference approximation is used instead. The default of NULL signals that analytical gradients are only used for the classical “beta” distribution but not for “xbetax” or “xbeta”.\n\n\n\n\nhessian\n\n\nlogical. Should the numerical Hessian matrix from the optim output be used for estimation of the covariance matrix? By default the analytical solution is employed. For details see below.\n\n\n\n\nstart\n\n\nan optional vector with starting values for all parameters (including phi).\n\n\n\n\nfsmaxit\n\n\ninteger specifying maximal number of additional (quasi) Fisher scoring iterations. For details see below.\n\n\n\n\nfstol\n\n\nnumeric tolerance for convergence in (quasi) Fisher scoring. For details see below.\n\n\n\n\nquad\n\n\nnumeric. The number of quadrature points for numeric integration in case of dist = “xbetax” is used in the beta regression.\n\n\n\n\n…\n\n\narguments passed to optim.\n\n\n\n\n\n\nAll parameters in betareg are estimated by maximum likelihood using optim with control options set in betareg.control. Most arguments are passed on directly to optim, and start controls how optim is called.\nAfter the optim maximization, an additional (quasi) Fisher scoring can be perfomed to further enhance the result or to perform additional bias reduction. If fsmaxit is greater than zero, this additional optimization is performed and it converges if the threshold fstol is attained for the cross-product of the step size.\nStarting values can be supplied via start or estimated by lm.wfit, using the link-transformed response. Covariances are in general derived analytically. Only if type = “ML” and hessian = TRUE, they are determined numerically using the Hessian matrix returned by optim. In the latter case no Fisher scoring iterations are performed.\nThe main parameters of interest are the coefficients in the linear predictor of the model and the additional precision parameter phi which can either be treated as a full model parameter (default) or as a nuisance parameter. In the latter case the estimation does not change, only the reported information in output from print, summary, or coef (among others) will be different. See also examples.\n\n\n\nA list with the arguments specified.\n\n\n\nbetareg\n\n\n\n\nlibrary(\"betareg\")\n\noptions(digits = 4)\n\ndata(\"GasolineYield\", package = \"betareg\")\n\n## regression with phi as full model parameter\ngy1 &lt;- betareg(yield ~ batch + temp, data = GasolineYield)\ngy1\n\n\nCall:\nbetareg(formula = yield ~ batch + temp, data = GasolineYield)\n\nCoefficients (mean model with logit link):\n(Intercept)       batch1       batch2       batch3       batch4       batch5  \n     -6.160        1.728        1.323        1.572        1.060        1.134  \n     batch6       batch7       batch8       batch9         temp  \n      1.040        0.544        0.496        0.386        0.011  \n\nPhi coefficients (precision model with identity link):\n(phi)  \n  440  \n\n## regression with phi as nuisance parameter\ngy2 &lt;- betareg(yield ~ batch + temp, data = GasolineYield, phi = FALSE)\ngy2\n\n\nCall:\nbetareg(formula = yield ~ batch + temp, data = GasolineYield, phi = FALSE)\n\nCoefficients (mean model with logit link):\n(Intercept)       batch1       batch2       batch3       batch4       batch5  \n     -6.160        1.728        1.323        1.572        1.060        1.134  \n     batch6       batch7       batch8       batch9         temp  \n      1.040        0.544        0.496        0.386        0.011  \n\n## compare reported output\ncoef(gy1)\n\n(Intercept)      batch1      batch2      batch3      batch4      batch5 \n   -6.15957     1.72773     1.32260     1.57231     1.05971     1.13375 \n     batch6      batch7      batch8      batch9        temp       (phi) \n    1.04016     0.54369     0.49590     0.38579     0.01097   440.27839 \n\ncoef(gy2)\n\n(Intercept)      batch1      batch2      batch3      batch4      batch5 \n   -6.15957     1.72773     1.32260     1.57231     1.05971     1.13375 \n     batch6      batch7      batch8      batch9        temp \n    1.04016     0.54369     0.49590     0.38579     0.01097 \n\nsummary(gy1)\n\n\nCall:\nbetareg(formula = yield ~ batch + temp, data = GasolineYield)\n\nQuantile residuals:\n   Min     1Q Median     3Q    Max \n-2.140 -0.570  0.120  0.704  1.751 \n\nCoefficients (mean model with logit link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -6.159571   0.182325  -33.78  &lt; 2e-16 ***\nbatch1       1.727729   0.101229   17.07  &lt; 2e-16 ***\nbatch2       1.322597   0.117902   11.22  &lt; 2e-16 ***\nbatch3       1.572310   0.116105   13.54  &lt; 2e-16 ***\nbatch4       1.059714   0.102360   10.35  &lt; 2e-16 ***\nbatch5       1.133752   0.103523   10.95  &lt; 2e-16 ***\nbatch6       1.040162   0.106036    9.81  &lt; 2e-16 ***\nbatch7       0.543692   0.109127    4.98  6.3e-07 ***\nbatch8       0.495901   0.108926    4.55  5.3e-06 ***\nbatch9       0.385793   0.118593    3.25   0.0011 ** \ntemp         0.010967   0.000413   26.58  &lt; 2e-16 ***\n\nPhi coefficients (precision model with identity link):\n      Estimate Std. Error z value Pr(&gt;|z|)    \n(phi)      440        110       4  6.3e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 84.8 on 12 Df\nPseudo R-squared: 0.962\nNumber of iterations: 51 (BFGS) + 3 (Fisher scoring) \n\nsummary(gy2)\n\n\nCall:\nbetareg(formula = yield ~ batch + temp, data = GasolineYield, phi = FALSE)\n\nQuantile residuals:\n   Min     1Q Median     3Q    Max \n-2.140 -0.570  0.120  0.704  1.751 \n\nCoefficients (mean model with logit link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -6.159571   0.182325  -33.78  &lt; 2e-16 ***\nbatch1       1.727729   0.101229   17.07  &lt; 2e-16 ***\nbatch2       1.322597   0.117902   11.22  &lt; 2e-16 ***\nbatch3       1.572310   0.116105   13.54  &lt; 2e-16 ***\nbatch4       1.059714   0.102360   10.35  &lt; 2e-16 ***\nbatch5       1.133752   0.103523   10.95  &lt; 2e-16 ***\nbatch6       1.040162   0.106036    9.81  &lt; 2e-16 ***\nbatch7       0.543692   0.109127    4.98  6.3e-07 ***\nbatch8       0.495901   0.108926    4.55  5.3e-06 ***\nbatch9       0.385793   0.118593    3.25   0.0011 ** \ntemp         0.010967   0.000413   26.58  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 84.8 on 12 Df\nPseudo R-squared: 0.962\nNumber of iterations: 51 (BFGS) + 3 (Fisher scoring)",
    "crumbs": [
      "Documentation",
      "Beta regression",
      "betareg.control"
    ]
  },
  {
    "objectID": "man/betareg.control.html#control-parameters-for-beta-regression",
    "href": "man/betareg.control.html#control-parameters-for-beta-regression",
    "title": "betareg",
    "section": "",
    "text": "Various parameters that control fitting of beta regression models using betareg.\n\n\n\nbetareg.control(phi = TRUE, method = \"BFGS\", maxit = 5000,\n  gradient = NULL, hessian = FALSE, trace = FALSE, start = NULL,\n  fsmaxit = 200, fstol = 1e-8, quad = 20, ...)\n\n\n\n\n\n\n\nphi\n\n\nlogical indicating whether the precision parameter phi should be treated as a full model parameter (TRUE, default) or as a nuisance parameter.\n\n\n\n\nmethod\n\n\ncharacters string specifying the method argument passed to optim. Additionally, method = “nlminb” can be used to employ nlminb, instead.\n\n\n\n\nmaxit\n\n\ninteger specifying the maxit argument (maximal number of iterations) passed to optim.\n\n\n\n\ntrace\n\n\nlogical or integer controlling whether tracing information on\nthe progress of the optimization should be produced (passed to optim).\n\n\n\n\ngradient\n\n\nlogical. Should the analytical gradient be used for optimizing the log-likelihood? If set to FALSE a finite-difference approximation is used instead. The default of NULL signals that analytical gradients are only used for the classical “beta” distribution but not for “xbetax” or “xbeta”.\n\n\n\n\nhessian\n\n\nlogical. Should the numerical Hessian matrix from the optim output be used for estimation of the covariance matrix? By default the analytical solution is employed. For details see below.\n\n\n\n\nstart\n\n\nan optional vector with starting values for all parameters (including phi).\n\n\n\n\nfsmaxit\n\n\ninteger specifying maximal number of additional (quasi) Fisher scoring iterations. For details see below.\n\n\n\n\nfstol\n\n\nnumeric tolerance for convergence in (quasi) Fisher scoring. For details see below.\n\n\n\n\nquad\n\n\nnumeric. The number of quadrature points for numeric integration in case of dist = “xbetax” is used in the beta regression.\n\n\n\n\n…\n\n\narguments passed to optim.\n\n\n\n\n\n\nAll parameters in betareg are estimated by maximum likelihood using optim with control options set in betareg.control. Most arguments are passed on directly to optim, and start controls how optim is called.\nAfter the optim maximization, an additional (quasi) Fisher scoring can be perfomed to further enhance the result or to perform additional bias reduction. If fsmaxit is greater than zero, this additional optimization is performed and it converges if the threshold fstol is attained for the cross-product of the step size.\nStarting values can be supplied via start or estimated by lm.wfit, using the link-transformed response. Covariances are in general derived analytically. Only if type = “ML” and hessian = TRUE, they are determined numerically using the Hessian matrix returned by optim. In the latter case no Fisher scoring iterations are performed.\nThe main parameters of interest are the coefficients in the linear predictor of the model and the additional precision parameter phi which can either be treated as a full model parameter (default) or as a nuisance parameter. In the latter case the estimation does not change, only the reported information in output from print, summary, or coef (among others) will be different. See also examples.\n\n\n\nA list with the arguments specified.\n\n\n\nbetareg\n\n\n\n\nlibrary(\"betareg\")\n\noptions(digits = 4)\n\ndata(\"GasolineYield\", package = \"betareg\")\n\n## regression with phi as full model parameter\ngy1 &lt;- betareg(yield ~ batch + temp, data = GasolineYield)\ngy1\n\n\nCall:\nbetareg(formula = yield ~ batch + temp, data = GasolineYield)\n\nCoefficients (mean model with logit link):\n(Intercept)       batch1       batch2       batch3       batch4       batch5  \n     -6.160        1.728        1.323        1.572        1.060        1.134  \n     batch6       batch7       batch8       batch9         temp  \n      1.040        0.544        0.496        0.386        0.011  \n\nPhi coefficients (precision model with identity link):\n(phi)  \n  440  \n\n## regression with phi as nuisance parameter\ngy2 &lt;- betareg(yield ~ batch + temp, data = GasolineYield, phi = FALSE)\ngy2\n\n\nCall:\nbetareg(formula = yield ~ batch + temp, data = GasolineYield, phi = FALSE)\n\nCoefficients (mean model with logit link):\n(Intercept)       batch1       batch2       batch3       batch4       batch5  \n     -6.160        1.728        1.323        1.572        1.060        1.134  \n     batch6       batch7       batch8       batch9         temp  \n      1.040        0.544        0.496        0.386        0.011  \n\n## compare reported output\ncoef(gy1)\n\n(Intercept)      batch1      batch2      batch3      batch4      batch5 \n   -6.15957     1.72773     1.32260     1.57231     1.05971     1.13375 \n     batch6      batch7      batch8      batch9        temp       (phi) \n    1.04016     0.54369     0.49590     0.38579     0.01097   440.27839 \n\ncoef(gy2)\n\n(Intercept)      batch1      batch2      batch3      batch4      batch5 \n   -6.15957     1.72773     1.32260     1.57231     1.05971     1.13375 \n     batch6      batch7      batch8      batch9        temp \n    1.04016     0.54369     0.49590     0.38579     0.01097 \n\nsummary(gy1)\n\n\nCall:\nbetareg(formula = yield ~ batch + temp, data = GasolineYield)\n\nQuantile residuals:\n   Min     1Q Median     3Q    Max \n-2.140 -0.570  0.120  0.704  1.751 \n\nCoefficients (mean model with logit link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -6.159571   0.182325  -33.78  &lt; 2e-16 ***\nbatch1       1.727729   0.101229   17.07  &lt; 2e-16 ***\nbatch2       1.322597   0.117902   11.22  &lt; 2e-16 ***\nbatch3       1.572310   0.116105   13.54  &lt; 2e-16 ***\nbatch4       1.059714   0.102360   10.35  &lt; 2e-16 ***\nbatch5       1.133752   0.103523   10.95  &lt; 2e-16 ***\nbatch6       1.040162   0.106036    9.81  &lt; 2e-16 ***\nbatch7       0.543692   0.109127    4.98  6.3e-07 ***\nbatch8       0.495901   0.108926    4.55  5.3e-06 ***\nbatch9       0.385793   0.118593    3.25   0.0011 ** \ntemp         0.010967   0.000413   26.58  &lt; 2e-16 ***\n\nPhi coefficients (precision model with identity link):\n      Estimate Std. Error z value Pr(&gt;|z|)    \n(phi)      440        110       4  6.3e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 84.8 on 12 Df\nPseudo R-squared: 0.962\nNumber of iterations: 51 (BFGS) + 3 (Fisher scoring) \n\nsummary(gy2)\n\n\nCall:\nbetareg(formula = yield ~ batch + temp, data = GasolineYield, phi = FALSE)\n\nQuantile residuals:\n   Min     1Q Median     3Q    Max \n-2.140 -0.570  0.120  0.704  1.751 \n\nCoefficients (mean model with logit link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -6.159571   0.182325  -33.78  &lt; 2e-16 ***\nbatch1       1.727729   0.101229   17.07  &lt; 2e-16 ***\nbatch2       1.322597   0.117902   11.22  &lt; 2e-16 ***\nbatch3       1.572310   0.116105   13.54  &lt; 2e-16 ***\nbatch4       1.059714   0.102360   10.35  &lt; 2e-16 ***\nbatch5       1.133752   0.103523   10.95  &lt; 2e-16 ***\nbatch6       1.040162   0.106036    9.81  &lt; 2e-16 ***\nbatch7       0.543692   0.109127    4.98  6.3e-07 ***\nbatch8       0.495901   0.108926    4.55  5.3e-06 ***\nbatch9       0.385793   0.118593    3.25   0.0011 ** \ntemp         0.010967   0.000413   26.58  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 84.8 on 12 Df\nPseudo R-squared: 0.962\nNumber of iterations: 51 (BFGS) + 3 (Fisher scoring)",
    "crumbs": [
      "Documentation",
      "Beta regression",
      "betareg.control"
    ]
  },
  {
    "objectID": "man/CarTask.html",
    "href": "man/CarTask.html",
    "title": "betareg",
    "section": "",
    "text": "Partition-primed Probability Judgement Task for Car Dealership\n\nDescription\nIn this study participants were asked to judge how likely it is that a customer trades in a coupe or that a customer buys a car form a specific salesperson out of four possible salespersons.\n\n\nUsage\ndata(CarTask)\n\n\nFormat\nA data frame with 155 observations on the following 3 variables.\n\n\ntask\n\n\na factor with levels Car and Salesperson indicating the condition.\n\n\nprobability\n\n\na numeric vector of the estimated probability.\n\n\nNFCCscale\n\n\na numeric vector of the NFCC scale.\n\n\n\n\nDetails\nAll participants in the study were undergraduate students at The Australian National University, some of whom obtained course credit in first-year Psychology for their participation in the study.\nThe NFCC scale is a combined scale of the Need for Closure and Need for Certainty scales which are strongly correlated.\nFor task the questions were:\n\n\nCar\n\n\nWhat is the probability that a customer trades in a coupe?\n\n\nSalesperson\n\n\nWhat is the probability that a customer buys a car from Carlos?\n\n\n\n\nSource\nTaken from Smithson et al. (2011) supplements.\n\n\nReferences\nSmithson, M., Merkle, E.C., and Verkuilen, J. (2011). Beta Regression Finite Mixture Models of Polarization and Priming. Journal of Educational and Behavioral Statistics, 36(6), 804–831. doi:10.3102/1076998610396893\nSmithson, M., and Segale, C. (2009). Partition Priming in Judgments of Imprecise Probabilities. Journal of Statistical Theory and Practice, 3(1), 169–181.\n\n\nExamples\n\nlibrary(\"betareg\")\n\ndata(\"CarTask\", package = \"betareg\")\nlibrary(\"flexmix\")\ncar_betamix &lt;- betamix(probability ~ 1, data = CarTask, k = 3,\n  extra_components = list(extraComponent(type = \"uniform\", coef = 1/2,\n  delta = 0.01), extraComponent(type = \"uniform\", coef = 1/4, delta = 0.01)),\n  FLXconcomitant = FLXPmultinom(~ task))",
    "crumbs": [
      "Documentation",
      "Data sets",
      "CarTask"
    ]
  },
  {
    "objectID": "man/ImpreciseTask.html",
    "href": "man/ImpreciseTask.html",
    "title": "betareg",
    "section": "",
    "text": "Imprecise Probabilities for Sunday Weather and Boeing Stock Task\n\nDescription\nIn this study participants were asked to estimate upper and lower probabilities for event to occur and not to occur.\n\n\nUsage\ndata(ImpreciseTask)\n\n\nFormat\nA data frame with 242 observations on the following 3 variables.\n\n\ntask\n\n\na factor with levels Boeing stock and Sunday weather.\n\n\nlocation\n\n\na numeric vector of the average of the lower estimate for the event not to occur and the upper estimate for the event to occur.\n\n\ndifference\n\n\na numeric vector of the differences of the lower and upper estimate for the event to occur.\n\n\n\n\nDetails\nAll participants in the study were either first- or second-year undergraduate students in psychology, none of whom had a strong background in probability or were familiar with imprecise probability theories.\nFor the sunday weather task see WeatherTask. For the Boeing stock task participants were asked to estimate the probability that Boeing’s stock would rise more than those in a list of 30 companies.\nFor each task participants were asked to provide lower and upper estimates for the event to occur and not to occur.\n\n\nSource\nTaken from Smithson et al. (2011) supplements.\n\n\nReferences\nSmithson, M., Merkle, E.C., and Verkuilen, J. (2011). Beta Regression Finite Mixture Models of Polarization and Priming. Journal of Educational and Behavioral Statistics, 36(6), 804–831. doi:10.3102/1076998610396893\nSmithson, M., and Segale, C. (2009). Partition Priming in Judgments of Imprecise Probabilities. Journal of Statistical Theory and Practice, 3(1), 169–181.\n\n\nExamples\n\nlibrary(\"betareg\")\n\ndata(\"ImpreciseTask\", package = \"betareg\")\nlibrary(\"flexmix\")\nwt_betamix &lt;- betamix(location ~ difference * task, data = ImpreciseTask, k = 2,\n  extra_components = extraComponent(type = \"betareg\", coef =\n    list(mean = 0, precision = 8)),\n  FLXconcomitant = FLXPmultinom(~ task))",
    "crumbs": [
      "Documentation",
      "Data sets",
      "ImpreciseTask"
    ]
  },
  {
    "objectID": "man/dbeta01.html",
    "href": "man/dbeta01.html",
    "title": "betareg",
    "section": "",
    "text": "Density, distribution function, quantile function, and random generation for the zero- and/or one-inflated beta distribution in regression parameterization.\n\n\n\ndbeta01(x, mu, phi, p0 = 0, p1 = 0, log = FALSE)\n\npbeta01(q, mu, phi, p0 = 0, p1 = 0, lower.tail = TRUE, log.p = FALSE)\n\nqbeta01(p, mu, phi, p0 = 0, p1 = 0, lower.tail = TRUE, log.p = FALSE)\n\nrbeta01(n, mu, phi, p0 = 0, p1 = 0)\n\n\n\n\n\n\n\nx, q\n\n\nnumeric. Vector of quantiles.\n\n\n\n\np\n\n\nnumeric. Vector of probabilities.\n\n\n\n\nn\n\n\nnumeric. Number of observations. If length(n) &gt; 1, the length is taken to be the number required.\n\n\n\n\nmu\n\n\nnumeric. The mean of the beta distribution (on the open unit interval).\n\n\n\n\nphi\n\n\nnumeric. The precision parameter of the beta distribution.\n\n\n\n\np0\n\n\nnumeric. The probability for an observation of zero (often referred to as zero inflation).\n\n\n\n\np1\n\n\nnumeric. The probability for an observation of one (often referred to as one inflation).\n\n\n\n\nlog, log.p\n\n\nlogical. If TRUE, probabilities p are given as log(p).\n\n\n\n\nlower.tail\n\n\nlogical. If TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].\n\n\n\n\n\n\nThe zero- and/or one-inflated beta distribution is obtained by adding point masses at zero and/or one to a standard beta distribution.\nNote that the support of the standard beta distribution is the open unit interval where values of exactly zero or one cannot occur. Thus, the inflation jargon is rather misleading as there is no probability that could be inflated. It is rather a hurdle or two-part (or three-part) model.\n\n\n\ndbeta01 gives the density, pbeta01 gives the distribution function, qbeta01 gives the quantile function, and rbeta01 generates random deviates.\n\n\n\ndbetar, Beta01",
    "crumbs": [
      "Documentation",
      "Distributions",
      "dbeta01"
    ]
  },
  {
    "objectID": "man/dbeta01.html#the-zero--andor-one-inflated-beta-distribution-in-regression-parameterization",
    "href": "man/dbeta01.html#the-zero--andor-one-inflated-beta-distribution-in-regression-parameterization",
    "title": "betareg",
    "section": "",
    "text": "Density, distribution function, quantile function, and random generation for the zero- and/or one-inflated beta distribution in regression parameterization.\n\n\n\ndbeta01(x, mu, phi, p0 = 0, p1 = 0, log = FALSE)\n\npbeta01(q, mu, phi, p0 = 0, p1 = 0, lower.tail = TRUE, log.p = FALSE)\n\nqbeta01(p, mu, phi, p0 = 0, p1 = 0, lower.tail = TRUE, log.p = FALSE)\n\nrbeta01(n, mu, phi, p0 = 0, p1 = 0)\n\n\n\n\n\n\n\nx, q\n\n\nnumeric. Vector of quantiles.\n\n\n\n\np\n\n\nnumeric. Vector of probabilities.\n\n\n\n\nn\n\n\nnumeric. Number of observations. If length(n) &gt; 1, the length is taken to be the number required.\n\n\n\n\nmu\n\n\nnumeric. The mean of the beta distribution (on the open unit interval).\n\n\n\n\nphi\n\n\nnumeric. The precision parameter of the beta distribution.\n\n\n\n\np0\n\n\nnumeric. The probability for an observation of zero (often referred to as zero inflation).\n\n\n\n\np1\n\n\nnumeric. The probability for an observation of one (often referred to as one inflation).\n\n\n\n\nlog, log.p\n\n\nlogical. If TRUE, probabilities p are given as log(p).\n\n\n\n\nlower.tail\n\n\nlogical. If TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].\n\n\n\n\n\n\nThe zero- and/or one-inflated beta distribution is obtained by adding point masses at zero and/or one to a standard beta distribution.\nNote that the support of the standard beta distribution is the open unit interval where values of exactly zero or one cannot occur. Thus, the inflation jargon is rather misleading as there is no probability that could be inflated. It is rather a hurdle or two-part (or three-part) model.\n\n\n\ndbeta01 gives the density, pbeta01 gives the distribution function, qbeta01 gives the quantile function, and rbeta01 generates random deviates.\n\n\n\ndbetar, Beta01",
    "crumbs": [
      "Documentation",
      "Distributions",
      "dbeta01"
    ]
  },
  {
    "objectID": "man/LossAversion.html",
    "href": "man/LossAversion.html",
    "title": "betareg",
    "section": "",
    "text": "Data for assessing the extent of myopic loss aversion among adolescents (mostly aged 11 to 19).\n\n\n\ndata(\"LossAversion\")\n\n\n\nA data frame containing 570 observations on 7 variables.\n\n\ninvest\n\n\nnumeric. Average proportion of points invested across all 9 rounds.\n\n\ngender\n\n\nfactor. Gender of the player (or team of players).\n\n\nmale\n\n\nfactor. Was (at least one of) the player(s) male (in the team)?\n\n\nage\n\n\nnumeric. Age in years (averaged for teams).\n\n\ntreatment\n\n\nfactor. Type of treatment: long vs. short.\n\n\ngrade\n\n\nfactor. School grades: 6-8 (11-14 years) vs. 10-12 (15-18 years).\n\n\narrangement\n\n\nfactor. Is the player a single player or team of two?\n\n\n\n\n\nMyopic loss aversion is a phenomenon in behavioral economics, where individuals do not behave economically rationally when making short-term decisions under uncertainty. Example: In lotteries with positive expected payouts investments are lower than the maximum possible (loss aversion). This effect is enhanced for short-term investments (myopia or short-sightedness).\nThe data in LossAversion were collected by Matthias Sutter and Daniela Glätzle-Rützler (Universität Innsbruck) in an experiment with high-school students in Tyrol, Austria (Schwaz and Innsbruck). The students could invest X points (0-100) in each of 9 rounds in a lottery. The payouts were 100 + 2.5 * X points with probability 1/3 and 100 - X points with probability 2/3. Thus, the expected payouts were 100 + 1/6 * X points. Depending on the treatment in the experiment, the investments could either be modified in each round (treatment: \"short\") or only in round 1, 4, 7 (treatment \"long\"). Decisions were either made alone or in teams of two. The points were converted to monetary payouts using a conversion of EUR 0.5 per 100 points for lower grades (Unterstufe, 6-8) or EUR 1.0 per 100 points for upper grades (Oberstufe, 10-12).\nFrom the myopic loss aversion literature (on adults) one would expect that the investments of the players (either single players or teams of two) would depend on all factors: Investments should be\n\n\nlower in the short treatment (which would indicate myopia),\n\n\nhigher for teams (indicating a reduction in loss aversion),\n\n\nhigher for (teams with) male players,\n\n\nincrease with age/grade.\n\n\nSee Glätzle-Rützler et al. (2015) for more details and references to the literature. In their original analysis, the investments are analyzes using a panel structure (i.e., 9 separate investments for each team). Here, the data are averaged across rounds for each player, leading to qualitatively similar results. The full data along with replication materials are available in the Harvard Dataverse.\n\n\n\nGlätzle-Rützler D, Sutter M, Zeileis A (2020). Replication Data for: No Myopic Loss Aversion in Adolescents? - An Experimental Note. Harvard Dataverse, UNF:6:6hVtbHavJAFYfL7dDl7jqA==. doi:10.7910/DVN/IHFZAK\n\n\n\nGlätzle-Rützler D, Sutter M, Zeileis A (2015). No Myopic Loss Aversion in Adolescents? - An Experimental Note. Journal of Economic Behavior & Organization, 111, 169-176. doi:10.1016/j.jebo.2014.12.021\n\n\n\nbetareg\n\n\n\n\nlibrary(\"betareg\")\n\n## data for students in higher grades\ndata(\"LossAversion\", package = \"betareg\")\nLossAversion &lt;- subset(LossAversion, grade == \"10-12\")\n\n## ad hoc scaling (a la Smithson & Verkuilen)\nLossAversion$invests &lt;- ((LossAversion$invest * (nrow(LossAversion) - 1) + 0.5)/nrow(LossAversion))\n\n## fraction of boundary observations for ad hoc extended-support beta specification (xbeta)\np01 &lt;- mean(LossAversion$invest &lt;= 0 | LossAversion$invest &gt;= 1)\n\n## main effects models: Gaussian, beta, extended-support beta, extended-support beta mixture\nla_gr  &lt;- glm(invest      ~ arrangement + male + age,                      data = LossAversion)\nla_br  &lt;- betareg(invests ~ arrangement + male + age | arrangement + male, data = LossAversion)\nla_xbx &lt;- betareg(invest  ~ arrangement + male + age | arrangement + male, data = LossAversion)\nla_xb  &lt;- betareg(invest  ~ arrangement + male + age | arrangement + male, data = LossAversion,\n  dist = \"xbeta\", nu = p01/2)",
    "crumbs": [
      "Documentation",
      "Data sets",
      "LossAversion"
    ]
  },
  {
    "objectID": "man/LossAversion.html#no-myopic-loss-aversion-in-adolescents",
    "href": "man/LossAversion.html#no-myopic-loss-aversion-in-adolescents",
    "title": "betareg",
    "section": "",
    "text": "Data for assessing the extent of myopic loss aversion among adolescents (mostly aged 11 to 19).\n\n\n\ndata(\"LossAversion\")\n\n\n\nA data frame containing 570 observations on 7 variables.\n\n\ninvest\n\n\nnumeric. Average proportion of points invested across all 9 rounds.\n\n\ngender\n\n\nfactor. Gender of the player (or team of players).\n\n\nmale\n\n\nfactor. Was (at least one of) the player(s) male (in the team)?\n\n\nage\n\n\nnumeric. Age in years (averaged for teams).\n\n\ntreatment\n\n\nfactor. Type of treatment: long vs. short.\n\n\ngrade\n\n\nfactor. School grades: 6-8 (11-14 years) vs. 10-12 (15-18 years).\n\n\narrangement\n\n\nfactor. Is the player a single player or team of two?\n\n\n\n\n\nMyopic loss aversion is a phenomenon in behavioral economics, where individuals do not behave economically rationally when making short-term decisions under uncertainty. Example: In lotteries with positive expected payouts investments are lower than the maximum possible (loss aversion). This effect is enhanced for short-term investments (myopia or short-sightedness).\nThe data in LossAversion were collected by Matthias Sutter and Daniela Glätzle-Rützler (Universität Innsbruck) in an experiment with high-school students in Tyrol, Austria (Schwaz and Innsbruck). The students could invest X points (0-100) in each of 9 rounds in a lottery. The payouts were 100 + 2.5 * X points with probability 1/3 and 100 - X points with probability 2/3. Thus, the expected payouts were 100 + 1/6 * X points. Depending on the treatment in the experiment, the investments could either be modified in each round (treatment: \"short\") or only in round 1, 4, 7 (treatment \"long\"). Decisions were either made alone or in teams of two. The points were converted to monetary payouts using a conversion of EUR 0.5 per 100 points for lower grades (Unterstufe, 6-8) or EUR 1.0 per 100 points for upper grades (Oberstufe, 10-12).\nFrom the myopic loss aversion literature (on adults) one would expect that the investments of the players (either single players or teams of two) would depend on all factors: Investments should be\n\n\nlower in the short treatment (which would indicate myopia),\n\n\nhigher for teams (indicating a reduction in loss aversion),\n\n\nhigher for (teams with) male players,\n\n\nincrease with age/grade.\n\n\nSee Glätzle-Rützler et al. (2015) for more details and references to the literature. In their original analysis, the investments are analyzes using a panel structure (i.e., 9 separate investments for each team). Here, the data are averaged across rounds for each player, leading to qualitatively similar results. The full data along with replication materials are available in the Harvard Dataverse.\n\n\n\nGlätzle-Rützler D, Sutter M, Zeileis A (2020). Replication Data for: No Myopic Loss Aversion in Adolescents? - An Experimental Note. Harvard Dataverse, UNF:6:6hVtbHavJAFYfL7dDl7jqA==. doi:10.7910/DVN/IHFZAK\n\n\n\nGlätzle-Rützler D, Sutter M, Zeileis A (2015). No Myopic Loss Aversion in Adolescents? - An Experimental Note. Journal of Economic Behavior & Organization, 111, 169-176. doi:10.1016/j.jebo.2014.12.021\n\n\n\nbetareg\n\n\n\n\nlibrary(\"betareg\")\n\n## data for students in higher grades\ndata(\"LossAversion\", package = \"betareg\")\nLossAversion &lt;- subset(LossAversion, grade == \"10-12\")\n\n## ad hoc scaling (a la Smithson & Verkuilen)\nLossAversion$invests &lt;- ((LossAversion$invest * (nrow(LossAversion) - 1) + 0.5)/nrow(LossAversion))\n\n## fraction of boundary observations for ad hoc extended-support beta specification (xbeta)\np01 &lt;- mean(LossAversion$invest &lt;= 0 | LossAversion$invest &gt;= 1)\n\n## main effects models: Gaussian, beta, extended-support beta, extended-support beta mixture\nla_gr  &lt;- glm(invest      ~ arrangement + male + age,                      data = LossAversion)\nla_br  &lt;- betareg(invests ~ arrangement + male + age | arrangement + male, data = LossAversion)\nla_xbx &lt;- betareg(invest  ~ arrangement + male + age | arrangement + male, data = LossAversion)\nla_xb  &lt;- betareg(invest  ~ arrangement + male + age | arrangement + male, data = LossAversion,\n  dist = \"xbeta\", nu = p01/2)",
    "crumbs": [
      "Documentation",
      "Data sets",
      "LossAversion"
    ]
  },
  {
    "objectID": "man/GasolineYield.html",
    "href": "man/GasolineYield.html",
    "title": "betareg",
    "section": "",
    "text": "Operational data of the proportion of crude oil converted to gasoline after distillation and fractionation.\n\n\n\ndata(\"GasolineYield\")\n\n\n\nA data frame containing 32 observations on 6 variables.\n\n\nyield\n\n\nproportion of crude oil converted to gasoline after distillation and fractionation.\n\n\ngravity\n\n\ncrude oil gravity (degrees API).\n\n\npressure\n\n\nvapor pressure of crude oil (lbf/in2).\n\n\ntemp10\n\n\ntemperature (degrees F) at which 10 percent of crude oil has vaporized.\n\n\ntemp\n\n\ntemperature (degrees F) at which all gasoline has vaporized.\n\n\nbatch\n\n\nfactor indicating unique batch of conditions gravity, pressure, and temp10.\n\n\n\n\n\nThis dataset was collected by Prater (1956), its dependent variable is the proportion of crude oil after distillation and fractionation. This dataset was analyzed by Atkinson (1985), who used the linear regression model and noted that there is “indication that the error distribution is not quite symmetrical, giving rise to some unduly large and small residuals” (p. 60).\nThe dataset contains 32 observations on the response and on the independent variables. It has been noted (Daniel and Wood, 1971, Chapter 8) that there are only ten sets of values of the first three explanatory variables which correspond to ten different crudes and were subjected to experimentally controlled distillation conditions. These conditions are captured in variable batch and the data were ordered according to the ascending order of temp10.\n\n\n\nTaken from Prater (1956).\n\n\n\nAtkinson, A.C. (1985). Plots, Transformations and Regression: An Introduction to Graphical Methods of Diagnostic Regression Analysis. New York: Oxford University Press.\nCribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R. Journal of Statistical Software, 34(2), 1–24. doi:10.18637/jss.v034.i02\nDaniel, C., and Wood, F.S. (1971). Fitting Equations to Data. New York: John Wiley and Sons.\nFerrari, S.L.P., and Cribari-Neto, F. (2004). Beta Regression for Modeling Rates and Proportions. Journal of Applied Statistics, 31(7), 799–815.\nPrater, N.H. (1956). Estimate Gasoline Yields from Crudes. Petroleum Refiner, 35(5), 236–238.\n\n\n\nbetareg\n\n\n\n\nlibrary(\"betareg\")\n\n## IGNORE_RDIFF_BEGIN\ndata(\"GasolineYield\", package = \"betareg\")\n\ngy1 &lt;- betareg(yield ~ gravity + pressure + temp10 + temp, data = GasolineYield)\nsummary(gy1)\n\n\nCall:\nbetareg(formula = yield ~ gravity + pressure + temp10 + temp, data = GasolineYield)\n\nQuantile residuals:\n    Min      1Q  Median      3Q     Max \n-1.9010 -0.6829 -0.0385  0.5531  2.1314 \n\nCoefficients (mean model with logit link):\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -2.6949422  0.7625693  -3.534 0.000409 ***\ngravity      0.0045412  0.0071419   0.636 0.524871    \npressure     0.0304135  0.0281007   1.082 0.279117    \ntemp10      -0.0110449  0.0022640  -4.879 1.07e-06 ***\ntemp         0.0105650  0.0005154  20.499  &lt; 2e-16 ***\n\nPhi coefficients (precision model with identity link):\n      Estimate Std. Error z value Pr(&gt;|z|)    \n(phi)   248.24      62.02   4.003 6.26e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 75.68 on 6 Df\nPseudo R-squared: 0.9398\nNumber of iterations: 147 (BFGS) + 4 (Fisher scoring) \n\n## Ferrari and Cribari-Neto (2004)\ngy2 &lt;- betareg(yield ~ batch + temp, data = GasolineYield)\n## Table 1\nsummary(gy2)\n\n\nCall:\nbetareg(formula = yield ~ batch + temp, data = GasolineYield)\n\nQuantile residuals:\n    Min      1Q  Median      3Q     Max \n-2.1396 -0.5698  0.1202  0.7040  1.7506 \n\nCoefficients (mean model with logit link):\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -6.1595710  0.1823247 -33.784  &lt; 2e-16 ***\nbatch1       1.7277289  0.1012294  17.067  &lt; 2e-16 ***\nbatch2       1.3225969  0.1179020  11.218  &lt; 2e-16 ***\nbatch3       1.5723099  0.1161045  13.542  &lt; 2e-16 ***\nbatch4       1.0597141  0.1023598  10.353  &lt; 2e-16 ***\nbatch5       1.1337518  0.1035232  10.952  &lt; 2e-16 ***\nbatch6       1.0401618  0.1060365   9.809  &lt; 2e-16 ***\nbatch7       0.5436922  0.1091275   4.982 6.29e-07 ***\nbatch8       0.4959007  0.1089257   4.553 5.30e-06 ***\nbatch9       0.3857930  0.1185933   3.253  0.00114 ** \ntemp         0.0109669  0.0004126  26.577  &lt; 2e-16 ***\n\nPhi coefficients (precision model with identity link):\n      Estimate Std. Error z value Pr(&gt;|z|)    \n(phi)    440.3      110.0   4.002 6.29e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood:  84.8 on 12 Df\nPseudo R-squared: 0.9617\nNumber of iterations: 51 (BFGS) + 3 (Fisher scoring) \n\n## Figure 2\npar(mfrow = c(3, 2))\nplot(gy2, which = 1, type = \"pearson\", sub.caption = \"\")\nplot(gy2, which = 1, type = \"deviance\", sub.caption = \"\")\nplot(gy2, which = 5, type = \"deviance\", sub.caption = \"\")\nplot(gy2, which = 4, type = \"pearson\", sub.caption = \"\")\nplot(gy2, which = 2:3)\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\n## exclude 4th observation\ngy2a &lt;- update(gy2, subset = -4)\ngy2a\n\n\nCall:\nbetareg(formula = yield ~ batch + temp, data = GasolineYield, subset = -4)\n\nCoefficients (mean model with logit link):\n(Intercept)       batch1       batch2       batch3       batch4       batch5  \n   -6.35647      1.88688      1.37039      1.62512      1.08066      1.15158  \n     batch6       batch7       batch8       batch9         temp  \n    1.05766      0.56522      0.50066      0.38523      0.01146  \n\nPhi coefficients (precision model with identity link):\n(phi)  \n577.8  \n\nsummary(gy2a)\n\n\nCall:\nbetareg(formula = yield ~ batch + temp, data = GasolineYield, subset = -4)\n\nQuantile residuals:\n    Min      1Q  Median      3Q     Max \n-2.0153 -0.8176  0.0897  0.6948  2.0746 \n\nCoefficients (mean model with logit link):\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -6.3564713  0.1716020 -37.042  &lt; 2e-16 ***\nbatch1       1.8868782  0.1001837  18.834  &lt; 2e-16 ***\nbatch2       1.3703911  0.1042352  13.147  &lt; 2e-16 ***\nbatch3       1.6251199  0.1028326  15.804  &lt; 2e-16 ***\nbatch4       1.0806596  0.0897855  12.036  &lt; 2e-16 ***\nbatch5       1.1515826  0.0906857  12.699  &lt; 2e-16 ***\nbatch6       1.0576556  0.0929172  11.383  &lt; 2e-16 ***\nbatch7       0.5652219  0.0956100   5.912 3.39e-09 ***\nbatch8       0.5006625  0.0953210   5.252 1.50e-07 ***\nbatch9       0.3852258  0.1037500   3.713 0.000205 ***\ntemp         0.0114588  0.0003945  29.050  &lt; 2e-16 ***\n\nPhi coefficients (precision model with identity link):\n      Estimate Std. Error z value Pr(&gt;|z|)    \n(phi)    577.8      146.7   3.938 8.22e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 86.62 on 12 Df\nPseudo R-squared: 0.9662\nNumber of iterations: 51 (BFGS) + 4 (Fisher scoring) \n\n## IGNORE_RDIFF_END",
    "crumbs": [
      "Documentation",
      "Data sets",
      "GasolineYield"
    ]
  },
  {
    "objectID": "man/GasolineYield.html#estimation-of-gasoline-yields-from-crude-oil",
    "href": "man/GasolineYield.html#estimation-of-gasoline-yields-from-crude-oil",
    "title": "betareg",
    "section": "",
    "text": "Operational data of the proportion of crude oil converted to gasoline after distillation and fractionation.\n\n\n\ndata(\"GasolineYield\")\n\n\n\nA data frame containing 32 observations on 6 variables.\n\n\nyield\n\n\nproportion of crude oil converted to gasoline after distillation and fractionation.\n\n\ngravity\n\n\ncrude oil gravity (degrees API).\n\n\npressure\n\n\nvapor pressure of crude oil (lbf/in2).\n\n\ntemp10\n\n\ntemperature (degrees F) at which 10 percent of crude oil has vaporized.\n\n\ntemp\n\n\ntemperature (degrees F) at which all gasoline has vaporized.\n\n\nbatch\n\n\nfactor indicating unique batch of conditions gravity, pressure, and temp10.\n\n\n\n\n\nThis dataset was collected by Prater (1956), its dependent variable is the proportion of crude oil after distillation and fractionation. This dataset was analyzed by Atkinson (1985), who used the linear regression model and noted that there is “indication that the error distribution is not quite symmetrical, giving rise to some unduly large and small residuals” (p. 60).\nThe dataset contains 32 observations on the response and on the independent variables. It has been noted (Daniel and Wood, 1971, Chapter 8) that there are only ten sets of values of the first three explanatory variables which correspond to ten different crudes and were subjected to experimentally controlled distillation conditions. These conditions are captured in variable batch and the data were ordered according to the ascending order of temp10.\n\n\n\nTaken from Prater (1956).\n\n\n\nAtkinson, A.C. (1985). Plots, Transformations and Regression: An Introduction to Graphical Methods of Diagnostic Regression Analysis. New York: Oxford University Press.\nCribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R. Journal of Statistical Software, 34(2), 1–24. doi:10.18637/jss.v034.i02\nDaniel, C., and Wood, F.S. (1971). Fitting Equations to Data. New York: John Wiley and Sons.\nFerrari, S.L.P., and Cribari-Neto, F. (2004). Beta Regression for Modeling Rates and Proportions. Journal of Applied Statistics, 31(7), 799–815.\nPrater, N.H. (1956). Estimate Gasoline Yields from Crudes. Petroleum Refiner, 35(5), 236–238.\n\n\n\nbetareg\n\n\n\n\nlibrary(\"betareg\")\n\n## IGNORE_RDIFF_BEGIN\ndata(\"GasolineYield\", package = \"betareg\")\n\ngy1 &lt;- betareg(yield ~ gravity + pressure + temp10 + temp, data = GasolineYield)\nsummary(gy1)\n\n\nCall:\nbetareg(formula = yield ~ gravity + pressure + temp10 + temp, data = GasolineYield)\n\nQuantile residuals:\n    Min      1Q  Median      3Q     Max \n-1.9010 -0.6829 -0.0385  0.5531  2.1314 \n\nCoefficients (mean model with logit link):\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -2.6949422  0.7625693  -3.534 0.000409 ***\ngravity      0.0045412  0.0071419   0.636 0.524871    \npressure     0.0304135  0.0281007   1.082 0.279117    \ntemp10      -0.0110449  0.0022640  -4.879 1.07e-06 ***\ntemp         0.0105650  0.0005154  20.499  &lt; 2e-16 ***\n\nPhi coefficients (precision model with identity link):\n      Estimate Std. Error z value Pr(&gt;|z|)    \n(phi)   248.24      62.02   4.003 6.26e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 75.68 on 6 Df\nPseudo R-squared: 0.9398\nNumber of iterations: 147 (BFGS) + 4 (Fisher scoring) \n\n## Ferrari and Cribari-Neto (2004)\ngy2 &lt;- betareg(yield ~ batch + temp, data = GasolineYield)\n## Table 1\nsummary(gy2)\n\n\nCall:\nbetareg(formula = yield ~ batch + temp, data = GasolineYield)\n\nQuantile residuals:\n    Min      1Q  Median      3Q     Max \n-2.1396 -0.5698  0.1202  0.7040  1.7506 \n\nCoefficients (mean model with logit link):\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -6.1595710  0.1823247 -33.784  &lt; 2e-16 ***\nbatch1       1.7277289  0.1012294  17.067  &lt; 2e-16 ***\nbatch2       1.3225969  0.1179020  11.218  &lt; 2e-16 ***\nbatch3       1.5723099  0.1161045  13.542  &lt; 2e-16 ***\nbatch4       1.0597141  0.1023598  10.353  &lt; 2e-16 ***\nbatch5       1.1337518  0.1035232  10.952  &lt; 2e-16 ***\nbatch6       1.0401618  0.1060365   9.809  &lt; 2e-16 ***\nbatch7       0.5436922  0.1091275   4.982 6.29e-07 ***\nbatch8       0.4959007  0.1089257   4.553 5.30e-06 ***\nbatch9       0.3857930  0.1185933   3.253  0.00114 ** \ntemp         0.0109669  0.0004126  26.577  &lt; 2e-16 ***\n\nPhi coefficients (precision model with identity link):\n      Estimate Std. Error z value Pr(&gt;|z|)    \n(phi)    440.3      110.0   4.002 6.29e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood:  84.8 on 12 Df\nPseudo R-squared: 0.9617\nNumber of iterations: 51 (BFGS) + 3 (Fisher scoring) \n\n## Figure 2\npar(mfrow = c(3, 2))\nplot(gy2, which = 1, type = \"pearson\", sub.caption = \"\")\nplot(gy2, which = 1, type = \"deviance\", sub.caption = \"\")\nplot(gy2, which = 5, type = \"deviance\", sub.caption = \"\")\nplot(gy2, which = 4, type = \"pearson\", sub.caption = \"\")\nplot(gy2, which = 2:3)\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\n## exclude 4th observation\ngy2a &lt;- update(gy2, subset = -4)\ngy2a\n\n\nCall:\nbetareg(formula = yield ~ batch + temp, data = GasolineYield, subset = -4)\n\nCoefficients (mean model with logit link):\n(Intercept)       batch1       batch2       batch3       batch4       batch5  \n   -6.35647      1.88688      1.37039      1.62512      1.08066      1.15158  \n     batch6       batch7       batch8       batch9         temp  \n    1.05766      0.56522      0.50066      0.38523      0.01146  \n\nPhi coefficients (precision model with identity link):\n(phi)  \n577.8  \n\nsummary(gy2a)\n\n\nCall:\nbetareg(formula = yield ~ batch + temp, data = GasolineYield, subset = -4)\n\nQuantile residuals:\n    Min      1Q  Median      3Q     Max \n-2.0153 -0.8176  0.0897  0.6948  2.0746 \n\nCoefficients (mean model with logit link):\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -6.3564713  0.1716020 -37.042  &lt; 2e-16 ***\nbatch1       1.8868782  0.1001837  18.834  &lt; 2e-16 ***\nbatch2       1.3703911  0.1042352  13.147  &lt; 2e-16 ***\nbatch3       1.6251199  0.1028326  15.804  &lt; 2e-16 ***\nbatch4       1.0806596  0.0897855  12.036  &lt; 2e-16 ***\nbatch5       1.1515826  0.0906857  12.699  &lt; 2e-16 ***\nbatch6       1.0576556  0.0929172  11.383  &lt; 2e-16 ***\nbatch7       0.5652219  0.0956100   5.912 3.39e-09 ***\nbatch8       0.5006625  0.0953210   5.252 1.50e-07 ***\nbatch9       0.3852258  0.1037500   3.713 0.000205 ***\ntemp         0.0114588  0.0003945  29.050  &lt; 2e-16 ***\n\nPhi coefficients (precision model with identity link):\n      Estimate Std. Error z value Pr(&gt;|z|)    \n(phi)    577.8      146.7   3.938 8.22e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 86.62 on 12 Df\nPseudo R-squared: 0.9662\nNumber of iterations: 51 (BFGS) + 4 (Fisher scoring) \n\n## IGNORE_RDIFF_END",
    "crumbs": [
      "Documentation",
      "Data sets",
      "GasolineYield"
    ]
  },
  {
    "objectID": "NEWS.html",
    "href": "NEWS.html",
    "title": "betareg 3.2-0",
    "section": "",
    "text": "betareg 3.2-0\n\nMajor extension in betareg(): In addition to classic beta regression for responses in the open interval (0, 1), extended-support beta regression is added which can model responses in the closed interval [0, 1] (i.e., including boundary observations at 0 and/or 1). This is accomplished by adding two new response distributions: The extended-support beta distribution (\"xbeta\") leverages an underlying symmetric four-parameter beta distribution with exceedence parameter nu to obtain support [-nu, 1 + nu] that is subsequently censored to [0, 1] in order to obtain point masses at the boundary values 0 and 1. The extended-support beta mixture distribution (\"xbetax\") is a continuous mixture of extended-support beta distributions where the exceedence parameter follows an exponential distribution with mean nu (rather than a fixed value of nu). The latter \"xbetax\" specification is used by default in case of boundary observations at 0 and/or 1. The \"xbeta\" specification with fixed nu is mostly for testing and debugging purposes.\nQuantile residuals are added to the residuals() method for betareg objects. They are easy to compute and have good distributional properties. Hence, they are the new default residuals.\nBug fix in pseudo.r.squared computation for weighted models where previously the weights were erroneously ignored (reported by Ray Tayek).\nBug fixes in betatree(): Split points were computed incorrectly due to wrong sign of the log-likelihood (reported by Se-Wan Jeong). And trees with only intercepts for both mu and phi could not be fitted (reported by Ludwig Hothorn).\n\n\n\nbetareg 3.1-4\n\nIn betatree() the \"xlevels\" attribute from partykit::mob is now correctly stored in $levels (rather than $xlevels) of the returned object.\n\n\n\nbetareg 3.1-3\n\nAdded IGNORE_RDIFF flags in some examples in order to avoid showing diffs due to small numeric deviations in some checks (especially on CRAN).\n\n\n\nbetareg 3.1-2\n\nAdded suppressWarnings(RNGversion(\"3.5.0\")) in those places where set.seed() was used to assure exactly reproducible results from R 3.6.0 onwards.\n\n\n\nbetareg 3.1-1\n\nConditional registration of sctest() method for betatree objects when strucchange package is loaded.\n\n\n\nbetareg 3.1-0\n\nThe betatree() function now uses the new mob() implementation from the partykit package (instead of the old party package). The user interface essentially remained the same but now many more options are available through the new mob() function. The returned model object is now inheriting from modelparty/party.\nIncluded grDevices in Imports.\nFixed model.frame() method for betareg objects which do not store the model frame in $model.\nbetamix() gained arguments weights (case weights for observations) and offset (for the mean linear predictor).\n\n\n\nbetareg 3.0-5\n\nThe Formula package is now only in Imports but not Depends (see below).\nMethod FLXgetModelmatrix for FLXMRbeta objects modified due to changes in flexmix 2.3.12.\n\n\n\nbetareg 3.0-4\n\nFor some datasets betareg() would just “hang” because dbeta() “hangs” for certain extreme parameter combinations (in current R versions). betareg() now tries to catch these cases in order to avoid the problem.\nDepends/Imports/Suggests have been rearranged to conform with current CRAN check policies. This is the last version of betareg to have the Formula package in Depends - from the next version onwards it will only be in Imports.\n\n\n\nbetareg 3.0-3\n\nThe predict() method gained support for type = \"quantile\", so that quantiles of the response distribution can be predicted.\nThe Formula package is now not only in the list of dependencies but is also imported in the NAMESPACE, in order to facilitate importing betareg in other packages.\n\n\n\nbetareg 3.0-2\n\nAvoid .Call()-ing logit link functions directly, instead use elements of make.link(\"logit\").\n\n\n\nbetareg 3.0-1\n\nSmall consistency updates in labeling coefficients for current R-devel.\n\n\n\nbetareg 3.0-0\n\nNew release accompanying the second JSS paper: “Extended Beta Regression in R: Shaken, Stirred, Mixed, and Partitioned” by Gruen, Kosmidis, and Zeileis which appears as Journal of Statistical Software 48(11). See also citation(\"betareg\"). The paper presents the recently introduced features: bias correction/reduction in betareg(), recursive partitioning via betatree(), and finite mixture modeling via betamix(). See also vignette(\"betareg-ext\",   package = \"betareg\") for the vignette version within the package.\n\n\n\nbetareg 2.4-1\n\nFormula interface for betamix() changed to allow for three parts in the right hand side where the third part relates to the concomitant variables.\nModified the internal structure of vignettes/tests. The original vignettes are now moved to the vignettes directory, containing also .Rout.save files. Similarly, an .Rout.save for the examples is added in the tests directory.\n\n\n\nbetareg 2.4-0\n\nSupport bias-corrected (BC) and bias-reduced (BR) maximum likelihood estimation of beta regressions. See the type argument of betareg(). To enable BC/BR, an additional Fisher scoring iteration was added that (by default) also enhances the usual ML results.\nNew vignette(\"betareg-ext\", package = \"betareg\") introducing BC/BR estimation along with the recent additions beta regression trees and latent class beta regression (aka finite mixture beta regression models).\nEnabled fitting of beta regression models without coefficients in the mean equation.\nEnabled usage of offsets in both parts of the model, i.e., one can use betareg(y ~ x + offset(o1) | z + offset(o2)) which is also equivalent to betareg(y ~ x | z + offset(o2), offset = o1), i.e., the offset argument of betareg is employed for the mean equation only. Consequently, betareg_object$offset is now a list with two elements (mean/precision).\nAdded warning and ad-hoc workaround in the starting value selection of betareg.fit() for the precision model. If no valid starting value can be obtained, a warning is issued and c(1, 0, ..., 0) is employed.\nAdded betareg_object$nobs in the return object containing the number of observations with non-zero weights. Then nobs() can be used to extract this and consequently BIC() can be used to compute the BIC.\n\n\n\nbetareg 2.3-0\n\nNew betatree() function for beta regression trees based on model-based recursive partitioning. betatree() leverages the mob() function from the party package. For enabling this plug-in, a StatModel constructor betaReg() is provided based on the modeltools package.\nNew betamix() function for latent class beta regression, or finite mixture beta regression models. betamix() leverages the flexmix() function from the flexmix package. For enabling this plug-in, the driver FLXMRbeta() is provided.\nAdded tests/vignette-betareg.R based on the models fitted in vignette(\"betareg\", package = \"betareg\").\n\n\n\nbetareg 2.2-3\n\nThe \"levels\" element of a betareg object is now a list with components \"mean\", \"precision\", and \"full\" to match the \"terms\" of the object.\nImproved data handling bug in predict() method.\n\n\n\nbetareg 2.2-2\n\nDocumentation updates for ?gleverage.\n\n\n\nbetareg 2.2-1\n\nPackage now published in Journal of Statistical Software, see https://www.jstatsoft.org/v34/i02/ and citation(\"betareg\") within R.\nBug fix and improvements in gleverage() method for betareg objects: Analytic second derivatives are now used and variable dispersion models are handled correctly.\n\n\n\nbetareg 2.2-0\n\ndbeta(..., log = TRUE) is now used for computing the log-likelihood which is numerically more stable than the previous hand-crafted version.\nThe starting values in the dispersion regression are now chosen differently, resulting in a somewhat more robust specification of starting values. The intercept is computed as described in Ferrari & Cribari-Neto (2004), plus a link transformation (if any). All further parameters (if any) are initially set to zero. See also the vignette for details.\nVarious documentation improvements, especially in the vignette.\n\n\n\nbetareg 2.1-2\n\nNew vignette (written by Francisco Cribari-Neto and Z)\nintroducing the package and replicating a range of publications related to beta regression: vignette(\"betareg\", package = \"betareg\") provides some theoretical background, a discussion of the implementation and several hands-on examples.\nImplemented an optional precision model, yielding variable dispersion. The precision parameter phi may depend on a linear predictor, as suggested by Simas, Barreto-Souza, and Rocha (2010). In single part formulas of type y ~ x1 + x2, phi is by default assumed to be constant, i.e., an intercept plus identity link. But it can be extended to y ~ x1 + x2 | z1 + z2 where phi depends on z1 + z2, by default through a log link.\nAllowed all link functions (in mean model) that are available in make.link() for binary responses, and added log-log link.\nAdded data and replication code for Smithson & Verkuilen (2006, Psychological Methods). See ?ReadingSkills, ?MockJurors, ?StressAnxiety as well as the complete replication code in demo(\"SmithsonVerkuilen2006\").\nDefault in residuals() (as well as in the related plot() and summary() components) is now to use standardized weighted residuals 2 (type = \"sweighted2\").\n\n\n\nbetareg 2.0-0\n\nPackage betareg was orphaned on CRAN, Z took over as maintainer, ended up re-writing the whole package. The package still provides all functionality as before but the interface is not fully backward-compatible.\nbetareg(): More standard formula-interface arguments; betareg objects do not inherit from lm anymore.\nbetareg.fit(): Renamed from br.fit(), enhanced interface with more arguments and returned information. Untested support of weighted regressions is enabled.\nbetareg.control(): New function encapsulating control of optim(), slightly modified default values.\nanova() method was removed, use lrtest() from lmtest package instead.\ngen.lev.betareg() was changed to gleverage() method (with new generic) and a bug in the method was fixed.\nenvelope.beta() was removed and is now included in plot() method for betareg objects.\nDatasets prater and pratergrouped were incorporated into a single GasolineYield dataset.\nNew data set FoodExpenditure from Griffiths et al. (1993), replicating second application from Ferrari and Cribari-Neto (2004).\nAdded NAMESPACE.\nThe residuals() method now has three further types of residuals suggested by Espinheira et al. (2008) who recommend to use “standardized weighted residuals 2” (type = \"sweighted2\"). The default are Pearson (aka standardized) residuals."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "To report bugs please send a simple e-mail to the package maintainer: &lt;Achim.Zeileis at R-project.org&gt;\nFor discussions we also try to follow these channels:\n\nStackOverflow with betareg tag\nCrossValidated with beta-regression tag\nR-help mailing list\n\n\n\n\n\nAchim Zeileis  🌐\nFrancisco Cribari-Neto  🌐\nBettina Grün  🌐\nIoannis Kosmidis  🌐"
  },
  {
    "objectID": "contact.html#reporting-bugs",
    "href": "contact.html#reporting-bugs",
    "title": "Contact",
    "section": "",
    "text": "To report bugs please send a simple e-mail to the package maintainer: &lt;Achim.Zeileis at R-project.org&gt;\nFor discussions we also try to follow these channels:\n\nStackOverflow with betareg tag\nCrossValidated with beta-regression tag\nR-help mailing list"
  },
  {
    "objectID": "contact.html#authors",
    "href": "contact.html#authors",
    "title": "Contact",
    "section": "",
    "text": "Achim Zeileis  🌐\nFrancisco Cribari-Neto  🌐\nBettina Grün  🌐\nIoannis Kosmidis  🌐"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "betareg: Beta Regression in R",
    "section": "",
    "text": "Beta regression for modeling beta-distributed dependent variables on the open unit interval (0, 1), e.g., rates and proportions, see Cribari-Neto and Zeileis (2010, doi:10.18637/jss.v034.i02).\nExtended-support beta regression models for variables on the closed unit interval [0, 1] with boundary observations at 0 and/or 1 see Kosmidis and Zeileis (2024, forthcoming).\nAlternative specifications of the classical beta regression model: Bias-corrected and bias-reduced estimation, finite mixture models, and recursive partitioning for (0, 1) beta regression, see Grün, Kosmidis, and Zeileis (2012, doi:10.18637/jss.v048.i11).\n\n\n\n\nThe stable version of betareg is available on CRAN:\ninstall.packages(\"betareg\")\nThe latest development version can be installed from R-universe:\ninstall.packages(\"betareg\", repos = \"https://zeileis.R-universe.dev\")\n\n\n\nA nice first illustration of beta regression is the analysis of reading accuracy scores from primary school children from Smithson & Verkuilen (2006). Package and data can be loaded via:\n\nlibrary(\"betareg\")\ndata(\"ReadingSkills\", package = \"betareg\")\n\nThe reading accuracy was scaled to be within (0, 1). Its mean is explained by verbal iq score with separate lines by dyslexia (control vs. dyslexic). The precision parameter is explained by main effects of the two explanatory variables. More details are provided in ?ReadingSkills.\n\nbr &lt;- betareg(accuracy ~ dyslexia * iq | dyslexia + iq, data = ReadingSkills)\nsummary(br)\n#&gt; \n#&gt; Call:\n#&gt; betareg(formula = accuracy ~ dyslexia * iq | dyslexia + iq, data = ReadingSkills)\n#&gt; \n#&gt; Quantile residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -2.3625 -0.5872  0.3026  0.9425  1.5874 \n#&gt; \n#&gt; Coefficients (mean model with logit link):\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)   1.1232     0.1428   7.864 3.73e-15 ***\n#&gt; dyslexia     -0.7416     0.1428  -5.195 2.04e-07 ***\n#&gt; iq            0.4864     0.1331   3.653 0.000259 ***\n#&gt; dyslexia:iq  -0.5813     0.1327  -4.381 1.18e-05 ***\n#&gt; \n#&gt; Phi coefficients (precision model with log link):\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)   3.3044     0.2227  14.835  &lt; 2e-16 ***\n#&gt; dyslexia      1.7466     0.2623   6.658 2.77e-11 ***\n#&gt; iq            1.2291     0.2672   4.600 4.23e-06 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n#&gt; \n#&gt; Type of estimator: ML (maximum likelihood)\n#&gt; Log-likelihood:  65.9 on 7 Df\n#&gt; Pseudo R-squared: 0.5756\n#&gt; Number of iterations: 25 (BFGS) + 1 (Fisher scoring)\n\nThe regression summary shows that accuracy increases with iq for the control group but not for the dyslexic group (even slightly decreases). This can be brought out more clearly graphically. This also highlights that the model employs a logit link so that the fitted curves always remain within (0, 1).\n\npal &lt;- palette.colors()[c(4, 8)]\npch &lt;- c(19, 17)\nplot(accuracy ~ iq, data = ReadingSkills, col = pal[dyslexia], pch = pch[dyslexia])\niq &lt;- -30:30/10\nlines(iq, predict(br, newdata = data.frame(dyslexia = \"no\", iq = iq)), col = pal[1], lwd = 2)\nlines(iq, predict(br, newdata = data.frame(dyslexia = \"yes\", iq = iq)), col = pal[2], lwd = 2)\nlegend(\"topleft\", c(\"Control\", \"Dyslexic\"), pch = pch, col = pal, bty = \"n\")\n\n\n\n\n\n\n\n\n\n\n\nFor going beyond this basic analysis the following extensions can be considered.\n\n\nBias-reduced estimation (instead of the default maximum likelihood estimation) can be used by adding the argument type = \"BR\" in betareg(). This slightly shrinks all coefficient estimates but leads to qualitatively identical results.\n\nbetareg(accuracy ~ dyslexia * iq | dyslexia + iq, data = ReadingSkills, type = \"BR\")\n\n\n\n\nTo analyze the original accuracy scores in [0, 1] (without scaling the perfect scores of 1 to 0.99) use the variable accuracy1 in the code above. The betareg() model then estimates an additional exceedence parameter that accounts for the boundary probability of a perfect score.\n\nbetareg(accuracy1 ~ dyslexia * iq | dyslexia + iq, data = ReadingSkills)\n\n\n\n\nTo find subgroups in a beta regression by recursively splitting subsamples (rather than fixing the dyslexia interaction in advance), beta regression trees can be used:\n\nbetatree(accuracy ~ iq | iq, ~ dyslexia + ..., data = ReadingSkills, minsize = 10)\n\nSee the documentation of betatree() for more details.\n\n\n\nTo find clusters in a beta regression (without even having the dyslexia information), finite mixtures of beta regressions can be used:\n\nbetamix(accuracy ~ iq, data = ReadingSkills, k = 3, ...)\n\nSee the documentation of betamix() for more details."
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "betareg: Beta Regression in R",
    "section": "",
    "text": "Beta regression for modeling beta-distributed dependent variables on the open unit interval (0, 1), e.g., rates and proportions, see Cribari-Neto and Zeileis (2010, doi:10.18637/jss.v034.i02).\nExtended-support beta regression models for variables on the closed unit interval [0, 1] with boundary observations at 0 and/or 1 see Kosmidis and Zeileis (2024, forthcoming).\nAlternative specifications of the classical beta regression model: Bias-corrected and bias-reduced estimation, finite mixture models, and recursive partitioning for (0, 1) beta regression, see Grün, Kosmidis, and Zeileis (2012, doi:10.18637/jss.v048.i11)."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "betareg: Beta Regression in R",
    "section": "",
    "text": "The stable version of betareg is available on CRAN:\ninstall.packages(\"betareg\")\nThe latest development version can be installed from R-universe:\ninstall.packages(\"betareg\", repos = \"https://zeileis.R-universe.dev\")"
  },
  {
    "objectID": "index.html#illustration",
    "href": "index.html#illustration",
    "title": "betareg: Beta Regression in R",
    "section": "",
    "text": "A nice first illustration of beta regression is the analysis of reading accuracy scores from primary school children from Smithson & Verkuilen (2006). Package and data can be loaded via:\n\nlibrary(\"betareg\")\ndata(\"ReadingSkills\", package = \"betareg\")\n\nThe reading accuracy was scaled to be within (0, 1). Its mean is explained by verbal iq score with separate lines by dyslexia (control vs. dyslexic). The precision parameter is explained by main effects of the two explanatory variables. More details are provided in ?ReadingSkills.\n\nbr &lt;- betareg(accuracy ~ dyslexia * iq | dyslexia + iq, data = ReadingSkills)\nsummary(br)\n#&gt; \n#&gt; Call:\n#&gt; betareg(formula = accuracy ~ dyslexia * iq | dyslexia + iq, data = ReadingSkills)\n#&gt; \n#&gt; Quantile residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -2.3625 -0.5872  0.3026  0.9425  1.5874 \n#&gt; \n#&gt; Coefficients (mean model with logit link):\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)   1.1232     0.1428   7.864 3.73e-15 ***\n#&gt; dyslexia     -0.7416     0.1428  -5.195 2.04e-07 ***\n#&gt; iq            0.4864     0.1331   3.653 0.000259 ***\n#&gt; dyslexia:iq  -0.5813     0.1327  -4.381 1.18e-05 ***\n#&gt; \n#&gt; Phi coefficients (precision model with log link):\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)   3.3044     0.2227  14.835  &lt; 2e-16 ***\n#&gt; dyslexia      1.7466     0.2623   6.658 2.77e-11 ***\n#&gt; iq            1.2291     0.2672   4.600 4.23e-06 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n#&gt; \n#&gt; Type of estimator: ML (maximum likelihood)\n#&gt; Log-likelihood:  65.9 on 7 Df\n#&gt; Pseudo R-squared: 0.5756\n#&gt; Number of iterations: 25 (BFGS) + 1 (Fisher scoring)\n\nThe regression summary shows that accuracy increases with iq for the control group but not for the dyslexic group (even slightly decreases). This can be brought out more clearly graphically. This also highlights that the model employs a logit link so that the fitted curves always remain within (0, 1).\n\npal &lt;- palette.colors()[c(4, 8)]\npch &lt;- c(19, 17)\nplot(accuracy ~ iq, data = ReadingSkills, col = pal[dyslexia], pch = pch[dyslexia])\niq &lt;- -30:30/10\nlines(iq, predict(br, newdata = data.frame(dyslexia = \"no\", iq = iq)), col = pal[1], lwd = 2)\nlines(iq, predict(br, newdata = data.frame(dyslexia = \"yes\", iq = iq)), col = pal[2], lwd = 2)\nlegend(\"topleft\", c(\"Control\", \"Dyslexic\"), pch = pch, col = pal, bty = \"n\")"
  },
  {
    "objectID": "index.html#extended-models",
    "href": "index.html#extended-models",
    "title": "betareg: Beta Regression in R",
    "section": "",
    "text": "For going beyond this basic analysis the following extensions can be considered.\n\n\nBias-reduced estimation (instead of the default maximum likelihood estimation) can be used by adding the argument type = \"BR\" in betareg(). This slightly shrinks all coefficient estimates but leads to qualitatively identical results.\n\nbetareg(accuracy ~ dyslexia * iq | dyslexia + iq, data = ReadingSkills, type = \"BR\")\n\n\n\n\nTo analyze the original accuracy scores in [0, 1] (without scaling the perfect scores of 1 to 0.99) use the variable accuracy1 in the code above. The betareg() model then estimates an additional exceedence parameter that accounts for the boundary probability of a perfect score.\n\nbetareg(accuracy1 ~ dyslexia * iq | dyslexia + iq, data = ReadingSkills)\n\n\n\n\nTo find subgroups in a beta regression by recursively splitting subsamples (rather than fixing the dyslexia interaction in advance), beta regression trees can be used:\n\nbetatree(accuracy ~ iq | iq, ~ dyslexia + ..., data = ReadingSkills, minsize = 10)\n\nSee the documentation of betatree() for more details.\n\n\n\nTo find clusters in a beta regression (without even having the dyslexia information), finite mixtures of beta regressions can be used:\n\nbetamix(accuracy ~ iq, data = ReadingSkills, k = 3, ...)\n\nSee the documentation of betamix() for more details."
  },
  {
    "objectID": "CITATION.html",
    "href": "CITATION.html",
    "title": "Citation",
    "section": "",
    "text": "Citation\nTo cite betareg in publications use:\n\nCribari-Neto F, Zeileis A (2010). “Beta Regression in R.” Journal of Statistical Software, 34(2), 1–24. doi:10.18637/jss.v034.i02.\n\nIf you use betatree(), betamix(), or bias correction/reduction in betareg(), please cite:\n\nGrün B, Kosmidis I, Zeileis A (2012). “Extended Beta Regression in R: Shaken, Stirred, Mixed, and Partitioned.” Journal of Statistical Software, 48(11), 1–25. doi:10.18637/jss.v048.i11."
  },
  {
    "objectID": "man/BetaR.html",
    "href": "man/BetaR.html",
    "title": "betareg",
    "section": "",
    "text": "Class and methods for beta distributions in regression specification using the workflow from the distributions3 package.\n\n\n\nBetaR(mu, phi)\n\n\n\n\n\n\n\nmu\n\n\nnumeric. The mean of the beta distribution.\n\n\n\n\nphi\n\n\nnumeric. The precision parameter of the beta distribution.\n\n\n\n\n\n\nAlternative parameterization of the classic beta distribution in terms of its mean mu and precision parameter phi. Thus, the distribution provided by BetaR is equivalent to the Beta distribution with parameters alpha = mu * phi and beta = (1 - mu) * phi.\n\n\n\nA BetaR distribution object.\n\n\n\ndbetar, Beta\n\n\n\n\nlibrary(\"betareg\")\n\n\n## package and random seed\nlibrary(\"distributions3\")\nset.seed(6020)\n\n## three beta distributions\nX &lt;- BetaR(\n  mu  = c(0.25, 0.50, 0.75),\n  phi = c(1, 1, 2)\n)\nX\n\n[1] \"BetaR(mu = 0.25, phi = 1)\" \"BetaR(mu = 0.50, phi = 1)\"\n[3] \"BetaR(mu = 0.75, phi = 2)\"\n\n## compute moments of the distribution\nmean(X)\n\n[1] 0.25 0.50 0.75\n\nvariance(X)\n\n[1] 0.09375 0.12500 0.06250\n\nskewness(X)\n\n[1] -0.1666667 -1.5000000  0.0000000\n\nkurtosis(X)\n\n[1] -0.1666667 -1.5000000  0.0000000\n\n## support interval (minimum and maximum)\nsupport(X)\n\n     min max\n[1,]   0   1\n[2,]   0   1\n[3,]   0   1\n\n## simulate random variables\nrandom(X, 5)\n\n           r_1       r_2         r_3       r_4        r_5\n[1,] 0.7497152 0.8385523 0.031967958 0.9188288 0.54543668\n[2,] 0.1886452 0.9982310 0.004743561 0.1429292 0.07917131\n[3,] 0.9569594 0.9906614 0.757365599 0.9186620 0.84031674\n\n## histograms of 1,000 simulated observations\nx &lt;- random(X, 1000)\nhist(x[1, ])\n\n\n\n\n\n\n\nhist(x[2, ])\n\n\n\n\n\n\n\nhist(x[3, ])\n\n\n\n\n\n\n\n## probability density function (PDF) and log-density (or log-likelihood)\nx &lt;- c(0.25, 0.5, 0.75)\npdf(X, x)\n\n[1] 0.6840925 0.6366198 1.1026578\n\npdf(X, x, log = TRUE)\n\n[1] -0.37966219 -0.45158271  0.09772344\n\nlog_pdf(X, x)\n\n[1] -0.37966219 -0.45158271  0.09772344\n\n## cumulative distribution function (CDF)\ncdf(X, x)\n\n[1] 0.6453748 0.5000000 0.3910022\n\n## quantiles\nquantile(X, 0.5)\n\n[1] 0.09331223 0.50000000 0.83680601\n\n## cdf() and quantile() are inverses (except at censoring points)\ncdf(X, quantile(X, 0.5))\n\n[1] 0.5 0.5 0.5\n\nquantile(X, cdf(X, 1))\n\n[1] 1 1 1\n\n## all methods above can either be applied elementwise or for\n## all combinations of X and x, if length(X) = length(x),\n## also the result can be assured to be a matrix via drop = FALSE\np &lt;- c(0.05, 0.5, 0.95)\nquantile(X, p, elementwise = FALSE)\n\n           q_0.05      q_0.5    q_0.95\n[1,] 9.512588e-06 0.09331223 0.9118445\n[2,] 6.155830e-03 0.50000000 0.9938442\n[3,] 2.285198e-01 0.83680601 0.9984571\n\nquantile(X, p, elementwise = TRUE)\n\n[1] 9.512588e-06 5.000000e-01 9.984571e-01\n\nquantile(X, p, elementwise = TRUE, drop = FALSE)\n\n         quantile\n[1,] 9.512588e-06\n[2,] 5.000000e-01\n[3,] 9.984571e-01\n\n## compare theoretical and empirical mean from 1,000 simulated observations\ncbind(\n  \"theoretical\" = mean(X),\n  \"empirical\" = rowMeans(random(X, 1000))\n)\n\n     theoretical empirical\n[1,]        0.25 0.2464581\n[2,]        0.50 0.4941967\n[3,]        0.75 0.7542970",
    "crumbs": [
      "Documentation",
      "distributions3 objects",
      "BetaR"
    ]
  },
  {
    "objectID": "man/BetaR.html#create-a-beta-regression-distribution",
    "href": "man/BetaR.html#create-a-beta-regression-distribution",
    "title": "betareg",
    "section": "",
    "text": "Class and methods for beta distributions in regression specification using the workflow from the distributions3 package.\n\n\n\nBetaR(mu, phi)\n\n\n\n\n\n\n\nmu\n\n\nnumeric. The mean of the beta distribution.\n\n\n\n\nphi\n\n\nnumeric. The precision parameter of the beta distribution.\n\n\n\n\n\n\nAlternative parameterization of the classic beta distribution in terms of its mean mu and precision parameter phi. Thus, the distribution provided by BetaR is equivalent to the Beta distribution with parameters alpha = mu * phi and beta = (1 - mu) * phi.\n\n\n\nA BetaR distribution object.\n\n\n\ndbetar, Beta\n\n\n\n\nlibrary(\"betareg\")\n\n\n## package and random seed\nlibrary(\"distributions3\")\nset.seed(6020)\n\n## three beta distributions\nX &lt;- BetaR(\n  mu  = c(0.25, 0.50, 0.75),\n  phi = c(1, 1, 2)\n)\nX\n\n[1] \"BetaR(mu = 0.25, phi = 1)\" \"BetaR(mu = 0.50, phi = 1)\"\n[3] \"BetaR(mu = 0.75, phi = 2)\"\n\n## compute moments of the distribution\nmean(X)\n\n[1] 0.25 0.50 0.75\n\nvariance(X)\n\n[1] 0.09375 0.12500 0.06250\n\nskewness(X)\n\n[1] -0.1666667 -1.5000000  0.0000000\n\nkurtosis(X)\n\n[1] -0.1666667 -1.5000000  0.0000000\n\n## support interval (minimum and maximum)\nsupport(X)\n\n     min max\n[1,]   0   1\n[2,]   0   1\n[3,]   0   1\n\n## simulate random variables\nrandom(X, 5)\n\n           r_1       r_2         r_3       r_4        r_5\n[1,] 0.7497152 0.8385523 0.031967958 0.9188288 0.54543668\n[2,] 0.1886452 0.9982310 0.004743561 0.1429292 0.07917131\n[3,] 0.9569594 0.9906614 0.757365599 0.9186620 0.84031674\n\n## histograms of 1,000 simulated observations\nx &lt;- random(X, 1000)\nhist(x[1, ])\n\n\n\n\n\n\n\nhist(x[2, ])\n\n\n\n\n\n\n\nhist(x[3, ])\n\n\n\n\n\n\n\n## probability density function (PDF) and log-density (or log-likelihood)\nx &lt;- c(0.25, 0.5, 0.75)\npdf(X, x)\n\n[1] 0.6840925 0.6366198 1.1026578\n\npdf(X, x, log = TRUE)\n\n[1] -0.37966219 -0.45158271  0.09772344\n\nlog_pdf(X, x)\n\n[1] -0.37966219 -0.45158271  0.09772344\n\n## cumulative distribution function (CDF)\ncdf(X, x)\n\n[1] 0.6453748 0.5000000 0.3910022\n\n## quantiles\nquantile(X, 0.5)\n\n[1] 0.09331223 0.50000000 0.83680601\n\n## cdf() and quantile() are inverses (except at censoring points)\ncdf(X, quantile(X, 0.5))\n\n[1] 0.5 0.5 0.5\n\nquantile(X, cdf(X, 1))\n\n[1] 1 1 1\n\n## all methods above can either be applied elementwise or for\n## all combinations of X and x, if length(X) = length(x),\n## also the result can be assured to be a matrix via drop = FALSE\np &lt;- c(0.05, 0.5, 0.95)\nquantile(X, p, elementwise = FALSE)\n\n           q_0.05      q_0.5    q_0.95\n[1,] 9.512588e-06 0.09331223 0.9118445\n[2,] 6.155830e-03 0.50000000 0.9938442\n[3,] 2.285198e-01 0.83680601 0.9984571\n\nquantile(X, p, elementwise = TRUE)\n\n[1] 9.512588e-06 5.000000e-01 9.984571e-01\n\nquantile(X, p, elementwise = TRUE, drop = FALSE)\n\n         quantile\n[1,] 9.512588e-06\n[2,] 5.000000e-01\n[3,] 9.984571e-01\n\n## compare theoretical and empirical mean from 1,000 simulated observations\ncbind(\n  \"theoretical\" = mean(X),\n  \"empirical\" = rowMeans(random(X, 1000))\n)\n\n     theoretical empirical\n[1,]        0.25 0.2464581\n[2,]        0.50 0.4941967\n[3,]        0.75 0.7542970",
    "crumbs": [
      "Documentation",
      "distributions3 objects",
      "BetaR"
    ]
  },
  {
    "objectID": "man/dxbetax.html",
    "href": "man/dxbetax.html",
    "title": "betareg",
    "section": "",
    "text": "Density, distribution function, quantile function, and random generation for the extended-support beta mixture distribution (in regression parameterization) on [0, 1].\n\n\n\ndxbetax(x, mu, phi, nu = 0, log = FALSE, quad = 20)\n\npxbetax(q, mu, phi, nu = 0, lower.tail = TRUE, log.p = FALSE, quad = 20)\n\nqxbetax(p, mu, phi, nu = 0, lower.tail = TRUE, log.p = FALSE, quad = 20,\n  tol = .Machine\\$double.eps^0.7)\n\nrxbetax(n, mu, phi, nu = 0)\n\n\n\n\n\n\n\nx, q\n\n\nnumeric. Vector of quantiles.\n\n\n\n\np\n\n\nnumeric. Vector of probabilities.\n\n\n\n\nn\n\n\nnumeric. Number of observations. If length(n) &gt; 1, the length is taken to be the number required.\n\n\n\n\nmu\n\n\nnumeric. The mean of the underlying beta distribution on [-nu, 1 + nu].\n\n\n\n\nphi\n\n\nnumeric. The precision parameter of the underlying beta distribution on [-nu, 1 + nu].\n\n\n\n\nnu\n\n\nnumeric. Mean of the exponentially-distributed exceedence parameter for the underlying beta distribution on [-nu, 1 + nu] that is censored to [0, 1].\n\n\n\n\nlog, log.p\n\n\nlogical. If TRUE, probabilities p are given as log(p).\n\n\n\n\nlower.tail\n\n\nlogical. If TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].\n\n\n\n\nquad\n\n\nnumeric. The number of quadrature points for numeric integration of the continuous mixture. Alternatively, a matrix with nodes and weights for the quadrature points can be specified.\n\n\n\n\ntol\n\n\nnumeric. Accuracy (convergence tolerance) for numerically determining quantiles based on uniroot and pxbetax.\n\n\n\n\n\n\nThe extended-support beta mixture distribution is a continuous mixture of extended-support beta distributions on [0, 1] where the underlying exceedence parameter is exponentially distributed with mean nu. Thus, if nu &gt; 0, the resulting distribution has point masses on the boundaries 0 and 1 with larger values of nu leading to higher boundary probabilities. For nu = 0 (the default), the distribution reduces to the classic beta distribution (in regression parameterization) without boundary observations.\n\n\n\ndxbetax gives the density, pxbetax gives the distribution function, qxbetax gives the quantile function, and rxbetax generates random deviates.\n\n\n\ndxbeta, XBetaX",
    "crumbs": [
      "Documentation",
      "Distributions",
      "dxbetax"
    ]
  },
  {
    "objectID": "man/dxbetax.html#the-extended-support-beta-mixture-distribution",
    "href": "man/dxbetax.html#the-extended-support-beta-mixture-distribution",
    "title": "betareg",
    "section": "",
    "text": "Density, distribution function, quantile function, and random generation for the extended-support beta mixture distribution (in regression parameterization) on [0, 1].\n\n\n\ndxbetax(x, mu, phi, nu = 0, log = FALSE, quad = 20)\n\npxbetax(q, mu, phi, nu = 0, lower.tail = TRUE, log.p = FALSE, quad = 20)\n\nqxbetax(p, mu, phi, nu = 0, lower.tail = TRUE, log.p = FALSE, quad = 20,\n  tol = .Machine\\$double.eps^0.7)\n\nrxbetax(n, mu, phi, nu = 0)\n\n\n\n\n\n\n\nx, q\n\n\nnumeric. Vector of quantiles.\n\n\n\n\np\n\n\nnumeric. Vector of probabilities.\n\n\n\n\nn\n\n\nnumeric. Number of observations. If length(n) &gt; 1, the length is taken to be the number required.\n\n\n\n\nmu\n\n\nnumeric. The mean of the underlying beta distribution on [-nu, 1 + nu].\n\n\n\n\nphi\n\n\nnumeric. The precision parameter of the underlying beta distribution on [-nu, 1 + nu].\n\n\n\n\nnu\n\n\nnumeric. Mean of the exponentially-distributed exceedence parameter for the underlying beta distribution on [-nu, 1 + nu] that is censored to [0, 1].\n\n\n\n\nlog, log.p\n\n\nlogical. If TRUE, probabilities p are given as log(p).\n\n\n\n\nlower.tail\n\n\nlogical. If TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].\n\n\n\n\nquad\n\n\nnumeric. The number of quadrature points for numeric integration of the continuous mixture. Alternatively, a matrix with nodes and weights for the quadrature points can be specified.\n\n\n\n\ntol\n\n\nnumeric. Accuracy (convergence tolerance) for numerically determining quantiles based on uniroot and pxbetax.\n\n\n\n\n\n\nThe extended-support beta mixture distribution is a continuous mixture of extended-support beta distributions on [0, 1] where the underlying exceedence parameter is exponentially distributed with mean nu. Thus, if nu &gt; 0, the resulting distribution has point masses on the boundaries 0 and 1 with larger values of nu leading to higher boundary probabilities. For nu = 0 (the default), the distribution reduces to the classic beta distribution (in regression parameterization) without boundary observations.\n\n\n\ndxbetax gives the density, pxbetax gives the distribution function, qxbetax gives the quantile function, and rxbetax generates random deviates.\n\n\n\ndxbeta, XBetaX",
    "crumbs": [
      "Documentation",
      "Distributions",
      "dxbetax"
    ]
  },
  {
    "objectID": "man/gleverage.html",
    "href": "man/gleverage.html",
    "title": "betareg",
    "section": "",
    "text": "Compute the generalized leverages values for fitted models.\n\n\n\ngleverage(model, ...)\n\n\n\n\n\n\n\nmodel\n\n\na model object.\n\n\n\n\n…\n\n\nfurther arguments passed to methods.\n\n\n\n\n\n\ngleverage is a new generic for computing generalized leverage values as suggested by Wei, Hu, and Fung (1998). Currently, there is only a method for betareg models, implementing the formulas from Rocha and Simas (2011) which are consistent with the formulas from Ferrari and Cribari-Neto (2004) for the fixed dispersion case.\nCurrently, the vector of generalized leverages requires computations and storage of order \\(n \\times n\\).\n\n\n\nFerrari, S.L.P., and Cribari-Neto, F. (2004). Beta Regression for Modeling Rates and Proportions. Journal of Applied Statistics, 31(7), 799–815.\nRocha, A.V., and Simas, A.B. (2011). Influence Diagnostics in a General Class of Beta Regression Models. Test, 20(1), 95–119. doi:10.1007/s11749-010-0189-z\nWei, B.-C., and Hu, Y.-Q., and Fung, W.-K. (1998). Generalized Leverage and Its Applications. Scandinavian Journal of Statistics, 25, 25–37.\n\n\n\nbetareg\n\n\n\n\nlibrary(\"betareg\")\n\noptions(digits = 4)\ndata(\"GasolineYield\", package = \"betareg\")\ngy &lt;- betareg(yield ~ batch + temp, data = GasolineYield)\ngleverage(gy)\n\n     1      2      3      4      5      6      7      8      9     10     11 \n0.2167 0.2517 0.3254 0.4542 0.2239 0.3201 0.5271 0.2819 0.3011 0.5066 0.1970 \n    12     13     14     15     16     17     18     19     20     21     22 \n0.2146 0.3054 0.4397 0.2909 0.3514 0.4049 0.2448 0.3570 0.4840 0.2154 0.1835 \n    23     24     25     26     27     28     29     30     31     32 \n0.2899 0.4701 0.2910 0.2982 0.5449 0.3677 0.6603 0.3181 0.2557 0.4569",
    "crumbs": [
      "Documentation",
      "Beta regression",
      "gleverage"
    ]
  },
  {
    "objectID": "man/gleverage.html#generalized-leverage-values",
    "href": "man/gleverage.html#generalized-leverage-values",
    "title": "betareg",
    "section": "",
    "text": "Compute the generalized leverages values for fitted models.\n\n\n\ngleverage(model, ...)\n\n\n\n\n\n\n\nmodel\n\n\na model object.\n\n\n\n\n…\n\n\nfurther arguments passed to methods.\n\n\n\n\n\n\ngleverage is a new generic for computing generalized leverage values as suggested by Wei, Hu, and Fung (1998). Currently, there is only a method for betareg models, implementing the formulas from Rocha and Simas (2011) which are consistent with the formulas from Ferrari and Cribari-Neto (2004) for the fixed dispersion case.\nCurrently, the vector of generalized leverages requires computations and storage of order \\(n \\times n\\).\n\n\n\nFerrari, S.L.P., and Cribari-Neto, F. (2004). Beta Regression for Modeling Rates and Proportions. Journal of Applied Statistics, 31(7), 799–815.\nRocha, A.V., and Simas, A.B. (2011). Influence Diagnostics in a General Class of Beta Regression Models. Test, 20(1), 95–119. doi:10.1007/s11749-010-0189-z\nWei, B.-C., and Hu, Y.-Q., and Fung, W.-K. (1998). Generalized Leverage and Its Applications. Scandinavian Journal of Statistics, 25, 25–37.\n\n\n\nbetareg\n\n\n\n\nlibrary(\"betareg\")\n\noptions(digits = 4)\ndata(\"GasolineYield\", package = \"betareg\")\ngy &lt;- betareg(yield ~ batch + temp, data = GasolineYield)\ngleverage(gy)\n\n     1      2      3      4      5      6      7      8      9     10     11 \n0.2167 0.2517 0.3254 0.4542 0.2239 0.3201 0.5271 0.2819 0.3011 0.5066 0.1970 \n    12     13     14     15     16     17     18     19     20     21     22 \n0.2146 0.3054 0.4397 0.2909 0.3514 0.4049 0.2448 0.3570 0.4840 0.2154 0.1835 \n    23     24     25     26     27     28     29     30     31     32 \n0.2899 0.4701 0.2910 0.2982 0.5449 0.3677 0.6603 0.3181 0.2557 0.4569",
    "crumbs": [
      "Documentation",
      "Beta regression",
      "gleverage"
    ]
  },
  {
    "objectID": "man/FoodExpenditure.html",
    "href": "man/FoodExpenditure.html",
    "title": "betareg",
    "section": "",
    "text": "Data on proportion of income spent on food for a random sample of 38 households in a large US city.\n\n\n\ndata(\"FoodExpenditure\")\n\n\n\nA data frame containing 38 observations on 3 variables.\n\n\nfood\n\n\nhousehold expenditures for food.\n\n\nincome\n\n\nhousehold income.\n\n\npersons\n\n\nnumber of persons living in household.\n\n\n\n\n\nTaken from Griffiths et al. (1993, Table 15.4).\n\n\n\nCribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R. Journal of Statistical Software, 34(2), 1–24. doi:10.18637/jss.v034.i02\nFerrari, S.L.P., and Cribari-Neto, F. (2004). Beta Regression for Modeling Rates and Proportions. Journal of Applied Statistics, 31(7), 799–815.\nGriffiths, W.E., Hill, R.C., and Judge, G.G. (1993). Learning and Practicing Econometrics New York: John Wiley and Sons.\n\n\n\nbetareg\n\n\n\n\nlibrary(\"betareg\")\n\ndata(\"FoodExpenditure\", package = \"betareg\")\n\n## Ferrari and Cribari-Neto (2004)\n## Section 4\nfe_lin &lt;- lm(I(food/income) ~ income + persons, data = FoodExpenditure)\nlibrary(\"lmtest\")\nbptest(fe_lin)\n\n\n    studentized Breusch-Pagan test\n\ndata:  fe_lin\nBP = 5.9348, df = 2, p-value = 0.05144\n\n## Table 2\nfe_beta &lt;- betareg(I(food/income) ~ income + persons, data = FoodExpenditure)\nsummary(fe_beta)\n\n\nCall:\nbetareg(formula = I(food/income) ~ income + persons, data = FoodExpenditure)\n\nQuantile residuals:\n    Min      1Q  Median      3Q     Max \n-2.5328 -0.4599  0.1698  0.6416  1.7733 \n\nCoefficients (mean model with logit link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.622548   0.223854  -2.781 0.005418 ** \nincome      -0.012299   0.003036  -4.052 5.09e-05 ***\npersons      0.118462   0.035341   3.352 0.000802 ***\n\nPhi coefficients (precision model with identity link):\n      Estimate Std. Error z value Pr(&gt;|z|)    \n(phi)    35.61       8.08   4.407 1.05e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 45.33 on 4 Df\nPseudo R-squared: 0.3878\nNumber of iterations: 28 (BFGS) + 4 (Fisher scoring)",
    "crumbs": [
      "Documentation",
      "Data sets",
      "FoodExpenditure"
    ]
  },
  {
    "objectID": "man/FoodExpenditure.html#proportion-of-household-income-spent-on-food",
    "href": "man/FoodExpenditure.html#proportion-of-household-income-spent-on-food",
    "title": "betareg",
    "section": "",
    "text": "Data on proportion of income spent on food for a random sample of 38 households in a large US city.\n\n\n\ndata(\"FoodExpenditure\")\n\n\n\nA data frame containing 38 observations on 3 variables.\n\n\nfood\n\n\nhousehold expenditures for food.\n\n\nincome\n\n\nhousehold income.\n\n\npersons\n\n\nnumber of persons living in household.\n\n\n\n\n\nTaken from Griffiths et al. (1993, Table 15.4).\n\n\n\nCribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R. Journal of Statistical Software, 34(2), 1–24. doi:10.18637/jss.v034.i02\nFerrari, S.L.P., and Cribari-Neto, F. (2004). Beta Regression for Modeling Rates and Proportions. Journal of Applied Statistics, 31(7), 799–815.\nGriffiths, W.E., Hill, R.C., and Judge, G.G. (1993). Learning and Practicing Econometrics New York: John Wiley and Sons.\n\n\n\nbetareg\n\n\n\n\nlibrary(\"betareg\")\n\ndata(\"FoodExpenditure\", package = \"betareg\")\n\n## Ferrari and Cribari-Neto (2004)\n## Section 4\nfe_lin &lt;- lm(I(food/income) ~ income + persons, data = FoodExpenditure)\nlibrary(\"lmtest\")\nbptest(fe_lin)\n\n\n    studentized Breusch-Pagan test\n\ndata:  fe_lin\nBP = 5.9348, df = 2, p-value = 0.05144\n\n## Table 2\nfe_beta &lt;- betareg(I(food/income) ~ income + persons, data = FoodExpenditure)\nsummary(fe_beta)\n\n\nCall:\nbetareg(formula = I(food/income) ~ income + persons, data = FoodExpenditure)\n\nQuantile residuals:\n    Min      1Q  Median      3Q     Max \n-2.5328 -0.4599  0.1698  0.6416  1.7733 \n\nCoefficients (mean model with logit link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.622548   0.223854  -2.781 0.005418 ** \nincome      -0.012299   0.003036  -4.052 5.09e-05 ***\npersons      0.118462   0.035341   3.352 0.000802 ***\n\nPhi coefficients (precision model with identity link):\n      Estimate Std. Error z value Pr(&gt;|z|)    \n(phi)    35.61       8.08   4.407 1.05e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 45.33 on 4 Df\nPseudo R-squared: 0.3878\nNumber of iterations: 28 (BFGS) + 4 (Fisher scoring)",
    "crumbs": [
      "Documentation",
      "Data sets",
      "FoodExpenditure"
    ]
  },
  {
    "objectID": "man/betamix.html",
    "href": "man/betamix.html",
    "title": "betareg",
    "section": "",
    "text": "Fit finite mixtures of beta regression models for rates and proportions via maximum likelihood with the EM algorithm using a parametrization with mean (depending through a link function on the covariates) and precision parameter (called phi).\n\n\n\nbetamix(formula, data, k, subset, na.action, weights, offset,\n  link = c(\"logit\", \"probit\", \"cloglog\", \"cauchit\", \"log\",\n    \"loglog\"), link.phi = \"log\",\n  control = betareg.control(...), cluster = NULL,\n  FLXconcomitant = NULL, FLXcontrol = list(), verbose = FALSE,\n  nstart = if (is.null(cluster)) 3 else 1, which = \"BIC\", \n  ID, fixed, extra_components, ...)\n\nextraComponent(type = c(\"uniform\", \"betareg\"), coef, delta,\n  link = \"logit\", link.phi = \"log\")\n\n\n\n\n\n\n\nformula\n\n\nsymbolic description of the model (of type y ~ x or y ~ x | z; for details see betareg).\n\n\n\n\ndata, subset, na.action\n\n\narguments controlling formula processing via model.frame.\n\n\n\n\nweights\n\n\noptional numeric vector of integer case weights.\n\n\n\n\noffset\n\n\noptional numeric vector with an a priori known component to be included in the linear predictor for the mean.\n\n\n\n\nk\n\n\na vector of integers indicating the number of components of the finite mixture; passed in turn to the k argument of stepFlexmix.\n\n\n\n\nlink\n\n\ncharacter specification of the link function in the mean model (mu). Currently, “logit”, “probit”, “cloglog”, “cauchit”, “log”, “loglog” are supported. Alternatively, an object of class “link-glm” can be supplied.\n\n\n\n\nlink.phi\n\n\ncharacter specification of the link function in the precision model (phi). Currently, “identity”, “log”, “sqrt” are supported. The default is “log” unless formula is of type y ~ x where the default is “identity” (for backward compatibility). Alternatively, an object of class “link-glm” can be supplied.\n\n\n\n\ncontrol\n\n\na list of control arguments specified via betareg.control.\n\n\n\n\ncluster\n\n\nEither a matrix with k columns of initial cluster membership probabilities for each observation; or a factor or integer vector with the initial cluster assignments of observations at the start of the EM algorithm. Default is random assignment into k clusters.\n\n\n\n\nFLXconcomitant\n\n\nconcomitant variable model; object of class FLXP. Default is the object returned by calling FLXPconstant. The argument FLXconcomitant can be omitted if formula is a three-part formula of type y ~ x | z | w, where w specificies the concomitant variables.\n\n\n\n\nFLXcontrol\n\n\nobject of class “FLXcontrol” or a named list; controls the EM algorithm and passed in turn to the control argument of flexmix.\n\n\n\n\nverbose\n\n\na logical; if TRUE progress information is shown for different starts of the EM algorithm.\n\n\n\n\nnstart\n\n\nfor each value of k run stepFlexmix nstart times and keep only the solution with maximum likelihood.\n\n\n\n\nwhich\n\n\nnumber of model to get if k is a vector of integers longer than one. If character, interpreted as number of components or name of an information criterion.\n\n\n\n\nID\n\n\ngrouping variable indicating if observations are from the same individual, i.e. the component membership is restricted to be the same for these observations.\n\n\n\n\nfixed\n\n\nsymbolic description of the model for the parameters fixed over components (of type ~ x | z).\n\n\n\n\nextra_components\n\n\na list containing objects returned by extraComponent().\n\n\n\n\n…\n\n\narguments passed to betareg.control.\n\n\n\n\ntype\n\n\nspecifies if the component follows a uniform distribution or a beta regression model.\n\n\n\n\ncoef\n\n\na vector with the coefficients to determine the midpoint of the uniform distribution or names list with the coefficients for the mean and precision of the beta regression model.\n\n\n\n\ndelta\n\n\nnumeric; half-length of the interval of the uniform distribution.\n\n\n\n\n\n\nThe arguments and the model specification are similar to betareg. Internally stepFlexmix is called with suitable arguments to fit the finite mixture model with the EM algorithm. See Grün et al. (2012) for more details.\nextra_components is a list where each element corresponds to a component where the parameters are fixed a-priori.\n\n\n\nAn object of class “flexmix” containing the best model with respect to the log likelihood or the one selected according to which if k is a vector of integers longer than 1.\n\n\n\nBettina Grün and Achim Zeileis\n\n\n\nCribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R. Journal of Statistical Software, 34(2), 1–24. doi:10.18637/jss.v034.i02\nGrün, B., Kosmidis, I., and Zeileis, A. (2012). Extended Beta Regression in R: Shaken, Stirred, Mixed, and Partitioned. Journal of Statistical Software, 48(11), 1–25. doi:10.18637/jss.v048.i11\nGrün, B., and Leisch, F. (2008). FlexMix Version 2: Finite Mixtures with Concomitant Variables and Varying and Constant Parameters. Journal of Statistical Software, 28(4), 1–35. doi:10.18637/jss.v028.i04\nLeisch, F. (2004). FlexMix: A General Framework for Finite Mixture Models and Latent Class Regression in R. Journal of Statistical Software, 11(8), 1–18. doi:10.18637/jss.v011.i08\n\n\n\nbetareg, flexmix, stepFlexmix\n\n\n\n\nlibrary(\"betareg\")\n\noptions(digits = 4)\n\n## data with two groups of dyslexic and non-dyslexic children\ndata(\"ReadingSkills\", package = \"betareg\")\n\nsuppressWarnings(RNGversion(\"3.5.0\"))\nset.seed(4040)\n## try to capture accuracy ~ iq relationship (without using dyslexia\n## information) using two beta regression components and one additional\n## extra component for a perfect reading score\nrs_mix &lt;- betamix(accuracy ~ iq, data = ReadingSkills, k = 3,\n  nstart = 10, extra_components = extraComponent(type = \"uniform\",\n  coef = 0.99, delta = 0.01))\n\n## visualize result\n## intensities based on posterior probabilities\nprob &lt;- 2 * (posterior(rs_mix)[cbind(1:nrow(ReadingSkills),\n   clusters(rs_mix))] - 0.5)\n## associated HCL colors\ncol0 &lt;- hcl(c(260, 0, 130), 65, 45, fixup = FALSE)\ncol1 &lt;- col0[clusters(rs_mix)]\ncol2 &lt;- hcl(c(260, 0, 130)[clusters(rs_mix)], 65 * abs(prob)^1.5,\n   95 - 50 * abs(prob)^1.5, fixup = FALSE)\n## scatter plot\nplot(accuracy ~ iq, data = ReadingSkills, col = col2, pch = 19,\n   cex = 1.5, xlim = c(-2, 2))\npoints(accuracy ~ iq, data = ReadingSkills, cex = 1.5, pch = 1,\n   col = col1)\n## fitted lines\niq &lt;- -30:30/10\ncf &lt;- rbind(coef(rs_mix, model = \"mean\", component = 1:2),\n   c(qlogis(0.99), 0))\nfor(i in 1:3)\n   lines(iq, plogis(cf[i, 1] + cf[i, 2] * iq), lwd = 2,\n         col = col0[i])\n\n\n\n\n\n\n\n## refit the model including a concomitant variable model using the\n## dyslexia information with some noise to avoid complete separation\n## between concomitant variable and component memberships\nset.seed(4040)\nw &lt;- rnorm(nrow(ReadingSkills), \n           c(-1, 1)[as.integer(ReadingSkills$dyslexia)])\n\n## The argument FLXconcomitant can be omitted when specifying\n## the model via a three part formula given by\n## accuracy ~ iq | 1 | w\n## The posteriors from the previously fitted model are used\n## for initialization.\nlibrary(\"flexmix\")\nrs_mix2 &lt;- betamix(accuracy ~ iq, data = ReadingSkills,\n  extra_components = extraComponent(type = \"uniform\",\n  coef = 0.99, delta = 0.01), cluster = posterior(rs_mix),\n  FLXconcomitant = FLXPmultinom(~w))\ncoef(rs_mix2, which = \"concomitant\")\n\n  (Intercept)       w\n1      0.0000  0.0000\n2      0.8114  1.0778\n3     -0.1195 -0.3488\n\nsummary(rs_mix2, which = \"concomitant\")\n\n$Comp.2\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)    0.821      0.882    0.93     0.35  \nw              1.078      0.497    2.17     0.03 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n$Comp.3\n            Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept)   -0.113      0.812   -0.14     0.89\nw             -0.346      0.452   -0.77     0.44",
    "crumbs": [
      "Documentation",
      "Beta regression",
      "betamix"
    ]
  },
  {
    "objectID": "man/betamix.html#finite-mixtures-of-beta-regression-for-rates-and-proportions",
    "href": "man/betamix.html#finite-mixtures-of-beta-regression-for-rates-and-proportions",
    "title": "betareg",
    "section": "",
    "text": "Fit finite mixtures of beta regression models for rates and proportions via maximum likelihood with the EM algorithm using a parametrization with mean (depending through a link function on the covariates) and precision parameter (called phi).\n\n\n\nbetamix(formula, data, k, subset, na.action, weights, offset,\n  link = c(\"logit\", \"probit\", \"cloglog\", \"cauchit\", \"log\",\n    \"loglog\"), link.phi = \"log\",\n  control = betareg.control(...), cluster = NULL,\n  FLXconcomitant = NULL, FLXcontrol = list(), verbose = FALSE,\n  nstart = if (is.null(cluster)) 3 else 1, which = \"BIC\", \n  ID, fixed, extra_components, ...)\n\nextraComponent(type = c(\"uniform\", \"betareg\"), coef, delta,\n  link = \"logit\", link.phi = \"log\")\n\n\n\n\n\n\n\nformula\n\n\nsymbolic description of the model (of type y ~ x or y ~ x | z; for details see betareg).\n\n\n\n\ndata, subset, na.action\n\n\narguments controlling formula processing via model.frame.\n\n\n\n\nweights\n\n\noptional numeric vector of integer case weights.\n\n\n\n\noffset\n\n\noptional numeric vector with an a priori known component to be included in the linear predictor for the mean.\n\n\n\n\nk\n\n\na vector of integers indicating the number of components of the finite mixture; passed in turn to the k argument of stepFlexmix.\n\n\n\n\nlink\n\n\ncharacter specification of the link function in the mean model (mu). Currently, “logit”, “probit”, “cloglog”, “cauchit”, “log”, “loglog” are supported. Alternatively, an object of class “link-glm” can be supplied.\n\n\n\n\nlink.phi\n\n\ncharacter specification of the link function in the precision model (phi). Currently, “identity”, “log”, “sqrt” are supported. The default is “log” unless formula is of type y ~ x where the default is “identity” (for backward compatibility). Alternatively, an object of class “link-glm” can be supplied.\n\n\n\n\ncontrol\n\n\na list of control arguments specified via betareg.control.\n\n\n\n\ncluster\n\n\nEither a matrix with k columns of initial cluster membership probabilities for each observation; or a factor or integer vector with the initial cluster assignments of observations at the start of the EM algorithm. Default is random assignment into k clusters.\n\n\n\n\nFLXconcomitant\n\n\nconcomitant variable model; object of class FLXP. Default is the object returned by calling FLXPconstant. The argument FLXconcomitant can be omitted if formula is a three-part formula of type y ~ x | z | w, where w specificies the concomitant variables.\n\n\n\n\nFLXcontrol\n\n\nobject of class “FLXcontrol” or a named list; controls the EM algorithm and passed in turn to the control argument of flexmix.\n\n\n\n\nverbose\n\n\na logical; if TRUE progress information is shown for different starts of the EM algorithm.\n\n\n\n\nnstart\n\n\nfor each value of k run stepFlexmix nstart times and keep only the solution with maximum likelihood.\n\n\n\n\nwhich\n\n\nnumber of model to get if k is a vector of integers longer than one. If character, interpreted as number of components or name of an information criterion.\n\n\n\n\nID\n\n\ngrouping variable indicating if observations are from the same individual, i.e. the component membership is restricted to be the same for these observations.\n\n\n\n\nfixed\n\n\nsymbolic description of the model for the parameters fixed over components (of type ~ x | z).\n\n\n\n\nextra_components\n\n\na list containing objects returned by extraComponent().\n\n\n\n\n…\n\n\narguments passed to betareg.control.\n\n\n\n\ntype\n\n\nspecifies if the component follows a uniform distribution or a beta regression model.\n\n\n\n\ncoef\n\n\na vector with the coefficients to determine the midpoint of the uniform distribution or names list with the coefficients for the mean and precision of the beta regression model.\n\n\n\n\ndelta\n\n\nnumeric; half-length of the interval of the uniform distribution.\n\n\n\n\n\n\nThe arguments and the model specification are similar to betareg. Internally stepFlexmix is called with suitable arguments to fit the finite mixture model with the EM algorithm. See Grün et al. (2012) for more details.\nextra_components is a list where each element corresponds to a component where the parameters are fixed a-priori.\n\n\n\nAn object of class “flexmix” containing the best model with respect to the log likelihood or the one selected according to which if k is a vector of integers longer than 1.\n\n\n\nBettina Grün and Achim Zeileis\n\n\n\nCribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R. Journal of Statistical Software, 34(2), 1–24. doi:10.18637/jss.v034.i02\nGrün, B., Kosmidis, I., and Zeileis, A. (2012). Extended Beta Regression in R: Shaken, Stirred, Mixed, and Partitioned. Journal of Statistical Software, 48(11), 1–25. doi:10.18637/jss.v048.i11\nGrün, B., and Leisch, F. (2008). FlexMix Version 2: Finite Mixtures with Concomitant Variables and Varying and Constant Parameters. Journal of Statistical Software, 28(4), 1–35. doi:10.18637/jss.v028.i04\nLeisch, F. (2004). FlexMix: A General Framework for Finite Mixture Models and Latent Class Regression in R. Journal of Statistical Software, 11(8), 1–18. doi:10.18637/jss.v011.i08\n\n\n\nbetareg, flexmix, stepFlexmix\n\n\n\n\nlibrary(\"betareg\")\n\noptions(digits = 4)\n\n## data with two groups of dyslexic and non-dyslexic children\ndata(\"ReadingSkills\", package = \"betareg\")\n\nsuppressWarnings(RNGversion(\"3.5.0\"))\nset.seed(4040)\n## try to capture accuracy ~ iq relationship (without using dyslexia\n## information) using two beta regression components and one additional\n## extra component for a perfect reading score\nrs_mix &lt;- betamix(accuracy ~ iq, data = ReadingSkills, k = 3,\n  nstart = 10, extra_components = extraComponent(type = \"uniform\",\n  coef = 0.99, delta = 0.01))\n\n## visualize result\n## intensities based on posterior probabilities\nprob &lt;- 2 * (posterior(rs_mix)[cbind(1:nrow(ReadingSkills),\n   clusters(rs_mix))] - 0.5)\n## associated HCL colors\ncol0 &lt;- hcl(c(260, 0, 130), 65, 45, fixup = FALSE)\ncol1 &lt;- col0[clusters(rs_mix)]\ncol2 &lt;- hcl(c(260, 0, 130)[clusters(rs_mix)], 65 * abs(prob)^1.5,\n   95 - 50 * abs(prob)^1.5, fixup = FALSE)\n## scatter plot\nplot(accuracy ~ iq, data = ReadingSkills, col = col2, pch = 19,\n   cex = 1.5, xlim = c(-2, 2))\npoints(accuracy ~ iq, data = ReadingSkills, cex = 1.5, pch = 1,\n   col = col1)\n## fitted lines\niq &lt;- -30:30/10\ncf &lt;- rbind(coef(rs_mix, model = \"mean\", component = 1:2),\n   c(qlogis(0.99), 0))\nfor(i in 1:3)\n   lines(iq, plogis(cf[i, 1] + cf[i, 2] * iq), lwd = 2,\n         col = col0[i])\n\n\n\n\n\n\n\n## refit the model including a concomitant variable model using the\n## dyslexia information with some noise to avoid complete separation\n## between concomitant variable and component memberships\nset.seed(4040)\nw &lt;- rnorm(nrow(ReadingSkills), \n           c(-1, 1)[as.integer(ReadingSkills$dyslexia)])\n\n## The argument FLXconcomitant can be omitted when specifying\n## the model via a three part formula given by\n## accuracy ~ iq | 1 | w\n## The posteriors from the previously fitted model are used\n## for initialization.\nlibrary(\"flexmix\")\nrs_mix2 &lt;- betamix(accuracy ~ iq, data = ReadingSkills,\n  extra_components = extraComponent(type = \"uniform\",\n  coef = 0.99, delta = 0.01), cluster = posterior(rs_mix),\n  FLXconcomitant = FLXPmultinom(~w))\ncoef(rs_mix2, which = \"concomitant\")\n\n  (Intercept)       w\n1      0.0000  0.0000\n2      0.8114  1.0778\n3     -0.1195 -0.3488\n\nsummary(rs_mix2, which = \"concomitant\")\n\n$Comp.2\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)    0.821      0.882    0.93     0.35  \nw              1.078      0.497    2.17     0.03 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n$Comp.3\n            Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept)   -0.113      0.812   -0.14     0.89\nw             -0.346      0.452   -0.77     0.44",
    "crumbs": [
      "Documentation",
      "Beta regression",
      "betamix"
    ]
  },
  {
    "objectID": "man/residuals.betareg.html",
    "href": "man/residuals.betareg.html",
    "title": "betareg",
    "section": "",
    "text": "Extract various types of residuals from beta regression models: raw response residuals (observed - fitted), Pearson residuals (raw residuals scaled by square root of variance function), deviance residuals (scaled log-likelihood contributions), and different kinds of weighted residuals suggested by Espinheira et al. (2008).\n\n\n\n## S3 method for class 'betareg'\nresiduals(object, type = c(\"quantile\",\n  \"deviance\", \"pearson\", \"response\", \"weighted\", \"sweighted\", \"sweighted2\"),\n  ...)\n\n\n\n\n\n\n\nobject\n\n\nfitted model object of class “betareg”.\n\n\n\n\ntype\n\n\ncharacter indicating type of residuals.\n\n\n\n\n…\n\n\ncurrently not used.\n\n\n\n\n\n\nThe default residuals (starting from version 3.2-0) are quantile residuals as proposed by Dunn and Smyth (1996) and explored in the context of beta regression by Pereira (2017). In case of extended support beta regression with boundary observations at 0 and/or 1, the quantile residuals for the boundary observations are randomized.\nThe definitions of all other residuals are provided in Espinheira et al. (2008): Equation 2 for “pearson”, last equation on page 409 for “deviance”, Equation 6 for “weighted”, Equation 7 for “sweighted”, and Equation 8 for “sweighted2”.\nEspinheira et al. (2008) recommend to use “sweighted2”, hence this was the default prior to version 3.2-0. However, these are rather burdensome to compute because they require operations of \\(O(n^2)\\) and hence are typically prohibitively costly in large sample. Also they are not available for extended support beta regression. Finally, Pereira (2017) found quantile residuals to have better distributional properties.\n\n\n\nCribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R. Journal of Statistical Software, 34(2), 1–24. doi:10.18637/jss.v034.i02\nDunn, P.K., and Smyth, G.K. (1996). Randomized Quantile Residuals. Journal of Computational and Graphical Statistics, 5(3), 236–244. doi:10.2307/1390802\nEspinheira, P.L., Ferrari, S.L.P., and Cribari-Neto, F. (2008). On Beta Regression Residuals. Journal of Applied Statistics, 35(4), 407–419. doi:10.1080/02664760701834931\nFerrari, S.L.P., and Cribari-Neto, F. (2004). Beta Regression for Modeling Rates and Proportions. Journal of Applied Statistics, 31(7), 799–815. doi:10.1080/0266476042000214501\nPereira, G.H.A. (2017). On Quantile Residuals in Beta Regression. Communications in Statistics – Simulation and Computation, 48(1), 302–316. doi:10.1080/03610918.2017.1381740\n\n\n\nbetareg\n\n\n\n\nlibrary(\"betareg\")\n\noptions(digits = 4)\n\ndata(\"GasolineYield\", package = \"betareg\")\n\ngy &lt;- betareg(yield ~ gravity + pressure + temp10 + temp, data = GasolineYield)\n\ngy_res &lt;- cbind(\n  \"quantile\"   = residuals(gy, type = \"quantile\"),\n  \"pearson\"    = residuals(gy, type = \"pearson\"),\n  \"deviance\"   = residuals(gy, type = \"deviance\"),\n  \"response\"   = residuals(gy, type = \"response\"),\n  \"weighted\"   = residuals(gy, type = \"weighted\"),\n  \"sweighted\"  = residuals(gy, type = \"sweighted\"),\n  \"sweighted2\" = residuals(gy, type = \"sweighted2\")\n)\npairs(gy_res)\n\n\n\n\n\n\n\ncor(gy_res)\n\n           quantile pearson deviance response weighted sweighted sweighted2\nquantile     1.0000  0.9980   0.9997   0.9659   0.9995    0.9995     0.9980\npearson      0.9980  1.0000   0.9984   0.9739   0.9956    0.9956     0.9941\ndeviance     0.9997  0.9984   1.0000   0.9682   0.9989    0.9989     0.9976\nresponse     0.9659  0.9739   0.9682   1.0000   0.9609    0.9609     0.9652\nweighted     0.9995  0.9956   0.9989   0.9609   1.0000    1.0000     0.9985\nsweighted    0.9995  0.9956   0.9989   0.9609   1.0000    1.0000     0.9985\nsweighted2   0.9980  0.9941   0.9976   0.9652   0.9985    0.9985     1.0000",
    "crumbs": [
      "Documentation",
      "Beta regression",
      "residuals.betareg"
    ]
  },
  {
    "objectID": "man/residuals.betareg.html#residuals-method-for-betareg-objects",
    "href": "man/residuals.betareg.html#residuals-method-for-betareg-objects",
    "title": "betareg",
    "section": "",
    "text": "Extract various types of residuals from beta regression models: raw response residuals (observed - fitted), Pearson residuals (raw residuals scaled by square root of variance function), deviance residuals (scaled log-likelihood contributions), and different kinds of weighted residuals suggested by Espinheira et al. (2008).\n\n\n\n## S3 method for class 'betareg'\nresiduals(object, type = c(\"quantile\",\n  \"deviance\", \"pearson\", \"response\", \"weighted\", \"sweighted\", \"sweighted2\"),\n  ...)\n\n\n\n\n\n\n\nobject\n\n\nfitted model object of class “betareg”.\n\n\n\n\ntype\n\n\ncharacter indicating type of residuals.\n\n\n\n\n…\n\n\ncurrently not used.\n\n\n\n\n\n\nThe default residuals (starting from version 3.2-0) are quantile residuals as proposed by Dunn and Smyth (1996) and explored in the context of beta regression by Pereira (2017). In case of extended support beta regression with boundary observations at 0 and/or 1, the quantile residuals for the boundary observations are randomized.\nThe definitions of all other residuals are provided in Espinheira et al. (2008): Equation 2 for “pearson”, last equation on page 409 for “deviance”, Equation 6 for “weighted”, Equation 7 for “sweighted”, and Equation 8 for “sweighted2”.\nEspinheira et al. (2008) recommend to use “sweighted2”, hence this was the default prior to version 3.2-0. However, these are rather burdensome to compute because they require operations of \\(O(n^2)\\) and hence are typically prohibitively costly in large sample. Also they are not available for extended support beta regression. Finally, Pereira (2017) found quantile residuals to have better distributional properties.\n\n\n\nCribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R. Journal of Statistical Software, 34(2), 1–24. doi:10.18637/jss.v034.i02\nDunn, P.K., and Smyth, G.K. (1996). Randomized Quantile Residuals. Journal of Computational and Graphical Statistics, 5(3), 236–244. doi:10.2307/1390802\nEspinheira, P.L., Ferrari, S.L.P., and Cribari-Neto, F. (2008). On Beta Regression Residuals. Journal of Applied Statistics, 35(4), 407–419. doi:10.1080/02664760701834931\nFerrari, S.L.P., and Cribari-Neto, F. (2004). Beta Regression for Modeling Rates and Proportions. Journal of Applied Statistics, 31(7), 799–815. doi:10.1080/0266476042000214501\nPereira, G.H.A. (2017). On Quantile Residuals in Beta Regression. Communications in Statistics – Simulation and Computation, 48(1), 302–316. doi:10.1080/03610918.2017.1381740\n\n\n\nbetareg\n\n\n\n\nlibrary(\"betareg\")\n\noptions(digits = 4)\n\ndata(\"GasolineYield\", package = \"betareg\")\n\ngy &lt;- betareg(yield ~ gravity + pressure + temp10 + temp, data = GasolineYield)\n\ngy_res &lt;- cbind(\n  \"quantile\"   = residuals(gy, type = \"quantile\"),\n  \"pearson\"    = residuals(gy, type = \"pearson\"),\n  \"deviance\"   = residuals(gy, type = \"deviance\"),\n  \"response\"   = residuals(gy, type = \"response\"),\n  \"weighted\"   = residuals(gy, type = \"weighted\"),\n  \"sweighted\"  = residuals(gy, type = \"sweighted\"),\n  \"sweighted2\" = residuals(gy, type = \"sweighted2\")\n)\npairs(gy_res)\n\n\n\n\n\n\n\ncor(gy_res)\n\n           quantile pearson deviance response weighted sweighted sweighted2\nquantile     1.0000  0.9980   0.9997   0.9659   0.9995    0.9995     0.9980\npearson      0.9980  1.0000   0.9984   0.9739   0.9956    0.9956     0.9941\ndeviance     0.9997  0.9984   1.0000   0.9682   0.9989    0.9989     0.9976\nresponse     0.9659  0.9739   0.9682   1.0000   0.9609    0.9609     0.9652\nweighted     0.9995  0.9956   0.9989   0.9609   1.0000    1.0000     0.9985\nsweighted    0.9995  0.9956   0.9989   0.9609   1.0000    1.0000     0.9985\nsweighted2   0.9980  0.9941   0.9976   0.9652   0.9985    0.9985     1.0000",
    "crumbs": [
      "Documentation",
      "Beta regression",
      "residuals.betareg"
    ]
  },
  {
    "objectID": "man/Beta01.html",
    "href": "man/Beta01.html",
    "title": "betareg",
    "section": "",
    "text": "Class and methods for zero- and/or one-inflated beta distributions in regression specification using the workflow from the distributions3 package.\n\n\n\nBeta01(mu, phi, p0 = 0, p1 = 0)\n\n\n\n\n\n\n\nmu\n\n\nnumeric. The mean of the beta distribution (on the open unit interval).\n\n\n\n\nphi\n\n\nnumeric. The precision parameter of the beta distribution.\n\n\n\n\np0\n\n\nnumeric. The probability for an observation of zero (often referred to as zero inflation).\n\n\n\n\np1\n\n\nnumeric. The probability for an observation of one (often referred to as one inflation).\n\n\n\n\n\n\nThe zero- and/or one-inflated beta distribution is obtained by adding point masses at zero and/or one to a standard beta distribution.\nNote that the support of the standard beta distribution is the open unit interval where values of exactly zero or one cannot occur. Thus, the inflation jargon is rather misleading as there is no probability that could be inflated. It is rather a hurdle or two-part (or three-part) model.\n\n\n\nA Beta01 distribution object.\n\n\n\ndbeta01, BetaR\n\n\n\n\nlibrary(\"betareg\")\n\n\n## package and random seed\nlibrary(\"distributions3\")\nset.seed(6020)\n\n## three beta distributions\nX &lt;- Beta01(\n  mu  = c(0.25, 0.50, 0.75),\n  phi = c(1, 1, 2),\n  p0 = c(0.1, 0, 0),\n  p1 = c(0, 0, 0.3)\n)\nX\n\n[1] \"Beta01(mu = 0.25, phi = 1, p0 = 0.1, p1 = 0.0)\"\n[2] \"Beta01(mu = 0.50, phi = 1, p0 = 0.0, p1 = 0.0)\"\n[3] \"Beta01(mu = 0.75, phi = 2, p0 = 0.0, p1 = 0.3)\"\n\n## compute moments of the distribution\nmean(X)\n\n[1] 0.225 0.500 0.825\n\nvariance(X)\n\n[1] 0.090000 0.125000 0.056875\n\n## support interval (minimum and maximum)\nsupport(X)\n\n     min max\n[1,]   0   1\n[2,]   0   1\n[3,]   0   1\n\n## simulate random variables\nrandom(X, 5)\n\n            r_1         r_2         r_3        r_4       r_5\n[1,] 0.01770077 0.031967958 0.009185013 0.09774271 0.5297302\n[2,] 0.11888790 0.004743561 0.209872794 0.56026234 0.7010201\n[3,] 0.43181699 0.757365599 0.612582662 0.76991426 0.3122026\n\n## histograms of 1,000 simulated observations\nx &lt;- random(X, 1000)\nhist(x[1, ])\n\n\n\n\n\n\n\nhist(x[2, ])\n\n\n\n\n\n\n\nhist(x[3, ])\n\n\n\n\n\n\n\n## probability density function (PDF) and log-density (or log-likelihood)\nx &lt;- c(0.25, 0.5, 0.75)\npdf(X, x)\n\n[1] 0.6156832 0.6366198 0.7718605\n\npdf(X, x, log = TRUE)\n\n[1] -0.4850227 -0.4515827 -0.2589515\n\nlog_pdf(X, x)\n\n[1] -0.4850227 -0.4515827 -0.2589515\n\n## cumulative distribution function (CDF)\ncdf(X, x)\n\n[1] 0.6808374 0.5000000 0.2737016\n\n## quantiles\nquantile(X, 0.5)\n\n[1] 0.05868041 0.50000000 0.94876688\n\n## cdf() and quantile() are inverses\ncdf(X, quantile(X, 0.5))\n\n[1] 0.5 0.5 0.5\n\nquantile(X, cdf(X, 1))\n\n[1] 1 1 1\n\n## point mass probabilities (if any) on boundary\ncdf(X, 0, lower.tail = TRUE)\n\n[1] 0.1 0.0 0.0\n\ncdf(X, 1, lower.tail = FALSE)\n\n[1] 0.0 0.0 0.3\n\n## all methods above can either be applied elementwise or for\n## all combinations of X and x, if length(X) = length(x),\n## also the result can be assured to be a matrix via drop = FALSE\np &lt;- c(0.05, 0.5, 0.95)\nquantile(X, p, elementwise = FALSE)\n\n         q_0.05      q_0.5    q_0.95\n[1,] 0.00000000 0.05868041 0.8991438\n[2,] 0.00615583 0.50000000 0.9938442\n[3,] 0.28573175 0.94876688 1.0000000\n\nquantile(X, p, elementwise = TRUE)\n\n[1] 0.0 0.5 1.0\n\nquantile(X, p, elementwise = TRUE, drop = FALSE)\n\n     quantile\n[1,]      0.0\n[2,]      0.5\n[3,]      1.0\n\n## compare theoretical and empirical mean from 1,000 simulated observations\ncbind(\n  \"theoretical\" = mean(X),\n  \"empirical\" = rowMeans(random(X, 1000))\n)\n\n     theoretical empirical\n[1,]       0.225 0.2275291\n[2,]       0.500 0.5091324\n[3,]       0.825 0.8103725",
    "crumbs": [
      "Documentation",
      "distributions3 objects",
      "Beta01"
    ]
  },
  {
    "objectID": "man/Beta01.html#create-a-zero--andor-one-inflated-beta-distribution",
    "href": "man/Beta01.html#create-a-zero--andor-one-inflated-beta-distribution",
    "title": "betareg",
    "section": "",
    "text": "Class and methods for zero- and/or one-inflated beta distributions in regression specification using the workflow from the distributions3 package.\n\n\n\nBeta01(mu, phi, p0 = 0, p1 = 0)\n\n\n\n\n\n\n\nmu\n\n\nnumeric. The mean of the beta distribution (on the open unit interval).\n\n\n\n\nphi\n\n\nnumeric. The precision parameter of the beta distribution.\n\n\n\n\np0\n\n\nnumeric. The probability for an observation of zero (often referred to as zero inflation).\n\n\n\n\np1\n\n\nnumeric. The probability for an observation of one (often referred to as one inflation).\n\n\n\n\n\n\nThe zero- and/or one-inflated beta distribution is obtained by adding point masses at zero and/or one to a standard beta distribution.\nNote that the support of the standard beta distribution is the open unit interval where values of exactly zero or one cannot occur. Thus, the inflation jargon is rather misleading as there is no probability that could be inflated. It is rather a hurdle or two-part (or three-part) model.\n\n\n\nA Beta01 distribution object.\n\n\n\ndbeta01, BetaR\n\n\n\n\nlibrary(\"betareg\")\n\n\n## package and random seed\nlibrary(\"distributions3\")\nset.seed(6020)\n\n## three beta distributions\nX &lt;- Beta01(\n  mu  = c(0.25, 0.50, 0.75),\n  phi = c(1, 1, 2),\n  p0 = c(0.1, 0, 0),\n  p1 = c(0, 0, 0.3)\n)\nX\n\n[1] \"Beta01(mu = 0.25, phi = 1, p0 = 0.1, p1 = 0.0)\"\n[2] \"Beta01(mu = 0.50, phi = 1, p0 = 0.0, p1 = 0.0)\"\n[3] \"Beta01(mu = 0.75, phi = 2, p0 = 0.0, p1 = 0.3)\"\n\n## compute moments of the distribution\nmean(X)\n\n[1] 0.225 0.500 0.825\n\nvariance(X)\n\n[1] 0.090000 0.125000 0.056875\n\n## support interval (minimum and maximum)\nsupport(X)\n\n     min max\n[1,]   0   1\n[2,]   0   1\n[3,]   0   1\n\n## simulate random variables\nrandom(X, 5)\n\n            r_1         r_2         r_3        r_4       r_5\n[1,] 0.01770077 0.031967958 0.009185013 0.09774271 0.5297302\n[2,] 0.11888790 0.004743561 0.209872794 0.56026234 0.7010201\n[3,] 0.43181699 0.757365599 0.612582662 0.76991426 0.3122026\n\n## histograms of 1,000 simulated observations\nx &lt;- random(X, 1000)\nhist(x[1, ])\n\n\n\n\n\n\n\nhist(x[2, ])\n\n\n\n\n\n\n\nhist(x[3, ])\n\n\n\n\n\n\n\n## probability density function (PDF) and log-density (or log-likelihood)\nx &lt;- c(0.25, 0.5, 0.75)\npdf(X, x)\n\n[1] 0.6156832 0.6366198 0.7718605\n\npdf(X, x, log = TRUE)\n\n[1] -0.4850227 -0.4515827 -0.2589515\n\nlog_pdf(X, x)\n\n[1] -0.4850227 -0.4515827 -0.2589515\n\n## cumulative distribution function (CDF)\ncdf(X, x)\n\n[1] 0.6808374 0.5000000 0.2737016\n\n## quantiles\nquantile(X, 0.5)\n\n[1] 0.05868041 0.50000000 0.94876688\n\n## cdf() and quantile() are inverses\ncdf(X, quantile(X, 0.5))\n\n[1] 0.5 0.5 0.5\n\nquantile(X, cdf(X, 1))\n\n[1] 1 1 1\n\n## point mass probabilities (if any) on boundary\ncdf(X, 0, lower.tail = TRUE)\n\n[1] 0.1 0.0 0.0\n\ncdf(X, 1, lower.tail = FALSE)\n\n[1] 0.0 0.0 0.3\n\n## all methods above can either be applied elementwise or for\n## all combinations of X and x, if length(X) = length(x),\n## also the result can be assured to be a matrix via drop = FALSE\np &lt;- c(0.05, 0.5, 0.95)\nquantile(X, p, elementwise = FALSE)\n\n         q_0.05      q_0.5    q_0.95\n[1,] 0.00000000 0.05868041 0.8991438\n[2,] 0.00615583 0.50000000 0.9938442\n[3,] 0.28573175 0.94876688 1.0000000\n\nquantile(X, p, elementwise = TRUE)\n\n[1] 0.0 0.5 1.0\n\nquantile(X, p, elementwise = TRUE, drop = FALSE)\n\n     quantile\n[1,]      0.0\n[2,]      0.5\n[3,]      1.0\n\n## compare theoretical and empirical mean from 1,000 simulated observations\ncbind(\n  \"theoretical\" = mean(X),\n  \"empirical\" = rowMeans(random(X, 1000))\n)\n\n     theoretical empirical\n[1,]       0.225 0.2275291\n[2,]       0.500 0.5091324\n[3,]       0.825 0.8103725",
    "crumbs": [
      "Documentation",
      "distributions3 objects",
      "Beta01"
    ]
  },
  {
    "objectID": "man/XBetaX.html",
    "href": "man/XBetaX.html",
    "title": "betareg",
    "section": "",
    "text": "Class and methods for extended-support beta distributions using the workflow from the distributions3 package.\n\n\n\nXBetaX(mu, phi, nu = 0)\n\n\n\n\n\n\n\nmu\n\n\nnumeric. The mean of the underlying beta distribution on [-nu, 1 + nu].\n\n\n\n\nphi\n\n\nnumeric. The precision parameter of the underlying beta distribution on [-nu, 1 + nu].\n\n\n\n\nnu\n\n\nnumeric. Mean of the exponentially-distributed exceedence parameter for the underlying beta distribution on [-nu, 1 + nu] that is censored to [0, 1].\n\n\n\n\n\n\nThe extended-support beta mixture distribution is a continuous mixture of extended-support beta distributions on [0, 1] where the underlying exceedence parameter is exponentially distributed with mean nu. Thus, if nu &gt; 0, the resulting distribution has point masses on the boundaries 0 and 1 with larger values of nu leading to higher boundary probabilities. For nu = 0 (the default), the distribution reduces to the classic beta distribution (in regression parameterization) without boundary observations.\n\n\n\nA XBetaX distribution object.\n\n\n\ndxbetax, XBeta\n\n\n\n\nlibrary(\"betareg\")\n\n\n## package and random seed\nlibrary(\"distributions3\")\nset.seed(6020)\n\n## three beta distributions\nX &lt;- XBetaX(\n  mu  = c(0.25, 0.50, 0.75),\n  phi = c(1, 1, 2),\n  nu = c(0, 0.1, 0.2)\n)\nX\n\n[1] \"XBetaX(mu = 0.25, phi = 1, nu = 0.0)\"\n[2] \"XBetaX(mu = 0.50, phi = 1, nu = 0.1)\"\n[3] \"XBetaX(mu = 0.75, phi = 2, nu = 0.2)\"\n\n## compute moments of the distribution\nmean(X)\n\n[1] 0.2500000 0.5000000 0.7812779\n\nvariance(X)\n\n[1] 0.09375000 0.14932803 0.08290156\n\n## support interval (minimum and maximum)\nsupport(X)\n\n     min max\n[1,]   0   1\n[2,]   0   1\n[3,]   0   1\n\n## it is only continuous when there are no point masses on the boundary\nis_continuous(X)\n\n[1]  TRUE FALSE FALSE\n\ncdf(X, 0)\n\n[1] 0.00000000 0.16127596 0.02230181\n\ncdf(X, 1, lower.tail = FALSE)\n\n[1] 0.0000000 0.1612760 0.4004398\n\n## simulate random variables\nrandom(X, 5)\n\n            r_1        r_2         r_3       r_4        r_5\n[1,] 0.01770077 0.03196796 0.009185013 0.3511111 0.03417845\n[2,] 0.03065274 0.00000000 0.159692910 0.4697419 0.62766314\n[3,] 0.40195437 1.00000000 0.675081997 0.9255527 1.00000000\n\n## histograms of 1,000 simulated observations\nx &lt;- random(X, 1000)\nhist(x[1, ])\n\n\n\n\n\n\n\nhist(x[2, ])\n\n\n\n\n\n\n\nhist(x[3, ])\n\n\n\n\n\n\n\n## probability density function (PDF) and log-density (or log-likelihood)\nx &lt;- c(0.25, 0.5, 0.75)\npdf(X, x)\n\n[1] 0.6840925 0.5424706 0.7405552\n\npdf(X, x, log = TRUE)\n\n[1] -0.3796622 -0.6116213 -0.3003551\n\nlog_pdf(X, x)\n\n[1] -0.3796622 -0.6116213 -0.3003551\n\n## cumulative distribution function (CDF)\ncdf(X, x)\n\n[1] 0.6453748 0.5000000 0.3312063\n\n## quantiles\nquantile(X, 0.5)\n\n[1] 0.09331223 0.50000000 0.93231291\n\n## cdf() and quantile() are inverses (except at censoring points)\ncdf(X, quantile(X, 0.5))\n\n[1] 0.5 0.5 0.5\n\nquantile(X, cdf(X, 1))\n\n[1] 1 1 1\n\n## all methods above can either be applied elementwise or for\n## all combinations of X and x, if length(X) = length(x),\n## also the result can be assured to be a matrix via drop = FALSE\np &lt;- c(0.05, 0.5, 0.95)\nquantile(X, p, elementwise = FALSE)\n\n           q_0.05      q_0.5    q_0.95\n[1,] 9.512588e-06 0.09331223 0.9118445\n[2,] 0.000000e+00 0.50000000 1.0000000\n[3,] 1.353857e-01 0.93231291 1.0000000\n\nquantile(X, p, elementwise = TRUE)\n\n[1] 9.512588e-06 5.000000e-01 1.000000e+00\n\nquantile(X, p, elementwise = TRUE, drop = FALSE)\n\n         quantile\n[1,] 9.512588e-06\n[2,] 5.000000e-01\n[3,] 1.000000e+00\n\n## compare theoretical and empirical mean from 1,000 simulated observations\ncbind(\n  \"theoretical\" = mean(X),\n  \"empirical\" = rowMeans(random(X, 1000))\n)\n\n     theoretical empirical\n[1,]   0.2500000 0.2403159\n[2,]   0.5000000 0.4935615\n[3,]   0.7812779 0.7936076",
    "crumbs": [
      "Documentation",
      "distributions3 objects",
      "XBetaX"
    ]
  },
  {
    "objectID": "man/XBetaX.html#create-an-extended-support-beta-mixture-distribution",
    "href": "man/XBetaX.html#create-an-extended-support-beta-mixture-distribution",
    "title": "betareg",
    "section": "",
    "text": "Class and methods for extended-support beta distributions using the workflow from the distributions3 package.\n\n\n\nXBetaX(mu, phi, nu = 0)\n\n\n\n\n\n\n\nmu\n\n\nnumeric. The mean of the underlying beta distribution on [-nu, 1 + nu].\n\n\n\n\nphi\n\n\nnumeric. The precision parameter of the underlying beta distribution on [-nu, 1 + nu].\n\n\n\n\nnu\n\n\nnumeric. Mean of the exponentially-distributed exceedence parameter for the underlying beta distribution on [-nu, 1 + nu] that is censored to [0, 1].\n\n\n\n\n\n\nThe extended-support beta mixture distribution is a continuous mixture of extended-support beta distributions on [0, 1] where the underlying exceedence parameter is exponentially distributed with mean nu. Thus, if nu &gt; 0, the resulting distribution has point masses on the boundaries 0 and 1 with larger values of nu leading to higher boundary probabilities. For nu = 0 (the default), the distribution reduces to the classic beta distribution (in regression parameterization) without boundary observations.\n\n\n\nA XBetaX distribution object.\n\n\n\ndxbetax, XBeta\n\n\n\n\nlibrary(\"betareg\")\n\n\n## package and random seed\nlibrary(\"distributions3\")\nset.seed(6020)\n\n## three beta distributions\nX &lt;- XBetaX(\n  mu  = c(0.25, 0.50, 0.75),\n  phi = c(1, 1, 2),\n  nu = c(0, 0.1, 0.2)\n)\nX\n\n[1] \"XBetaX(mu = 0.25, phi = 1, nu = 0.0)\"\n[2] \"XBetaX(mu = 0.50, phi = 1, nu = 0.1)\"\n[3] \"XBetaX(mu = 0.75, phi = 2, nu = 0.2)\"\n\n## compute moments of the distribution\nmean(X)\n\n[1] 0.2500000 0.5000000 0.7812779\n\nvariance(X)\n\n[1] 0.09375000 0.14932803 0.08290156\n\n## support interval (minimum and maximum)\nsupport(X)\n\n     min max\n[1,]   0   1\n[2,]   0   1\n[3,]   0   1\n\n## it is only continuous when there are no point masses on the boundary\nis_continuous(X)\n\n[1]  TRUE FALSE FALSE\n\ncdf(X, 0)\n\n[1] 0.00000000 0.16127596 0.02230181\n\ncdf(X, 1, lower.tail = FALSE)\n\n[1] 0.0000000 0.1612760 0.4004398\n\n## simulate random variables\nrandom(X, 5)\n\n            r_1        r_2         r_3       r_4        r_5\n[1,] 0.01770077 0.03196796 0.009185013 0.3511111 0.03417845\n[2,] 0.03065274 0.00000000 0.159692910 0.4697419 0.62766314\n[3,] 0.40195437 1.00000000 0.675081997 0.9255527 1.00000000\n\n## histograms of 1,000 simulated observations\nx &lt;- random(X, 1000)\nhist(x[1, ])\n\n\n\n\n\n\n\nhist(x[2, ])\n\n\n\n\n\n\n\nhist(x[3, ])\n\n\n\n\n\n\n\n## probability density function (PDF) and log-density (or log-likelihood)\nx &lt;- c(0.25, 0.5, 0.75)\npdf(X, x)\n\n[1] 0.6840925 0.5424706 0.7405552\n\npdf(X, x, log = TRUE)\n\n[1] -0.3796622 -0.6116213 -0.3003551\n\nlog_pdf(X, x)\n\n[1] -0.3796622 -0.6116213 -0.3003551\n\n## cumulative distribution function (CDF)\ncdf(X, x)\n\n[1] 0.6453748 0.5000000 0.3312063\n\n## quantiles\nquantile(X, 0.5)\n\n[1] 0.09331223 0.50000000 0.93231291\n\n## cdf() and quantile() are inverses (except at censoring points)\ncdf(X, quantile(X, 0.5))\n\n[1] 0.5 0.5 0.5\n\nquantile(X, cdf(X, 1))\n\n[1] 1 1 1\n\n## all methods above can either be applied elementwise or for\n## all combinations of X and x, if length(X) = length(x),\n## also the result can be assured to be a matrix via drop = FALSE\np &lt;- c(0.05, 0.5, 0.95)\nquantile(X, p, elementwise = FALSE)\n\n           q_0.05      q_0.5    q_0.95\n[1,] 9.512588e-06 0.09331223 0.9118445\n[2,] 0.000000e+00 0.50000000 1.0000000\n[3,] 1.353857e-01 0.93231291 1.0000000\n\nquantile(X, p, elementwise = TRUE)\n\n[1] 9.512588e-06 5.000000e-01 1.000000e+00\n\nquantile(X, p, elementwise = TRUE, drop = FALSE)\n\n         quantile\n[1,] 9.512588e-06\n[2,] 5.000000e-01\n[3,] 1.000000e+00\n\n## compare theoretical and empirical mean from 1,000 simulated observations\ncbind(\n  \"theoretical\" = mean(X),\n  \"empirical\" = rowMeans(random(X, 1000))\n)\n\n     theoretical empirical\n[1,]   0.2500000 0.2403159\n[2,]   0.5000000 0.4935615\n[3,]   0.7812779 0.7936076",
    "crumbs": [
      "Documentation",
      "distributions3 objects",
      "XBetaX"
    ]
  },
  {
    "objectID": "man/WeatherTask.html",
    "href": "man/WeatherTask.html",
    "title": "betareg",
    "section": "",
    "text": "Weather Task With Priming and Precise and Imprecise Probabilities\n\nDescription\nIn this study participants were asked to judge how likely Sunday is to be the hottest day of the week.\n\n\nUsage\ndata(WeatherTask)\n\n\nFormat\nA data frame with 345 observations on the following 3 variables.\n\n\npriming\n\n\na factor with levels two-fold (case prime) and seven-fold (class prime).\n\n\neliciting\n\n\na factor with levels precise and imprecise (lower and upper limit).\n\n\nagreement\n\n\na numeric vector, probability indicated by participants or the average between minimum and maximum probability indicated.\n\n\n\n\nDetails\nAll participants in the study were either first- or second-year undergraduate students in psychology, none of whom had a strong background in probability or were familiar with imprecise probability theories.\nFor priming the questions were:\n\n\ntwo-fold\n\n\n[What is the probability that] the temperature at Canberra airport on Sunday will be higher than every other day next week?\n\n\nseven-fold\n\n\n[What is the probability that] the highest temperature of the week at Canberra airport will occur on Sunday?\n\n\nFor eliciting the instructions were if\n\n\nprecise\n\n\nto assign a probability estimate,\n\n\nimprecise\n\n\nto assign a lower and upper probability estimate.\n\n\n\n\nSource\nTaken from Smithson et al. (2011) supplements.\n\n\nReferences\nSmithson, M., Merkle, E.C., and Verkuilen, J. (2011). Beta Regression Finite Mixture Models of Polarization and Priming. Journal of Educational and Behavioral Statistics, 36(6), 804–831. doi:10.3102/1076998610396893\nSmithson, M., and Segale, C. (2009). Partition Priming in Judgments of Imprecise Probabilities. Journal of Statistical Theory and Practice, 3(1), 169–181.\n\n\nExamples\n\nlibrary(\"betareg\")\n\ndata(\"WeatherTask\", package = \"betareg\")\nlibrary(\"flexmix\")\nwt_betamix &lt;- betamix(agreement ~ 1, data = WeatherTask, k = 2,\n  extra_components = extraComponent(type = \"betareg\", coef =\n    list(mean = 0, precision = 2)),\n  FLXconcomitant = FLXPmultinom(~ priming + eliciting))",
    "crumbs": [
      "Documentation",
      "Data sets",
      "WeatherTask"
    ]
  },
  {
    "objectID": "man/StressAnxiety.html",
    "href": "man/StressAnxiety.html",
    "title": "betareg",
    "section": "",
    "text": "Stress and anxiety among nonclinical women in Townsville, Queensland, Australia.\n\n\n\ndata(\"StressAnxiety\")\n\n\n\nA data frame containing 166 observations on 2 variables.\n\n\nstress\n\n\nscore, linearly transformed to the open unit interval (see below).\n\n\nanxiety\n\n\nscore, linearly transformed to the open unit interval (see below).\n\n\n\n\n\nBoth variables were assess on the Depression Anxiety Stress Scales, ranging from 0 to 42. Smithson and Verkuilen (2006) transformed these to the open unit interval (without providing details about this transformation).\n\n\n\nExample 2 from Smithson and Verkuilen (2006) supplements.\n\n\n\nSmithson, M., and Verkuilen, J. (2006). A Better Lemon Squeezer? Maximum-Likelihood Regression with Beta-Distributed Dependent Variables. Psychological Methods, 11(7), 54–71.\n\n\n\nbetareg, MockJurors, ReadingSkills\n\n\n\n\nlibrary(\"betareg\")\n\ndata(\"StressAnxiety\", package = \"betareg\")\nStressAnxiety &lt;- StressAnxiety[order(StressAnxiety$stress),]\n\n## Smithson & Verkuilen (2006, Table 4)\nsa_null &lt;- betareg(anxiety ~ 1 | 1,\n  data = StressAnxiety, hessian = TRUE)\nsa_stress &lt;- betareg(anxiety ~ stress | stress,\n  data = StressAnxiety, hessian = TRUE)\nsummary(sa_null)\n\n\nCall:\nbetareg(formula = anxiety ~ 1 | 1, data = StressAnxiety, hessian = TRUE)\n\nQuantile residuals:\n    Min      1Q  Median      3Q     Max \n-0.8377 -0.8377 -0.4467  0.6217  3.2396 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -2.24396    0.09879  -22.71   &lt;2e-16 ***\n\nPhi coefficients (precision model with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    1.796      0.123    14.6   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 239.4 on 2 Df\nNumber of iterations in BFGS optimization: 9 \n\nsummary(sa_stress)\n\n\nCall:\nbetareg(formula = anxiety ~ stress | stress, data = StressAnxiety, hessian = TRUE)\n\nQuantile residuals:\n    Min      1Q  Median      3Q     Max \n-2.0119 -0.7953 -0.1833  0.5658  3.1141 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -4.0237     0.1442  -27.90   &lt;2e-16 ***\nstress        4.9414     0.4409   11.21   &lt;2e-16 ***\n\nPhi coefficients (precision model with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   3.9608     0.2511  15.776  &lt; 2e-16 ***\nstress       -4.2733     0.7532  -5.674  1.4e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood:   302 on 4 Df\nPseudo R-squared: 0.4748\nNumber of iterations in BFGS optimization: 16 \n\nAIC(sa_null, sa_stress)\n\n          df       AIC\nsa_null    2 -474.8960\nsa_stress  4 -595.9202\n\n1 - as.vector(logLik(sa_null)/logLik(sa_stress))\n\n[1] 0.207021\n\n## visualization\nattach(StressAnxiety)\nplot(jitter(anxiety) ~ jitter(stress),\n  xlab = \"Stress\", ylab = \"Anxiety\",\n  xlim = c(0, 1), ylim = c(0, 1))\nlines(lowess(anxiety ~ stress))\nlines(fitted(sa_stress) ~ stress, lty = 2)\nlines(fitted(lm(anxiety ~ stress)) ~ stress, lty = 3)\nlegend(\"topleft\", c(\"lowess\", \"betareg\", \"lm\"), lty = 1:3, bty = \"n\")\n\n\n\n\n\n\n\ndetach(StressAnxiety)\n\n## see demo(\"SmithsonVerkuilen2006\", package = \"betareg\") for more details",
    "crumbs": [
      "Documentation",
      "Data sets",
      "StressAnxiety"
    ]
  },
  {
    "objectID": "man/StressAnxiety.html#dependency-of-anxiety-on-stress",
    "href": "man/StressAnxiety.html#dependency-of-anxiety-on-stress",
    "title": "betareg",
    "section": "",
    "text": "Stress and anxiety among nonclinical women in Townsville, Queensland, Australia.\n\n\n\ndata(\"StressAnxiety\")\n\n\n\nA data frame containing 166 observations on 2 variables.\n\n\nstress\n\n\nscore, linearly transformed to the open unit interval (see below).\n\n\nanxiety\n\n\nscore, linearly transformed to the open unit interval (see below).\n\n\n\n\n\nBoth variables were assess on the Depression Anxiety Stress Scales, ranging from 0 to 42. Smithson and Verkuilen (2006) transformed these to the open unit interval (without providing details about this transformation).\n\n\n\nExample 2 from Smithson and Verkuilen (2006) supplements.\n\n\n\nSmithson, M., and Verkuilen, J. (2006). A Better Lemon Squeezer? Maximum-Likelihood Regression with Beta-Distributed Dependent Variables. Psychological Methods, 11(7), 54–71.\n\n\n\nbetareg, MockJurors, ReadingSkills\n\n\n\n\nlibrary(\"betareg\")\n\ndata(\"StressAnxiety\", package = \"betareg\")\nStressAnxiety &lt;- StressAnxiety[order(StressAnxiety$stress),]\n\n## Smithson & Verkuilen (2006, Table 4)\nsa_null &lt;- betareg(anxiety ~ 1 | 1,\n  data = StressAnxiety, hessian = TRUE)\nsa_stress &lt;- betareg(anxiety ~ stress | stress,\n  data = StressAnxiety, hessian = TRUE)\nsummary(sa_null)\n\n\nCall:\nbetareg(formula = anxiety ~ 1 | 1, data = StressAnxiety, hessian = TRUE)\n\nQuantile residuals:\n    Min      1Q  Median      3Q     Max \n-0.8377 -0.8377 -0.4467  0.6217  3.2396 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -2.24396    0.09879  -22.71   &lt;2e-16 ***\n\nPhi coefficients (precision model with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    1.796      0.123    14.6   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 239.4 on 2 Df\nNumber of iterations in BFGS optimization: 9 \n\nsummary(sa_stress)\n\n\nCall:\nbetareg(formula = anxiety ~ stress | stress, data = StressAnxiety, hessian = TRUE)\n\nQuantile residuals:\n    Min      1Q  Median      3Q     Max \n-2.0119 -0.7953 -0.1833  0.5658  3.1141 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -4.0237     0.1442  -27.90   &lt;2e-16 ***\nstress        4.9414     0.4409   11.21   &lt;2e-16 ***\n\nPhi coefficients (precision model with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   3.9608     0.2511  15.776  &lt; 2e-16 ***\nstress       -4.2733     0.7532  -5.674  1.4e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood:   302 on 4 Df\nPseudo R-squared: 0.4748\nNumber of iterations in BFGS optimization: 16 \n\nAIC(sa_null, sa_stress)\n\n          df       AIC\nsa_null    2 -474.8960\nsa_stress  4 -595.9202\n\n1 - as.vector(logLik(sa_null)/logLik(sa_stress))\n\n[1] 0.207021\n\n## visualization\nattach(StressAnxiety)\nplot(jitter(anxiety) ~ jitter(stress),\n  xlab = \"Stress\", ylab = \"Anxiety\",\n  xlim = c(0, 1), ylim = c(0, 1))\nlines(lowess(anxiety ~ stress))\nlines(fitted(sa_stress) ~ stress, lty = 2)\nlines(fitted(lm(anxiety ~ stress)) ~ stress, lty = 3)\nlegend(\"topleft\", c(\"lowess\", \"betareg\", \"lm\"), lty = 1:3, bty = \"n\")\n\n\n\n\n\n\n\ndetach(StressAnxiety)\n\n## see demo(\"SmithsonVerkuilen2006\", package = \"betareg\") for more details",
    "crumbs": [
      "Documentation",
      "Data sets",
      "StressAnxiety"
    ]
  },
  {
    "objectID": "man/predict.betareg.html",
    "href": "man/predict.betareg.html",
    "title": "betareg",
    "section": "",
    "text": "Extract various types of predictions from beta regression models: either on the scale of responses in (0, 1) or the scale of the linear predictor.\n\n\n\n## S3 method for class 'betareg'\npredict(object, newdata = NULL,\n  type = c(\"response\", \"link\", \"precision\", \"variance\", \"parameters\",\n    \"density\", \"probability\", \"quantile\"),\n  na.action = na.pass, at = 0.5, ...)\n\n\n\n\n\n\n\nobject\n\n\nfitted model object of class “betareg”.\n\n\n\n\nnewdata\n\n\noptionally, a data frame in which to look for variables with which to predict. If omitted, the original observations are used.\n\n\n\n\ntype\n\n\ncharacter indicating type of predictions: fitted means of response (“response”), corresponding linear predictor (“link”), fitted precision parameter phi (“precision”), fitted variances of response (“variance”), or fitted quantile(s) of the response distribution (“quantile”).\n\n\n\n\nna.action\n\n\nfunction determining what should be done with missing values in newdata. The default is to predict NA.\n\n\n\n\nat\n\n\nnumeric vector indicating the level(s) at which quantiles should be predicted (only if type = “quantile”), defaulting to the median at = 0.5.\n\n\n\n\n…\n\n\ncurrently not used.\n\n\n\n\n\n\nFIXME: Update to extended type and at processing.\nFIXME: Add comments about pit and rootogram.\n\n\n\n\nlibrary(\"betareg\")\n\noptions(digits = 4)\n\ndata(\"GasolineYield\", package = \"betareg\")\n\ngy2 &lt;- betareg(yield ~ batch + temp | temp, data = GasolineYield)\n\ncbind(\n  predict(gy2, type = \"response\"),\n  predict(gy2, type = \"link\"),\n  predict(gy2, type = \"precision\"),\n  predict(gy2, type = \"variance\"),\n  predict(gy2, type = \"quantile\", at = c(0.25, 0.5, 0.75))\n)\n\n                                      q_0.25   q_0.5  q_0.75\n1  0.09997 -2.1976   77.56 1.145e-03 0.07549 0.09653 0.12074\n2  0.18658 -1.4724  215.06 7.024e-04 0.16816 0.18561 0.20394\n3  0.32143 -0.7472  596.36 3.651e-04 0.30842 0.32123 0.33422\n4  0.47379 -0.1049 1471.75 1.693e-04 0.46500 0.47378 0.48256\n5  0.08568 -2.3676   93.73 8.269e-04 0.06490 0.08273 0.10328\n6  0.14212 -1.7978  208.89 5.809e-04 0.12525 0.14097 0.15774\n7  0.26285 -1.0312  614.00 3.151e-04 0.25073 0.26259 0.27469\n8  0.10324 -2.1617   85.88 1.066e-03 0.07972 0.10017 0.12344\n9  0.17652 -1.5401  205.86 7.027e-04 0.15806 0.17547 0.19384\n10 0.30245 -0.8357  554.46 3.798e-04 0.28916 0.30221 0.31547\n11 0.07881 -2.4587  120.07 5.996e-04 0.06119 0.07647 0.09390\n12 0.14365 -1.7853  309.57 3.961e-04 0.12981 0.14288 0.15665\n13 0.24751 -1.1120  798.12 2.331e-04 0.23709 0.24730 0.25769\n14 0.34394 -0.6458 1537.51 1.467e-04 0.33573 0.34387 0.35208\n15 0.16957 -1.5887  342.81 4.096e-04 0.15556 0.16892 0.18287\n16 0.27545 -0.9671  821.72 2.426e-04 0.26484 0.27527 0.28586\n17 0.33691 -0.6771 1235.66 1.806e-04 0.32780 0.33683 0.34594\n18 0.10548 -2.1378  191.40 4.904e-04 0.08984 0.10410 0.11962\n19 0.23606 -1.1744  742.04 2.427e-04 0.22542 0.23583 0.24645\n20 0.32316 -0.7393 1368.34 1.597e-04 0.31459 0.32308 0.33164\n21 0.05383 -2.8665  120.07 4.207e-04 0.03893 0.05137 0.06608\n22 0.07928 -2.4521  215.06 3.379e-04 0.06624 0.07798 0.09091\n23 0.16906 -1.5923  720.73 1.946e-04 0.15949 0.16876 0.17831\n24 0.27063 -0.9914 1677.97 1.176e-04 0.26326 0.27054 0.27789\n25 0.08270 -2.4062  248.80 3.037e-04 0.07039 0.08158 0.09380\n26 0.17116 -1.5774  798.12 1.775e-04 0.16202 0.17088 0.18000\n27 0.31885 -0.7590 2523.27 8.604e-05 0.31257 0.31881 0.32509\n28 0.12701 -1.9276  650.84 1.701e-04 0.11801 0.12663 0.13560\n29 0.23661 -1.1714 1885.42 9.575e-05 0.22995 0.23651 0.24316\n30 0.10508 -2.1420  798.12 1.177e-04 0.09759 0.10475 0.11221\n31 0.11952 -1.9970  978.71 1.074e-04 0.11239 0.11926 0.12637\n32 0.18402 -1.4894 1998.57 7.509e-05 0.17811 0.18391 0.18980\n\n## evaluate cumulative _p_robabilities for (small) new data set\ngyd &lt;- GasolineYield[c(1, 5, 10), ]\n## CDF at 0.1 for each observation\npredict(gy2, newdata = gyd, type = \"probability\", at = 0.1)\n\n        1         5        10 \n5.407e-01 7.165e-01 6.053e-40 \n\n## CDF at each combination of 0.1/0.2 and observations\npredict(gy2, newdata = gyd, type = \"probability\", at = c(0.1, 0.2))\n\n       p_0.1     p_0.2\n1  5.407e-01 9.933e-01\n5  7.165e-01 9.991e-01\n10 6.053e-40 5.828e-09\n\n## CDF at pairwise combinations of 0.1/0.2/0.3 and observations\npredict(gy2, newdata = gyd, type = \"probability\", at = c(0.1, 0.2, 0.3))\n\n     1      5     10 \n0.5407 0.9991 0.4549 \n\n## CDF at all combinations of 0.1/0.2/0.3 and observations\npredict(gy2, newdata = gyd, type = \"probability\", at = rbind(c(0.1, 0.2, 0.3)))\n\n       p_0.1     p_0.2  p_0.3\n1  5.407e-01 9.933e-01 1.0000\n5  7.165e-01 9.991e-01 1.0000\n10 6.053e-40 5.828e-09 0.4549",
    "crumbs": [
      "Documentation",
      "Beta regression",
      "predict.betareg"
    ]
  },
  {
    "objectID": "man/predict.betareg.html#prediction-method-for-betareg-objects",
    "href": "man/predict.betareg.html#prediction-method-for-betareg-objects",
    "title": "betareg",
    "section": "",
    "text": "Extract various types of predictions from beta regression models: either on the scale of responses in (0, 1) or the scale of the linear predictor.\n\n\n\n## S3 method for class 'betareg'\npredict(object, newdata = NULL,\n  type = c(\"response\", \"link\", \"precision\", \"variance\", \"parameters\",\n    \"density\", \"probability\", \"quantile\"),\n  na.action = na.pass, at = 0.5, ...)\n\n\n\n\n\n\n\nobject\n\n\nfitted model object of class “betareg”.\n\n\n\n\nnewdata\n\n\noptionally, a data frame in which to look for variables with which to predict. If omitted, the original observations are used.\n\n\n\n\ntype\n\n\ncharacter indicating type of predictions: fitted means of response (“response”), corresponding linear predictor (“link”), fitted precision parameter phi (“precision”), fitted variances of response (“variance”), or fitted quantile(s) of the response distribution (“quantile”).\n\n\n\n\nna.action\n\n\nfunction determining what should be done with missing values in newdata. The default is to predict NA.\n\n\n\n\nat\n\n\nnumeric vector indicating the level(s) at which quantiles should be predicted (only if type = “quantile”), defaulting to the median at = 0.5.\n\n\n\n\n…\n\n\ncurrently not used.\n\n\n\n\n\n\nFIXME: Update to extended type and at processing.\nFIXME: Add comments about pit and rootogram.\n\n\n\n\nlibrary(\"betareg\")\n\noptions(digits = 4)\n\ndata(\"GasolineYield\", package = \"betareg\")\n\ngy2 &lt;- betareg(yield ~ batch + temp | temp, data = GasolineYield)\n\ncbind(\n  predict(gy2, type = \"response\"),\n  predict(gy2, type = \"link\"),\n  predict(gy2, type = \"precision\"),\n  predict(gy2, type = \"variance\"),\n  predict(gy2, type = \"quantile\", at = c(0.25, 0.5, 0.75))\n)\n\n                                      q_0.25   q_0.5  q_0.75\n1  0.09997 -2.1976   77.56 1.145e-03 0.07549 0.09653 0.12074\n2  0.18658 -1.4724  215.06 7.024e-04 0.16816 0.18561 0.20394\n3  0.32143 -0.7472  596.36 3.651e-04 0.30842 0.32123 0.33422\n4  0.47379 -0.1049 1471.75 1.693e-04 0.46500 0.47378 0.48256\n5  0.08568 -2.3676   93.73 8.269e-04 0.06490 0.08273 0.10328\n6  0.14212 -1.7978  208.89 5.809e-04 0.12525 0.14097 0.15774\n7  0.26285 -1.0312  614.00 3.151e-04 0.25073 0.26259 0.27469\n8  0.10324 -2.1617   85.88 1.066e-03 0.07972 0.10017 0.12344\n9  0.17652 -1.5401  205.86 7.027e-04 0.15806 0.17547 0.19384\n10 0.30245 -0.8357  554.46 3.798e-04 0.28916 0.30221 0.31547\n11 0.07881 -2.4587  120.07 5.996e-04 0.06119 0.07647 0.09390\n12 0.14365 -1.7853  309.57 3.961e-04 0.12981 0.14288 0.15665\n13 0.24751 -1.1120  798.12 2.331e-04 0.23709 0.24730 0.25769\n14 0.34394 -0.6458 1537.51 1.467e-04 0.33573 0.34387 0.35208\n15 0.16957 -1.5887  342.81 4.096e-04 0.15556 0.16892 0.18287\n16 0.27545 -0.9671  821.72 2.426e-04 0.26484 0.27527 0.28586\n17 0.33691 -0.6771 1235.66 1.806e-04 0.32780 0.33683 0.34594\n18 0.10548 -2.1378  191.40 4.904e-04 0.08984 0.10410 0.11962\n19 0.23606 -1.1744  742.04 2.427e-04 0.22542 0.23583 0.24645\n20 0.32316 -0.7393 1368.34 1.597e-04 0.31459 0.32308 0.33164\n21 0.05383 -2.8665  120.07 4.207e-04 0.03893 0.05137 0.06608\n22 0.07928 -2.4521  215.06 3.379e-04 0.06624 0.07798 0.09091\n23 0.16906 -1.5923  720.73 1.946e-04 0.15949 0.16876 0.17831\n24 0.27063 -0.9914 1677.97 1.176e-04 0.26326 0.27054 0.27789\n25 0.08270 -2.4062  248.80 3.037e-04 0.07039 0.08158 0.09380\n26 0.17116 -1.5774  798.12 1.775e-04 0.16202 0.17088 0.18000\n27 0.31885 -0.7590 2523.27 8.604e-05 0.31257 0.31881 0.32509\n28 0.12701 -1.9276  650.84 1.701e-04 0.11801 0.12663 0.13560\n29 0.23661 -1.1714 1885.42 9.575e-05 0.22995 0.23651 0.24316\n30 0.10508 -2.1420  798.12 1.177e-04 0.09759 0.10475 0.11221\n31 0.11952 -1.9970  978.71 1.074e-04 0.11239 0.11926 0.12637\n32 0.18402 -1.4894 1998.57 7.509e-05 0.17811 0.18391 0.18980\n\n## evaluate cumulative _p_robabilities for (small) new data set\ngyd &lt;- GasolineYield[c(1, 5, 10), ]\n## CDF at 0.1 for each observation\npredict(gy2, newdata = gyd, type = \"probability\", at = 0.1)\n\n        1         5        10 \n5.407e-01 7.165e-01 6.053e-40 \n\n## CDF at each combination of 0.1/0.2 and observations\npredict(gy2, newdata = gyd, type = \"probability\", at = c(0.1, 0.2))\n\n       p_0.1     p_0.2\n1  5.407e-01 9.933e-01\n5  7.165e-01 9.991e-01\n10 6.053e-40 5.828e-09\n\n## CDF at pairwise combinations of 0.1/0.2/0.3 and observations\npredict(gy2, newdata = gyd, type = \"probability\", at = c(0.1, 0.2, 0.3))\n\n     1      5     10 \n0.5407 0.9991 0.4549 \n\n## CDF at all combinations of 0.1/0.2/0.3 and observations\npredict(gy2, newdata = gyd, type = \"probability\", at = rbind(c(0.1, 0.2, 0.3)))\n\n       p_0.1     p_0.2  p_0.3\n1  5.407e-01 9.933e-01 1.0000\n5  7.165e-01 9.991e-01 1.0000\n10 6.053e-40 5.828e-09 0.4549",
    "crumbs": [
      "Documentation",
      "Beta regression",
      "predict.betareg"
    ]
  },
  {
    "objectID": "man/betatree.html",
    "href": "man/betatree.html",
    "title": "betareg",
    "section": "",
    "text": "Fit beta regression trees via model-based recursive partitioning.\n\n\n\nbetatree(formula, partition,\n  data, subset = NULL, na.action = na.omit, weights, offset, cluster,\n  link = \"logit\", link.phi = \"log\", control = betareg.control(),\n  ...)\n\n\n\n\n\n\n\nformula\n\n\nsymbolic description of the model of type y ~ x or y ~ x | z, specifying the variables influencing mean and precision of y, respectively. For details see betareg.\n\n\n\n\npartition\n\n\nsymbolic description of the partitioning variables, e.g., ~ p1 + p2. The argument partition can be omitted if formula is a three-part formula of type y ~ x | z | p1 + p2.\n\n\n\n\ndata, subset, na.action, weights, offset, cluster\n\n\narguments controlling data/model processing passed to mob.\n\n\n\n\nlink\n\n\ncharacter specification of the link function in the mean model (mu). Currently, “logit”, “probit”, “cloglog”, “cauchit”, “log”, “loglog” are supported. Alternatively, an object of class “link-glm” can be supplied.\n\n\n\n\nlink.phi\n\n\ncharacter specification of the link function in the precision model (phi). Currently, “identity”, “log”, “sqrt” are supported. Alternatively, an object of class “link-glm” can be supplied.\n\n\n\n\ncontrol\n\n\na list of control arguments for the beta regression specified via betareg.control.\n\n\n\n\n…\n\n\nfurther control arguments for the recursive partitioning passed to mob_control.\n\n\n\n\n\n\nBeta regression trees are an application of model-based recursive partitioning (implemented in mob, see Zeileis et al. 2008) to beta regression (implemented in betareg, see Cribari-Neto and Zeileis 2010). See also Grün at al. (2012) for more details.\nVarious methods are provided for “betatree” objects, most of them inherit their behavior from “mob” objects (e.g., print, summary, coef, etc.). The plot method employs the node_bivplot panel-generating function.\n\n\n\nbetatree() returns an object of S3 class “betatree” which inherits from “modelparty”.\n\n\n\nCribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R. Journal of Statistical Software, 34(2), 1–24. doi:10.18637/jss.v034.i02\nGrün, B., Kosmidis, I., and Zeileis, A. (2012). Extended Beta Regression in R: Shaken, Stirred, Mixed, and Partitioned. Journal of Statistical Software, 48(11), 1–25. doi:10.18637/jss.v048.i11\nZeileis, A., Hothorn, T., and Hornik K. (2008). Model-Based Recursive Partitioning. Journal of Computational and Graphical Statistics, 17(2), 492–514.\n\n\n\nbetareg, betareg.fit, mob\n\n\n\n\nlibrary(\"betareg\")\n\noptions(digits = 4)\nsuppressWarnings(RNGversion(\"3.5.0\"))\n\n## data with two groups of dyslexic and non-dyslexic children\ndata(\"ReadingSkills\", package = \"betareg\")\n## additional random noise (not associated with reading scores)\nset.seed(1071)\nReadingSkills$x1 &lt;- rnorm(nrow(ReadingSkills))\nReadingSkills$x2 &lt;- runif(nrow(ReadingSkills))\nReadingSkills$x3 &lt;- factor(rnorm(nrow(ReadingSkills)) &gt; 0)\n\n## fit beta regression tree: in each node\n##   - accurcay's mean and precision depends on iq\n##   - partitioning is done by dyslexia and the noise variables x1, x2, x3\n## only dyslexia is correctly selected for splitting\nbt &lt;- betatree(accuracy ~ iq | iq, ~ dyslexia + x1 + x2 + x3,\n  data = ReadingSkills, minsize = 10)\nplot(bt)\n\n\n\n\n\n\n\n## inspect result\ncoef(bt)\n\n  (Intercept)       iq (phi)_(Intercept) (phi)_iq\n2      1.6565  1.46571             1.273    2.048\n3      0.3809 -0.08623             4.808    0.826\n\nif(require(\"strucchange\")) sctest(bt)\n\n$`1`\n           dyslexia     x1     x2     x3\nstatistic 2.269e+01 8.5251 5.5699 1.0568\np.value   5.848e-04 0.9095 0.9987 0.9999\n\n$`2`\n          dyslexia     x1     x2     x3\nstatistic        0 6.4116 4.5170 4.2308\np.value         NA 0.8412 0.9752 0.7566\n\n$`3`\nNULL\n\n## IGNORE_RDIFF_BEGIN\nsummary(bt, node = 2)\n\n\nCall:\nbetatree(formula = accuracy ~ iq | iq, data = ReadingSkills)\n\nQuantile residuals:\n   Min     1Q Median     3Q    Max \n-2.495 -0.437  0.210  0.953  1.090 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    1.657      0.286    5.78  7.3e-09 ***\niq             1.466      0.248    5.92  3.2e-09 ***\n\nPhi coefficients (precision model with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    1.273      0.307    4.15  3.4e-05 ***\niq             2.048      0.331    6.19  5.9e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 39.4 on 4 Df\nPseudo R-squared: 0.149\nNumber of iterations: 17 (BFGS) + 2 (Fisher scoring) \n\nsummary(bt, node = 3)\n\n\nCall:\nbetatree(formula = accuracy ~ iq | iq, data = ReadingSkills)\n\nQuantile residuals:\n   Min     1Q Median     3Q    Max \n-2.426 -0.631 -0.067  0.778  1.555 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.3809     0.0486    7.83  4.8e-15 ***\niq           -0.0862     0.0549   -1.57     0.12    \n\nPhi coefficients (precision model with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    4.808      0.414   11.61   &lt;2e-16 ***\niq             0.826      0.395    2.09    0.036 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 27.3 on 4 Df\nPseudo R-squared: 0.0391\nNumber of iterations: 16 (BFGS) + 2 (Fisher scoring) \n\n## IGNORE_RDIFF_END\n\n## add a numerical variable with relevant information for splitting\nReadingSkills$x4 &lt;- rnorm(nrow(ReadingSkills), c(-1.5, 1.5)[ReadingSkills$dyslexia])\n\nbt2 &lt;- betatree(accuracy ~ iq | iq, ~ x1 + x2 + x3 + x4,\n  data = ReadingSkills, minsize = 10)\nplot(bt2)\n\n\n\n\n\n\n\n## inspect result\ncoef(bt2)\n\n  (Intercept)      iq (phi)_(Intercept) (phi)_iq\n2      1.7060 1.47402             1.293   2.0841\n3      0.5048 0.03391             3.131  -0.7684\n\nif(require(\"strucchange\")) sctest(bt2)\n\n$`1`\n              x1     x2     x3       x4\nstatistic 8.5251 5.5699 1.0568 19.94405\np.value   0.9095 0.9987 0.9999  0.03485\n\n$`2`\n              x1     x2     x3     x4\nstatistic 8.9467 3.5888 3.5677 4.7049\np.value   0.5964 0.9985 0.9197 0.9848\n\n$`3`\n              x1     x2     x3     x4\nstatistic 5.5413 1.2373 4.8649 4.9921\np.value   0.6595 0.9997 0.7619 0.7432\n\n## IGNORE_RDIFF_BEGIN\nsummary(bt2, node = 2)\n\n\nCall:\nbetatree(formula = accuracy ~ iq | iq, data = ReadingSkills)\n\nQuantile residuals:\n   Min     1Q Median     3Q    Max \n-2.583 -0.393  0.177  0.923  1.054 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    1.706      0.292    5.85  4.9e-09 ***\niq             1.474      0.248    5.95  2.7e-09 ***\n\nPhi coefficients (precision model with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    1.293      0.312    4.14  3.4e-05 ***\niq             2.084      0.333    6.25  4.0e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 38.6 on 4 Df\nPseudo R-squared: 0.163\nNumber of iterations: 17 (BFGS) + 1 (Fisher scoring) \n\nsummary(bt2, node = 3)\n\n\nCall:\nbetatree(formula = accuracy ~ iq | iq, data = ReadingSkills)\n\nQuantile residuals:\n   Min     1Q Median     3Q    Max \n-2.070 -0.584 -0.156  0.639  2.188 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.5048     0.1245    4.05    5e-05 ***\niq            0.0339     0.0998    0.34     0.73    \n\nPhi coefficients (precision model with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    3.131      0.370    8.45   &lt;2e-16 ***\niq            -0.768      0.359   -2.14    0.032 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 22.4 on 4 Df\nPseudo R-squared: 0.0378\nNumber of iterations: 16 (BFGS) + 1 (Fisher scoring) \n\n## IGNORE_RDIFF_END",
    "crumbs": [
      "Documentation",
      "Beta regression",
      "betatree"
    ]
  },
  {
    "objectID": "man/betatree.html#beta-regression-trees",
    "href": "man/betatree.html#beta-regression-trees",
    "title": "betareg",
    "section": "",
    "text": "Fit beta regression trees via model-based recursive partitioning.\n\n\n\nbetatree(formula, partition,\n  data, subset = NULL, na.action = na.omit, weights, offset, cluster,\n  link = \"logit\", link.phi = \"log\", control = betareg.control(),\n  ...)\n\n\n\n\n\n\n\nformula\n\n\nsymbolic description of the model of type y ~ x or y ~ x | z, specifying the variables influencing mean and precision of y, respectively. For details see betareg.\n\n\n\n\npartition\n\n\nsymbolic description of the partitioning variables, e.g., ~ p1 + p2. The argument partition can be omitted if formula is a three-part formula of type y ~ x | z | p1 + p2.\n\n\n\n\ndata, subset, na.action, weights, offset, cluster\n\n\narguments controlling data/model processing passed to mob.\n\n\n\n\nlink\n\n\ncharacter specification of the link function in the mean model (mu). Currently, “logit”, “probit”, “cloglog”, “cauchit”, “log”, “loglog” are supported. Alternatively, an object of class “link-glm” can be supplied.\n\n\n\n\nlink.phi\n\n\ncharacter specification of the link function in the precision model (phi). Currently, “identity”, “log”, “sqrt” are supported. Alternatively, an object of class “link-glm” can be supplied.\n\n\n\n\ncontrol\n\n\na list of control arguments for the beta regression specified via betareg.control.\n\n\n\n\n…\n\n\nfurther control arguments for the recursive partitioning passed to mob_control.\n\n\n\n\n\n\nBeta regression trees are an application of model-based recursive partitioning (implemented in mob, see Zeileis et al. 2008) to beta regression (implemented in betareg, see Cribari-Neto and Zeileis 2010). See also Grün at al. (2012) for more details.\nVarious methods are provided for “betatree” objects, most of them inherit their behavior from “mob” objects (e.g., print, summary, coef, etc.). The plot method employs the node_bivplot panel-generating function.\n\n\n\nbetatree() returns an object of S3 class “betatree” which inherits from “modelparty”.\n\n\n\nCribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R. Journal of Statistical Software, 34(2), 1–24. doi:10.18637/jss.v034.i02\nGrün, B., Kosmidis, I., and Zeileis, A. (2012). Extended Beta Regression in R: Shaken, Stirred, Mixed, and Partitioned. Journal of Statistical Software, 48(11), 1–25. doi:10.18637/jss.v048.i11\nZeileis, A., Hothorn, T., and Hornik K. (2008). Model-Based Recursive Partitioning. Journal of Computational and Graphical Statistics, 17(2), 492–514.\n\n\n\nbetareg, betareg.fit, mob\n\n\n\n\nlibrary(\"betareg\")\n\noptions(digits = 4)\nsuppressWarnings(RNGversion(\"3.5.0\"))\n\n## data with two groups of dyslexic and non-dyslexic children\ndata(\"ReadingSkills\", package = \"betareg\")\n## additional random noise (not associated with reading scores)\nset.seed(1071)\nReadingSkills$x1 &lt;- rnorm(nrow(ReadingSkills))\nReadingSkills$x2 &lt;- runif(nrow(ReadingSkills))\nReadingSkills$x3 &lt;- factor(rnorm(nrow(ReadingSkills)) &gt; 0)\n\n## fit beta regression tree: in each node\n##   - accurcay's mean and precision depends on iq\n##   - partitioning is done by dyslexia and the noise variables x1, x2, x3\n## only dyslexia is correctly selected for splitting\nbt &lt;- betatree(accuracy ~ iq | iq, ~ dyslexia + x1 + x2 + x3,\n  data = ReadingSkills, minsize = 10)\nplot(bt)\n\n\n\n\n\n\n\n## inspect result\ncoef(bt)\n\n  (Intercept)       iq (phi)_(Intercept) (phi)_iq\n2      1.6565  1.46571             1.273    2.048\n3      0.3809 -0.08623             4.808    0.826\n\nif(require(\"strucchange\")) sctest(bt)\n\n$`1`\n           dyslexia     x1     x2     x3\nstatistic 2.269e+01 8.5251 5.5699 1.0568\np.value   5.848e-04 0.9095 0.9987 0.9999\n\n$`2`\n          dyslexia     x1     x2     x3\nstatistic        0 6.4116 4.5170 4.2308\np.value         NA 0.8412 0.9752 0.7566\n\n$`3`\nNULL\n\n## IGNORE_RDIFF_BEGIN\nsummary(bt, node = 2)\n\n\nCall:\nbetatree(formula = accuracy ~ iq | iq, data = ReadingSkills)\n\nQuantile residuals:\n   Min     1Q Median     3Q    Max \n-2.495 -0.437  0.210  0.953  1.090 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    1.657      0.286    5.78  7.3e-09 ***\niq             1.466      0.248    5.92  3.2e-09 ***\n\nPhi coefficients (precision model with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    1.273      0.307    4.15  3.4e-05 ***\niq             2.048      0.331    6.19  5.9e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 39.4 on 4 Df\nPseudo R-squared: 0.149\nNumber of iterations: 17 (BFGS) + 2 (Fisher scoring) \n\nsummary(bt, node = 3)\n\n\nCall:\nbetatree(formula = accuracy ~ iq | iq, data = ReadingSkills)\n\nQuantile residuals:\n   Min     1Q Median     3Q    Max \n-2.426 -0.631 -0.067  0.778  1.555 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.3809     0.0486    7.83  4.8e-15 ***\niq           -0.0862     0.0549   -1.57     0.12    \n\nPhi coefficients (precision model with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    4.808      0.414   11.61   &lt;2e-16 ***\niq             0.826      0.395    2.09    0.036 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 27.3 on 4 Df\nPseudo R-squared: 0.0391\nNumber of iterations: 16 (BFGS) + 2 (Fisher scoring) \n\n## IGNORE_RDIFF_END\n\n## add a numerical variable with relevant information for splitting\nReadingSkills$x4 &lt;- rnorm(nrow(ReadingSkills), c(-1.5, 1.5)[ReadingSkills$dyslexia])\n\nbt2 &lt;- betatree(accuracy ~ iq | iq, ~ x1 + x2 + x3 + x4,\n  data = ReadingSkills, minsize = 10)\nplot(bt2)\n\n\n\n\n\n\n\n## inspect result\ncoef(bt2)\n\n  (Intercept)      iq (phi)_(Intercept) (phi)_iq\n2      1.7060 1.47402             1.293   2.0841\n3      0.5048 0.03391             3.131  -0.7684\n\nif(require(\"strucchange\")) sctest(bt2)\n\n$`1`\n              x1     x2     x3       x4\nstatistic 8.5251 5.5699 1.0568 19.94405\np.value   0.9095 0.9987 0.9999  0.03485\n\n$`2`\n              x1     x2     x3     x4\nstatistic 8.9467 3.5888 3.5677 4.7049\np.value   0.5964 0.9985 0.9197 0.9848\n\n$`3`\n              x1     x2     x3     x4\nstatistic 5.5413 1.2373 4.8649 4.9921\np.value   0.6595 0.9997 0.7619 0.7432\n\n## IGNORE_RDIFF_BEGIN\nsummary(bt2, node = 2)\n\n\nCall:\nbetatree(formula = accuracy ~ iq | iq, data = ReadingSkills)\n\nQuantile residuals:\n   Min     1Q Median     3Q    Max \n-2.583 -0.393  0.177  0.923  1.054 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    1.706      0.292    5.85  4.9e-09 ***\niq             1.474      0.248    5.95  2.7e-09 ***\n\nPhi coefficients (precision model with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    1.293      0.312    4.14  3.4e-05 ***\niq             2.084      0.333    6.25  4.0e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 38.6 on 4 Df\nPseudo R-squared: 0.163\nNumber of iterations: 17 (BFGS) + 1 (Fisher scoring) \n\nsummary(bt2, node = 3)\n\n\nCall:\nbetatree(formula = accuracy ~ iq | iq, data = ReadingSkills)\n\nQuantile residuals:\n   Min     1Q Median     3Q    Max \n-2.070 -0.584 -0.156  0.639  2.188 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.5048     0.1245    4.05    5e-05 ***\niq            0.0339     0.0998    0.34     0.73    \n\nPhi coefficients (precision model with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    3.131      0.370    8.45   &lt;2e-16 ***\niq            -0.768      0.359   -2.14    0.032 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 22.4 on 4 Df\nPseudo R-squared: 0.0378\nNumber of iterations: 16 (BFGS) + 1 (Fisher scoring) \n\n## IGNORE_RDIFF_END",
    "crumbs": [
      "Documentation",
      "Beta regression",
      "betatree"
    ]
  },
  {
    "objectID": "man/dxbeta.html",
    "href": "man/dxbeta.html",
    "title": "betareg",
    "section": "",
    "text": "Density, distribution function, quantile function, and random generation for the extended-support beta distribution (in regression parameterization) on [0, 1].\n\n\n\ndxbeta(x, mu, phi, nu = 0, log = FALSE)\n\npxbeta(q, mu, phi, nu = 0, lower.tail = TRUE, log.p = FALSE)\n\nqxbeta(p, mu, phi, nu = 0, lower.tail = TRUE, log.p = FALSE)\n\nrxbeta(n, mu, phi, nu = 0)\n\n\n\n\n\n\n\nx, q\n\n\nnumeric. Vector of quantiles.\n\n\n\n\np\n\n\nnumeric. Vector of probabilities.\n\n\n\n\nn\n\n\nnumeric. Number of observations. If length(n) &gt; 1, the length is taken to be the number required.\n\n\n\n\nmu\n\n\nnumeric. The mean of the underlying beta distribution on [-nu, 1 + nu].\n\n\n\n\nphi\n\n\nnumeric. The precision parameter of the underlying beta distribution on [-nu, 1 + nu].\n\n\n\n\nnu\n\n\nnumeric. Exceedence parameter for the support of the underlying beta distribution on [-nu, 1 + nu] that is censored to [0, 1].\n\n\n\n\nlog, log.p\n\n\nlogical. If TRUE, probabilities p are given as log(p).\n\n\n\n\nlower.tail\n\n\nlogical. If TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].\n\n\n\n\n\n\nIn order to obtain an extended-support beta distribution on [0, 1] an additional exceedence parameter nu is introduced. If nu &gt; 0, this scales the underlying beta distribution to the interval [-nu, 1 + nu] where the tails are subsequently censored to the unit interval [0, 1] with point masses on the boundaries 0 and 1. Thus, nu controls how likely boundary observations are and for nu = 0 (the default), the distribution reduces to the classic beta distribution (in regression parameterization) without boundary observations.\n\n\n\ndxbeta gives the density, pxbeta gives the distribution function, qxbeta gives the quantile function, and rxbeta generates random deviates.\n\n\n\ndbetar, XBeta",
    "crumbs": [
      "Documentation",
      "Distributions",
      "dxbeta"
    ]
  },
  {
    "objectID": "man/dxbeta.html#the-extended-support-beta-distribution",
    "href": "man/dxbeta.html#the-extended-support-beta-distribution",
    "title": "betareg",
    "section": "",
    "text": "Density, distribution function, quantile function, and random generation for the extended-support beta distribution (in regression parameterization) on [0, 1].\n\n\n\ndxbeta(x, mu, phi, nu = 0, log = FALSE)\n\npxbeta(q, mu, phi, nu = 0, lower.tail = TRUE, log.p = FALSE)\n\nqxbeta(p, mu, phi, nu = 0, lower.tail = TRUE, log.p = FALSE)\n\nrxbeta(n, mu, phi, nu = 0)\n\n\n\n\n\n\n\nx, q\n\n\nnumeric. Vector of quantiles.\n\n\n\n\np\n\n\nnumeric. Vector of probabilities.\n\n\n\n\nn\n\n\nnumeric. Number of observations. If length(n) &gt; 1, the length is taken to be the number required.\n\n\n\n\nmu\n\n\nnumeric. The mean of the underlying beta distribution on [-nu, 1 + nu].\n\n\n\n\nphi\n\n\nnumeric. The precision parameter of the underlying beta distribution on [-nu, 1 + nu].\n\n\n\n\nnu\n\n\nnumeric. Exceedence parameter for the support of the underlying beta distribution on [-nu, 1 + nu] that is censored to [0, 1].\n\n\n\n\nlog, log.p\n\n\nlogical. If TRUE, probabilities p are given as log(p).\n\n\n\n\nlower.tail\n\n\nlogical. If TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].\n\n\n\n\n\n\nIn order to obtain an extended-support beta distribution on [0, 1] an additional exceedence parameter nu is introduced. If nu &gt; 0, this scales the underlying beta distribution to the interval [-nu, 1 + nu] where the tails are subsequently censored to the unit interval [0, 1] with point masses on the boundaries 0 and 1. Thus, nu controls how likely boundary observations are and for nu = 0 (the default), the distribution reduces to the classic beta distribution (in regression parameterization) without boundary observations.\n\n\n\ndxbeta gives the density, pxbeta gives the distribution function, qxbeta gives the quantile function, and rxbeta generates random deviates.\n\n\n\ndbetar, XBeta",
    "crumbs": [
      "Documentation",
      "Distributions",
      "dxbeta"
    ]
  },
  {
    "objectID": "man/betareg.html",
    "href": "man/betareg.html",
    "title": "betareg",
    "section": "",
    "text": "Fit beta regression models for rates and proportions via maximum likelihood using a parametrization with mean (depending through a link function on the covariates) and precision parameter (called phi).\n\n\n\nbetareg(formula, data, subset, na.action, weights, offset,\n  link = c(\"logit\", \"probit\", \"cloglog\", \"cauchit\", \"log\", \"loglog\"),\n  link.phi = NULL, type = c(\"ML\", \"BC\", \"BR\"), dist = NULL, nu = NULL,\n  control = betareg.control(...), model = TRUE,\n  y = TRUE, x = FALSE, ...)\n\nbetareg.fit(x, y, z = NULL, weights = NULL, offset = NULL,\n  link = \"logit\", link.phi = \"log\", type = \"ML\", control = betareg.control(),\n  dist = NULL, nu = NULL)\n\n\n\n\n\n\n\nformula\n\n\nsymbolic description of the model (of type y ~ x or y ~ x | z; for details see below).\n\n\n\n\ndata, subset, na.action\n\n\narguments controlling formula processing via model.frame.\n\n\n\n\nweights\n\n\noptional numeric vector of case weights.\n\n\n\n\noffset\n\n\noptional numeric vector with an a priori known component to be included in the linear predictor for the mean. In betareg.fit, offset may also be a list of two offsets for the mean and precision equation, respectively.\n\n\n\n\nlink\n\n\ncharacter specification of the link function in the mean model (mu). Currently, “logit”, “probit”, “cloglog”, “cauchit”, “log”, “loglog” are supported. Alternatively, an object of class “link-glm” can be supplied.\n\n\n\n\nlink.phi\n\n\ncharacter specification of the link function in the precision model (phi). Currently, “identity”, “log”, “sqrt” are supported. The default is “log” unless formula is of type y ~ x where the default is “identity” (for backward compatibility). Alternatively, an object of class “link-glm” can be supplied.\n\n\n\n\ntype\n\n\ncharacter specification of the type of estimator. Currently, maximum likelihood (“ML”), ML with bias correction (“BC”), and ML with bias reduction (“BR”) are supported.\n\n\n\n\ndist\n\n\ncharacter specification of the response distribution. Usually, this does not have to be set by the user because by default the classical “beta” distribution is used when all observations for the dependent variable are in (0, 1). In the presence of boundary observations (0 or 1, which cannot be accomodated by “beta”) the extended-support beta mixture distribution (“xbetax”) is used. Additionally, dist = “xbeta” can be used with fixed exceedence parameter nu, mostly for testing and debugging purposes.\n\n\n\n\nnu\n\n\nnumeric. The fixed value of the expected exceedence parameter nu in case the extended-support beta mixture distribution is used. By default, nu does not need to be specified and is estimated if needed. So setting nu is mostly for profiling and debugging.\n\n\n\n\ncontrol\n\n\na list of control arguments specified via betareg.control.\n\n\n\n\nmodel, y, x\n\n\nlogicals. If TRUE the corresponding components of the fit (model frame, response, model matrix) are returned. For betareg.fit, x should be a numeric regressor matrix and y should be the numeric response vector (with values in (0,1)).\n\n\n\n\nz\n\n\nnumeric matrix. Regressor matrix for the precision model, defaulting to an intercept only.\n\n\n\n\n…\n\n\narguments passed to betareg.control.\n\n\n\n\n\n\nBeta regression as suggested by Ferrari and Cribari-Neto (2004) and extended by Simas, Barreto-Souza, and Rocha (2010) is implemented in betareg. It is useful in situations where the dependent variable is continuous and restricted to the unit interval (0, 1), e.g., resulting from rates or proportions. It is modeled to be beta-distributed with parametrization using mean and precision parameter (called phi). The mean is linked, as in generalized linear models (GLMs), to the responses through a link function and a linear predictor. Additionally, the precision parameter phi can be linked to another (potentially overlapping) set of regressors through a second link function, resulting in a model with variable dispersion.\nEstimation is performed by maximum likelihood (ML) via optim using analytical gradients and (by default) starting values from an auxiliary linear regression of the transformed response. Subsequently, the optim result may be enhanced by an additional Fisher scoring iteration using analytical gradients and expected information. This slightly improves the optimization by moving the gradients even closer to zero (for type = “ML” and “BC”) or solving the bias-adjusted estimating equations (for type = “BR”). For the former two estimators, the optional Fisher scoring can be disabled by setting fsmaxit = 0 in the control arguments. See Cribari-Neto and Zeileis (2010) and Grün et al. (2012) for details.\nIn the beta regression as introduced by Ferrari and Cribari-Neto (2004), the mean of the response is linked to a linear predictor described by y ~ x1 + x2 using a link function while the precision parameter phi is assumed to be constant. Simas et al. (2009) suggest to extend this model by linking phi to an additional set of regressors (z1 + z2, say): In betareg this can be specified in a formula of type y ~ x1 + x2 | z1 + z2 where the regressors in the two parts can be overlapping. In the precision model (for phi), the link function link.phi is used. The default is a “log” link unless no precision model is specified. In the latter case (i.e., when the formula is of type y ~ x1 + x2), the “identity” link is used by default for backward compatibility.\nSimas et al. (2009) also suggest further extensions (non-linear specificiations, bias correction) which are not yet implemented in betareg. However, Kosmidis and Firth (2010) discuss general algorithms for bias correction/reduction, both of which are available in betareg by setting the type argument accordingly. (Technical note: In case, either bias correction or reduction is requested, the second derivative of the inverse link function is required for link and link.phi. If the two links are specified by their names (as done by default in betareg), then the “link-glm” objects are enhanced automatically by the required additional d2mu.deta function. However, if a “link-glm” object is supplied directly by the user, it needs to have the d2mu.deta function or, for backward compatibility, dmu.deta.)\nThe main parameters of interest are the coefficients in the linear predictor of the mean model. The additional parameters in the precision model (phi) can either be treated as full model parameters (default) or as nuisance parameters. In the latter case the estimation does not change, only the reported information in output from print, summary, or coef (among others) will be different. See also betareg.control.\nThe extended-support beta distribution (“xbeta”) leverages an underlying symmetric four-parameter beta distribution with exceedence parameter nu to obtain support [-nu, 1 + nu] that is subsequently censored to [0, 1] in order to obtain point masses at the boundary values 0 and 1. The extended-support beta mixture distribution (“xbetax”) is a continuous mixture of extended-support beta distributions where the exceedence parameter follows an exponential distribution with mean nu (rather than a fixed value of nu). The latter “xbetax” specification is used by default in case of boundary observations at 0 and/or 1. The “xbeta” specification with fixed nu is mostly for testing and debugging purposes.\nA set of standard extractor functions for fitted model objects is available for objects of class “betareg”, including methods to the generic functions print, summary, plot, coef, vcov, logLik, residuals, predict, terms, model.frame, model.matrix, cooks.distance and hatvalues (see influence.measures), gleverage (new generic), estfun and bread (from the sandwich package), and coeftest (from the lmtest package).\nSee predict.betareg, residuals.betareg, plot.betareg, and summary.betareg for more details on all methods.\nThe original version of the package was written by Alexandre B. Simas and Andrea V. Rocha (up to version 1.2). Starting from version 2.0-0 the code was rewritten by Achim Zeileis.\n\n\n\nbetareg returns an object of class “betareg”, i.e., a list with components as follows. betareg.fit returns an unclassed list with components up to converged.\n\n\n\ncoefficients\n\n\na list with elements “mean” and “precision” containing the coefficients from the respective models,\n\n\n\n\nresiduals\n\n\na vector of raw residuals (observed - fitted),\n\n\n\n\nfitted.values\n\n\na vector of fitted means,\n\n\n\n\noptim\n\n\noutput from the optim call for maximizing the log-likelihood(s),\n\n\n\n\nmethod\n\n\nthe method argument passed to the optim call,\n\n\n\n\ncontrol\n\n\nthe control arguments passed to the optim call,\n\n\n\n\nstart\n\n\nthe starting values for the parameters passed to the optim call,\n\n\n\n\nweights\n\n\nthe weights used (if any),\n\n\n\n\noffset\n\n\na list of offset vectors used (if any),\n\n\n\n\nn\n\n\nnumber of observations,\n\n\n\n\nnobs\n\n\nnumber of observations with non-zero weights,\n\n\n\n\ndf.null\n\n\nresidual degrees of freedom in the null model (constant mean and dispersion), i.e., n - 2,\n\n\n\n\ndf.residual\n\n\nresidual degrees of freedom in the fitted model,\n\n\n\n\nphi\n\n\nlogical indicating whether the precision (phi) coefficients will be treated as full model parameters or nuisance parameters in subsequent calls to print, summary, coef etc.,\n\n\n\n\nloglik\n\n\nlog-likelihood of the fitted model,\n\n\n\n\nvcov\n\n\ncovariance matrix of all parameters in the model,\n\n\n\n\npseudo.r.squared\n\n\npseudo R-squared value (squared correlation of linear predictor and link-transformed response),\n\n\n\n\nlink\n\n\na list with elements “mean” and “precision” containing the link objects for the respective models,\n\n\n\n\nconverged\n\n\nlogical indicating successful convergence of optim,\n\n\n\n\ncall\n\n\nthe original function call,\n\n\n\n\nformula\n\n\nthe original formula,\n\n\n\n\nterms\n\n\na list with elements “mean”, “precision” and “full” containing the terms objects for the respective models,\n\n\n\n\nlevels\n\n\na list with elements “mean”, “precision” and “full” containing the levels of the categorical regressors,\n\n\n\n\ncontrasts\n\n\na list with elements “mean” and “precision” containing the contrasts corresponding to levels from the respective models,\n\n\n\n\nmodel\n\n\nthe full model frame (if model = TRUE),\n\n\n\n\ny\n\n\nthe response proportion vector (if y = TRUE),\n\n\n\n\nx\n\n\na list with elements “mean” and “precision” containing the model matrices from the respective models (if x = TRUE).\n\n\n\n\n\n\nCribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R. Journal of Statistical Software, 34(2), 1–24. doi:10.18637/jss.v034.i02\nFerrari, S.L.P., and Cribari-Neto, F. (2004). Beta Regression for Modeling Rates and Proportions. Journal of Applied Statistics, 31(7), 799–815.\nGrün, B., Kosmidis, I., and Zeileis, A. (2012). Extended Beta Regression in R: Shaken, Stirred, Mixed, and Partitioned. Journal of Statistical Software, 48(11), 1–25. doi:10.18637/jss.v048.i11\nKosmidis, I., and Firth, D. (2010). A Generic Algorithm for Reducing Bias in Parametric Estimation. Electronic Journal of Statistics, 4, 1097–1112.\nSimas, A.B., Barreto-Souza, W., and Rocha, A.V. (2010). Improved Estimators for a General Class of Beta Regression Models. Computational Statistics & Data Analysis, 54(2), 348–366.\n\n\n\nsummary.betareg, predict.betareg, residuals.betareg, Formula\n\n\n\n\nlibrary(\"betareg\")\n\noptions(digits = 4)\n\n## Section 4 from Ferrari and Cribari-Neto (2004)\ndata(\"GasolineYield\", package = \"betareg\")\ndata(\"FoodExpenditure\", package = \"betareg\")\n\n## Table 1\ngy &lt;- betareg(yield ~ batch + temp, data = GasolineYield)\nsummary(gy)\n\n\nCall:\nbetareg(formula = yield ~ batch + temp, data = GasolineYield)\n\nQuantile residuals:\n   Min     1Q Median     3Q    Max \n-2.140 -0.570  0.120  0.704  1.751 \n\nCoefficients (mean model with logit link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -6.159571   0.182325  -33.78  &lt; 2e-16 ***\nbatch1       1.727729   0.101229   17.07  &lt; 2e-16 ***\nbatch2       1.322597   0.117902   11.22  &lt; 2e-16 ***\nbatch3       1.572310   0.116105   13.54  &lt; 2e-16 ***\nbatch4       1.059714   0.102360   10.35  &lt; 2e-16 ***\nbatch5       1.133752   0.103523   10.95  &lt; 2e-16 ***\nbatch6       1.040162   0.106036    9.81  &lt; 2e-16 ***\nbatch7       0.543692   0.109127    4.98  6.3e-07 ***\nbatch8       0.495901   0.108926    4.55  5.3e-06 ***\nbatch9       0.385793   0.118593    3.25   0.0011 ** \ntemp         0.010967   0.000413   26.58  &lt; 2e-16 ***\n\nPhi coefficients (precision model with identity link):\n      Estimate Std. Error z value Pr(&gt;|z|)    \n(phi)      440        110       4  6.3e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 84.8 on 12 Df\nPseudo R-squared: 0.962\nNumber of iterations: 51 (BFGS) + 3 (Fisher scoring) \n\n## Table 2\nfe_lin &lt;- lm(I(food/income) ~ income + persons, data = FoodExpenditure)\nlibrary(\"lmtest\")\nbptest(fe_lin)\n\n\n    studentized Breusch-Pagan test\n\ndata:  fe_lin\nBP = 5.9, df = 2, p-value = 0.05\n\nfe_beta &lt;- betareg(I(food/income) ~ income + persons, data = FoodExpenditure)\nsummary(fe_beta)\n\n\nCall:\nbetareg(formula = I(food/income) ~ income + persons, data = FoodExpenditure)\n\nQuantile residuals:\n   Min     1Q Median     3Q    Max \n-2.533 -0.460  0.170  0.642  1.773 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.62255    0.22385   -2.78   0.0054 ** \nincome      -0.01230    0.00304   -4.05  5.1e-05 ***\npersons      0.11846    0.03534    3.35   0.0008 ***\n\nPhi coefficients (precision model with identity link):\n      Estimate Std. Error z value Pr(&gt;|z|)    \n(phi)    35.61       8.08    4.41    1e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 45.3 on 4 Df\nPseudo R-squared: 0.388\nNumber of iterations: 28 (BFGS) + 4 (Fisher scoring) \n\n## nested model comparisons via Wald and LR tests\nfe_beta2 &lt;- betareg(I(food/income) ~ income, data = FoodExpenditure)\nlrtest(fe_beta, fe_beta2)\n\nLikelihood ratio test\n\nModel 1: I(food/income) ~ income + persons\nModel 2: I(food/income) ~ income\n  #Df LogLik Df Chisq Pr(&gt;Chisq)   \n1   4   45.3                       \n2   3   40.5 -1  9.65     0.0019 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nwaldtest(fe_beta, fe_beta2)\n\nWald test\n\nModel 1: I(food/income) ~ income + persons\nModel 2: I(food/income) ~ income\n  Res.Df Df Chisq Pr(&gt;Chisq)    \n1     34                        \n2     35 -1  11.2      8e-04 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n## Section 3 from online supplements to Simas et al. (2010)\n## mean model as in gy above\n## precision model with regressor temp\ngy2 &lt;- betareg(yield ~ batch + temp | temp, data = GasolineYield)\n\n## MLE column in Table 19\nsummary(gy2)\n\n\nCall:\nbetareg(formula = yield ~ batch + temp | temp, data = GasolineYield)\n\nQuantile residuals:\n   Min     1Q Median     3Q    Max \n-2.104 -0.585 -0.143  0.690  2.520 \n\nCoefficients (mean model with logit link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -5.923236   0.183526  -32.27  &lt; 2e-16 ***\nbatch1       1.601988   0.063856   25.09  &lt; 2e-16 ***\nbatch2       1.297266   0.099100   13.09  &lt; 2e-16 ***\nbatch3       1.565338   0.099739   15.69  &lt; 2e-16 ***\nbatch4       1.030072   0.063288   16.28  &lt; 2e-16 ***\nbatch5       1.154163   0.065643   17.58  &lt; 2e-16 ***\nbatch6       1.019445   0.066351   15.36  &lt; 2e-16 ***\nbatch7       0.622259   0.065632    9.48  &lt; 2e-16 ***\nbatch8       0.564583   0.060185    9.38  &lt; 2e-16 ***\nbatch9       0.359439   0.067141    5.35  8.6e-08 ***\ntemp         0.010359   0.000436   23.75  &lt; 2e-16 ***\n\nPhi coefficients (precision model with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.36409    1.22578    1.11     0.27    \ntemp         0.01457    0.00362    4.03  5.7e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood:   87 on 13 Df\nPseudo R-squared: 0.952\nNumber of iterations: 33 (BFGS) + 28 (Fisher scoring) \n\n## LRT row in Table 18\nlrtest(gy, gy2)\n\nLikelihood ratio test\n\nModel 1: yield ~ batch + temp\nModel 2: yield ~ batch + temp | temp\n  #Df LogLik Df Chisq Pr(&gt;Chisq)  \n1  12   84.8                      \n2  13   87.0  1  4.36      0.037 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "Documentation",
      "Beta regression",
      "betareg"
    ]
  },
  {
    "objectID": "man/betareg.html#beta-regression-for-rates-and-proportions",
    "href": "man/betareg.html#beta-regression-for-rates-and-proportions",
    "title": "betareg",
    "section": "",
    "text": "Fit beta regression models for rates and proportions via maximum likelihood using a parametrization with mean (depending through a link function on the covariates) and precision parameter (called phi).\n\n\n\nbetareg(formula, data, subset, na.action, weights, offset,\n  link = c(\"logit\", \"probit\", \"cloglog\", \"cauchit\", \"log\", \"loglog\"),\n  link.phi = NULL, type = c(\"ML\", \"BC\", \"BR\"), dist = NULL, nu = NULL,\n  control = betareg.control(...), model = TRUE,\n  y = TRUE, x = FALSE, ...)\n\nbetareg.fit(x, y, z = NULL, weights = NULL, offset = NULL,\n  link = \"logit\", link.phi = \"log\", type = \"ML\", control = betareg.control(),\n  dist = NULL, nu = NULL)\n\n\n\n\n\n\n\nformula\n\n\nsymbolic description of the model (of type y ~ x or y ~ x | z; for details see below).\n\n\n\n\ndata, subset, na.action\n\n\narguments controlling formula processing via model.frame.\n\n\n\n\nweights\n\n\noptional numeric vector of case weights.\n\n\n\n\noffset\n\n\noptional numeric vector with an a priori known component to be included in the linear predictor for the mean. In betareg.fit, offset may also be a list of two offsets for the mean and precision equation, respectively.\n\n\n\n\nlink\n\n\ncharacter specification of the link function in the mean model (mu). Currently, “logit”, “probit”, “cloglog”, “cauchit”, “log”, “loglog” are supported. Alternatively, an object of class “link-glm” can be supplied.\n\n\n\n\nlink.phi\n\n\ncharacter specification of the link function in the precision model (phi). Currently, “identity”, “log”, “sqrt” are supported. The default is “log” unless formula is of type y ~ x where the default is “identity” (for backward compatibility). Alternatively, an object of class “link-glm” can be supplied.\n\n\n\n\ntype\n\n\ncharacter specification of the type of estimator. Currently, maximum likelihood (“ML”), ML with bias correction (“BC”), and ML with bias reduction (“BR”) are supported.\n\n\n\n\ndist\n\n\ncharacter specification of the response distribution. Usually, this does not have to be set by the user because by default the classical “beta” distribution is used when all observations for the dependent variable are in (0, 1). In the presence of boundary observations (0 or 1, which cannot be accomodated by “beta”) the extended-support beta mixture distribution (“xbetax”) is used. Additionally, dist = “xbeta” can be used with fixed exceedence parameter nu, mostly for testing and debugging purposes.\n\n\n\n\nnu\n\n\nnumeric. The fixed value of the expected exceedence parameter nu in case the extended-support beta mixture distribution is used. By default, nu does not need to be specified and is estimated if needed. So setting nu is mostly for profiling and debugging.\n\n\n\n\ncontrol\n\n\na list of control arguments specified via betareg.control.\n\n\n\n\nmodel, y, x\n\n\nlogicals. If TRUE the corresponding components of the fit (model frame, response, model matrix) are returned. For betareg.fit, x should be a numeric regressor matrix and y should be the numeric response vector (with values in (0,1)).\n\n\n\n\nz\n\n\nnumeric matrix. Regressor matrix for the precision model, defaulting to an intercept only.\n\n\n\n\n…\n\n\narguments passed to betareg.control.\n\n\n\n\n\n\nBeta regression as suggested by Ferrari and Cribari-Neto (2004) and extended by Simas, Barreto-Souza, and Rocha (2010) is implemented in betareg. It is useful in situations where the dependent variable is continuous and restricted to the unit interval (0, 1), e.g., resulting from rates or proportions. It is modeled to be beta-distributed with parametrization using mean and precision parameter (called phi). The mean is linked, as in generalized linear models (GLMs), to the responses through a link function and a linear predictor. Additionally, the precision parameter phi can be linked to another (potentially overlapping) set of regressors through a second link function, resulting in a model with variable dispersion.\nEstimation is performed by maximum likelihood (ML) via optim using analytical gradients and (by default) starting values from an auxiliary linear regression of the transformed response. Subsequently, the optim result may be enhanced by an additional Fisher scoring iteration using analytical gradients and expected information. This slightly improves the optimization by moving the gradients even closer to zero (for type = “ML” and “BC”) or solving the bias-adjusted estimating equations (for type = “BR”). For the former two estimators, the optional Fisher scoring can be disabled by setting fsmaxit = 0 in the control arguments. See Cribari-Neto and Zeileis (2010) and Grün et al. (2012) for details.\nIn the beta regression as introduced by Ferrari and Cribari-Neto (2004), the mean of the response is linked to a linear predictor described by y ~ x1 + x2 using a link function while the precision parameter phi is assumed to be constant. Simas et al. (2009) suggest to extend this model by linking phi to an additional set of regressors (z1 + z2, say): In betareg this can be specified in a formula of type y ~ x1 + x2 | z1 + z2 where the regressors in the two parts can be overlapping. In the precision model (for phi), the link function link.phi is used. The default is a “log” link unless no precision model is specified. In the latter case (i.e., when the formula is of type y ~ x1 + x2), the “identity” link is used by default for backward compatibility.\nSimas et al. (2009) also suggest further extensions (non-linear specificiations, bias correction) which are not yet implemented in betareg. However, Kosmidis and Firth (2010) discuss general algorithms for bias correction/reduction, both of which are available in betareg by setting the type argument accordingly. (Technical note: In case, either bias correction or reduction is requested, the second derivative of the inverse link function is required for link and link.phi. If the two links are specified by their names (as done by default in betareg), then the “link-glm” objects are enhanced automatically by the required additional d2mu.deta function. However, if a “link-glm” object is supplied directly by the user, it needs to have the d2mu.deta function or, for backward compatibility, dmu.deta.)\nThe main parameters of interest are the coefficients in the linear predictor of the mean model. The additional parameters in the precision model (phi) can either be treated as full model parameters (default) or as nuisance parameters. In the latter case the estimation does not change, only the reported information in output from print, summary, or coef (among others) will be different. See also betareg.control.\nThe extended-support beta distribution (“xbeta”) leverages an underlying symmetric four-parameter beta distribution with exceedence parameter nu to obtain support [-nu, 1 + nu] that is subsequently censored to [0, 1] in order to obtain point masses at the boundary values 0 and 1. The extended-support beta mixture distribution (“xbetax”) is a continuous mixture of extended-support beta distributions where the exceedence parameter follows an exponential distribution with mean nu (rather than a fixed value of nu). The latter “xbetax” specification is used by default in case of boundary observations at 0 and/or 1. The “xbeta” specification with fixed nu is mostly for testing and debugging purposes.\nA set of standard extractor functions for fitted model objects is available for objects of class “betareg”, including methods to the generic functions print, summary, plot, coef, vcov, logLik, residuals, predict, terms, model.frame, model.matrix, cooks.distance and hatvalues (see influence.measures), gleverage (new generic), estfun and bread (from the sandwich package), and coeftest (from the lmtest package).\nSee predict.betareg, residuals.betareg, plot.betareg, and summary.betareg for more details on all methods.\nThe original version of the package was written by Alexandre B. Simas and Andrea V. Rocha (up to version 1.2). Starting from version 2.0-0 the code was rewritten by Achim Zeileis.\n\n\n\nbetareg returns an object of class “betareg”, i.e., a list with components as follows. betareg.fit returns an unclassed list with components up to converged.\n\n\n\ncoefficients\n\n\na list with elements “mean” and “precision” containing the coefficients from the respective models,\n\n\n\n\nresiduals\n\n\na vector of raw residuals (observed - fitted),\n\n\n\n\nfitted.values\n\n\na vector of fitted means,\n\n\n\n\noptim\n\n\noutput from the optim call for maximizing the log-likelihood(s),\n\n\n\n\nmethod\n\n\nthe method argument passed to the optim call,\n\n\n\n\ncontrol\n\n\nthe control arguments passed to the optim call,\n\n\n\n\nstart\n\n\nthe starting values for the parameters passed to the optim call,\n\n\n\n\nweights\n\n\nthe weights used (if any),\n\n\n\n\noffset\n\n\na list of offset vectors used (if any),\n\n\n\n\nn\n\n\nnumber of observations,\n\n\n\n\nnobs\n\n\nnumber of observations with non-zero weights,\n\n\n\n\ndf.null\n\n\nresidual degrees of freedom in the null model (constant mean and dispersion), i.e., n - 2,\n\n\n\n\ndf.residual\n\n\nresidual degrees of freedom in the fitted model,\n\n\n\n\nphi\n\n\nlogical indicating whether the precision (phi) coefficients will be treated as full model parameters or nuisance parameters in subsequent calls to print, summary, coef etc.,\n\n\n\n\nloglik\n\n\nlog-likelihood of the fitted model,\n\n\n\n\nvcov\n\n\ncovariance matrix of all parameters in the model,\n\n\n\n\npseudo.r.squared\n\n\npseudo R-squared value (squared correlation of linear predictor and link-transformed response),\n\n\n\n\nlink\n\n\na list with elements “mean” and “precision” containing the link objects for the respective models,\n\n\n\n\nconverged\n\n\nlogical indicating successful convergence of optim,\n\n\n\n\ncall\n\n\nthe original function call,\n\n\n\n\nformula\n\n\nthe original formula,\n\n\n\n\nterms\n\n\na list with elements “mean”, “precision” and “full” containing the terms objects for the respective models,\n\n\n\n\nlevels\n\n\na list with elements “mean”, “precision” and “full” containing the levels of the categorical regressors,\n\n\n\n\ncontrasts\n\n\na list with elements “mean” and “precision” containing the contrasts corresponding to levels from the respective models,\n\n\n\n\nmodel\n\n\nthe full model frame (if model = TRUE),\n\n\n\n\ny\n\n\nthe response proportion vector (if y = TRUE),\n\n\n\n\nx\n\n\na list with elements “mean” and “precision” containing the model matrices from the respective models (if x = TRUE).\n\n\n\n\n\n\nCribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R. Journal of Statistical Software, 34(2), 1–24. doi:10.18637/jss.v034.i02\nFerrari, S.L.P., and Cribari-Neto, F. (2004). Beta Regression for Modeling Rates and Proportions. Journal of Applied Statistics, 31(7), 799–815.\nGrün, B., Kosmidis, I., and Zeileis, A. (2012). Extended Beta Regression in R: Shaken, Stirred, Mixed, and Partitioned. Journal of Statistical Software, 48(11), 1–25. doi:10.18637/jss.v048.i11\nKosmidis, I., and Firth, D. (2010). A Generic Algorithm for Reducing Bias in Parametric Estimation. Electronic Journal of Statistics, 4, 1097–1112.\nSimas, A.B., Barreto-Souza, W., and Rocha, A.V. (2010). Improved Estimators for a General Class of Beta Regression Models. Computational Statistics & Data Analysis, 54(2), 348–366.\n\n\n\nsummary.betareg, predict.betareg, residuals.betareg, Formula\n\n\n\n\nlibrary(\"betareg\")\n\noptions(digits = 4)\n\n## Section 4 from Ferrari and Cribari-Neto (2004)\ndata(\"GasolineYield\", package = \"betareg\")\ndata(\"FoodExpenditure\", package = \"betareg\")\n\n## Table 1\ngy &lt;- betareg(yield ~ batch + temp, data = GasolineYield)\nsummary(gy)\n\n\nCall:\nbetareg(formula = yield ~ batch + temp, data = GasolineYield)\n\nQuantile residuals:\n   Min     1Q Median     3Q    Max \n-2.140 -0.570  0.120  0.704  1.751 \n\nCoefficients (mean model with logit link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -6.159571   0.182325  -33.78  &lt; 2e-16 ***\nbatch1       1.727729   0.101229   17.07  &lt; 2e-16 ***\nbatch2       1.322597   0.117902   11.22  &lt; 2e-16 ***\nbatch3       1.572310   0.116105   13.54  &lt; 2e-16 ***\nbatch4       1.059714   0.102360   10.35  &lt; 2e-16 ***\nbatch5       1.133752   0.103523   10.95  &lt; 2e-16 ***\nbatch6       1.040162   0.106036    9.81  &lt; 2e-16 ***\nbatch7       0.543692   0.109127    4.98  6.3e-07 ***\nbatch8       0.495901   0.108926    4.55  5.3e-06 ***\nbatch9       0.385793   0.118593    3.25   0.0011 ** \ntemp         0.010967   0.000413   26.58  &lt; 2e-16 ***\n\nPhi coefficients (precision model with identity link):\n      Estimate Std. Error z value Pr(&gt;|z|)    \n(phi)      440        110       4  6.3e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 84.8 on 12 Df\nPseudo R-squared: 0.962\nNumber of iterations: 51 (BFGS) + 3 (Fisher scoring) \n\n## Table 2\nfe_lin &lt;- lm(I(food/income) ~ income + persons, data = FoodExpenditure)\nlibrary(\"lmtest\")\nbptest(fe_lin)\n\n\n    studentized Breusch-Pagan test\n\ndata:  fe_lin\nBP = 5.9, df = 2, p-value = 0.05\n\nfe_beta &lt;- betareg(I(food/income) ~ income + persons, data = FoodExpenditure)\nsummary(fe_beta)\n\n\nCall:\nbetareg(formula = I(food/income) ~ income + persons, data = FoodExpenditure)\n\nQuantile residuals:\n   Min     1Q Median     3Q    Max \n-2.533 -0.460  0.170  0.642  1.773 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.62255    0.22385   -2.78   0.0054 ** \nincome      -0.01230    0.00304   -4.05  5.1e-05 ***\npersons      0.11846    0.03534    3.35   0.0008 ***\n\nPhi coefficients (precision model with identity link):\n      Estimate Std. Error z value Pr(&gt;|z|)    \n(phi)    35.61       8.08    4.41    1e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 45.3 on 4 Df\nPseudo R-squared: 0.388\nNumber of iterations: 28 (BFGS) + 4 (Fisher scoring) \n\n## nested model comparisons via Wald and LR tests\nfe_beta2 &lt;- betareg(I(food/income) ~ income, data = FoodExpenditure)\nlrtest(fe_beta, fe_beta2)\n\nLikelihood ratio test\n\nModel 1: I(food/income) ~ income + persons\nModel 2: I(food/income) ~ income\n  #Df LogLik Df Chisq Pr(&gt;Chisq)   \n1   4   45.3                       \n2   3   40.5 -1  9.65     0.0019 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nwaldtest(fe_beta, fe_beta2)\n\nWald test\n\nModel 1: I(food/income) ~ income + persons\nModel 2: I(food/income) ~ income\n  Res.Df Df Chisq Pr(&gt;Chisq)    \n1     34                        \n2     35 -1  11.2      8e-04 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n## Section 3 from online supplements to Simas et al. (2010)\n## mean model as in gy above\n## precision model with regressor temp\ngy2 &lt;- betareg(yield ~ batch + temp | temp, data = GasolineYield)\n\n## MLE column in Table 19\nsummary(gy2)\n\n\nCall:\nbetareg(formula = yield ~ batch + temp | temp, data = GasolineYield)\n\nQuantile residuals:\n   Min     1Q Median     3Q    Max \n-2.104 -0.585 -0.143  0.690  2.520 \n\nCoefficients (mean model with logit link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -5.923236   0.183526  -32.27  &lt; 2e-16 ***\nbatch1       1.601988   0.063856   25.09  &lt; 2e-16 ***\nbatch2       1.297266   0.099100   13.09  &lt; 2e-16 ***\nbatch3       1.565338   0.099739   15.69  &lt; 2e-16 ***\nbatch4       1.030072   0.063288   16.28  &lt; 2e-16 ***\nbatch5       1.154163   0.065643   17.58  &lt; 2e-16 ***\nbatch6       1.019445   0.066351   15.36  &lt; 2e-16 ***\nbatch7       0.622259   0.065632    9.48  &lt; 2e-16 ***\nbatch8       0.564583   0.060185    9.38  &lt; 2e-16 ***\nbatch9       0.359439   0.067141    5.35  8.6e-08 ***\ntemp         0.010359   0.000436   23.75  &lt; 2e-16 ***\n\nPhi coefficients (precision model with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.36409    1.22578    1.11     0.27    \ntemp         0.01457    0.00362    4.03  5.7e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood:   87 on 13 Df\nPseudo R-squared: 0.952\nNumber of iterations: 33 (BFGS) + 28 (Fisher scoring) \n\n## LRT row in Table 18\nlrtest(gy, gy2)\n\nLikelihood ratio test\n\nModel 1: yield ~ batch + temp\nModel 2: yield ~ batch + temp | temp\n  #Df LogLik Df Chisq Pr(&gt;Chisq)  \n1  12   84.8                      \n2  13   87.0  1  4.36      0.037 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "Documentation",
      "Beta regression",
      "betareg"
    ]
  }
]